{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Semi-Supervised Architope (Chaotic Data)\n",
    "---\n",
    "- This code Implements Algorithm 3.2 of the \"Architopes\" paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode: Code-Testin Parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_run = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-parameters\n",
    "In Grid_Enhanced_NetworkGrid_Enhanced_Network.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-size Ratio\n",
    "test_size_ratio = 1\n",
    "min_height = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------#\n",
    "# Only For Motivational Example Only #\n",
    "#------------------------------------#\n",
    "## Hyperparameters\n",
    "percentage_in_row = .25\n",
    "N = 5000\n",
    "\n",
    "def f_1(x):\n",
    "    return x\n",
    "def f_2(x):\n",
    "    return x**2\n",
    "x_0 = 0\n",
    "x_end = 1\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "Only turn of if running code directly here, typically this script should be run be called by other notebooks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "results_path = \"./outputs/models/\"\n",
    "results_tables_path = \"./outputs/results/\"\n",
    "raw_data_path_folder = \"./inputs/raw/\"\n",
    "data_path_folder = \"./inputs/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "lorenz input data               x         y          z\n",
      "0      5.894076 -6.415820  -8.194456\n",
      "1      4.821934 -4.429324  -8.263782\n",
      "2      4.022918 -2.797976  -8.203039\n",
      "3      3.441617 -1.433997  -8.064589\n",
      "4      3.035476 -0.265226  -7.879283\n",
      "...         ...       ...        ...\n",
      "47994  8.413575  7.664786  27.872319\n",
      "47995  8.339276  7.603378  27.769801\n",
      "47996  8.266649  7.551238  27.659791\n",
      "47997  8.196433  7.508691  27.543485\n",
      "47998  8.129324  7.475957  27.422103\n",
      "\n",
      "[47999 rows x 3 columns]\n",
      "size training input data: (43199, 3)\n",
      "size test input data: (4800, 3)\n",
      "size training output data: (43199, 3)\n",
      "size test output data: (4800, 3)\n",
      "#================================================#\n",
      " Training Datasize: 43199 and test datasize: 4800.  \n",
      "#================================================#\n",
      "lorenz_input_data shape: (47999, 3)\n",
      "size training output data: (43199, 3)\n",
      "size test output data: (4800, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load Packages/Modules\n",
    "exec(open('Init_Dump.py').read())\n",
    "# Load Hyper-parameter Grid - here is set the Option_Function\n",
    "exec(open('Grid_Enhanced_Network.py').read()) \n",
    "# Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Pre-process Data\n",
    "if Option_Function != \"Motivational_Example\": \n",
    "    exec(open('Chaos_Data_Preprocessor.py').read())\n",
    "else:\n",
    "    print(1)\n",
    "    exec(open('Motivational_Example.py').read())\n",
    "    print(\"Training Data size: \",X_train.shape[0])\n",
    "# Import time separately\n",
    "import time\n",
    "\n",
    "# TEMP\n",
    "# import pickle_compat\n",
    "# pickle_compat.patch()\n",
    "# param_grid_Vanilla_Nets['input_dim']=X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lorenz\n"
     ]
    }
   ],
   "source": [
    "print(Option_Function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)\n",
    "tf.random.set_seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Process:\n",
    "- Convert Categorical Variables to Dummies\n",
    "- Remove Bad Column\n",
    "- Perform Training/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Lipschitz Partition Builder\n",
    "\n",
    "We implement the random paritioning method of [Yair Bartal](https://scholar.google.com/citations?user=eCXP24kAAAAJ&hl=en):\n",
    "- [On approximating arbitrary metrices by tree metrics](https://dl.acm.org/doi/10.1145/276698.276725)\n",
    "\n",
    "The algorithm is summarized as follow:\n",
    "\n",
    "---\n",
    "\n",
    "## Algorithm:\n",
    " 1. Sample $\\alpha \\in [4^{-1},2^{-1}]$ randomly and uniformly,\n",
    " 2. Apply a random suffle of the data, (a random bijection $\\pi:\\{i\\}_{i=1}^X \\rightarrow \\mathbb{X}$),\n",
    " 3. For $i = 1,\\dots,I$:\n",
    "   - Set $K_i\\triangleq B\\left(\\pi(i),\\alpha \\Delta \\right) - \\bigcup_{j=1}^{i-1} P_j$\n",
    " \n",
    " 4. Remove empty members of $\\left\\{K_i\\right\\}_{i=1}^X$.  \n",
    " \n",
    " **Return**: $\\left\\{K_i\\right\\}_{i=1}^{\\tilde{X}}$.  \n",
    " \n",
    " For more details on the random-Lipschitz partition of Yair Bartal, see this [well-written blog post](https://nickhar.wordpress.com/2012/03/26/lecture-22-random-partitions-of-metric-spaces/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Random Partition Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use $\\Delta_{in} = Q_{q}\\left(\\Delta(\\mathbb{X})\\right)$ where $\\Delta(\\mathbb{X})$ is the vector of (Euclidean) distances between the given data-points, $q \\in (0,1)$ is a hyper-parameter, and $Q$ is the empirical quantile function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Lipschitz_Partioner(Min_data_size_percentage,q_in, X_train_in,y_train_in, CV_folds_failsafe, min_size):\n",
    "       \n",
    "    #-----------------------#\n",
    "    # Reset Seed Internally #\n",
    "    #-----------------------#\n",
    "    random.seed(2020)\n",
    "    np.random.seed(2020)\n",
    "\n",
    "    #-------------------------------------------#\n",
    "    #-------------------------------------------#\n",
    "    # 1) Sample radius from unifom distribution #\n",
    "    #-------------------------------------------#\n",
    "    #-------------------------------------------#\n",
    "    alpha = np.random.uniform(low=.25,high=.5,size=1)[0]\n",
    "\n",
    "    #-------------------------------------#\n",
    "    #-------------------------------------#\n",
    "    # 2) Apply Random Bijection (Shuffle) #\n",
    "    #-------------------------------------#\n",
    "    #-------------------------------------#\n",
    "    X_train_in_shuffled = X_train_in#.sample(frac=1)\n",
    "    y_train_in_shuffled = y_train_in#.sample(frac=1)\n",
    "\n",
    "    #--------------------#\n",
    "    #--------------------#\n",
    "    # X) Initializations #\n",
    "    #--------------------#\n",
    "    #--------------------#\n",
    "    # Compute-data-driven radius\n",
    "    Delta_X = distance_matrix(X_train_in_shuffled,X_train_in_shuffled)[::,0]\n",
    "    # note this operation:',distance_matrix(X_train_in_shuffled,X_train_in_shuffled).shape)\n",
    "    print('size of Data driven radius:',Delta_X.shape)\n",
    "    Delta_in = np.quantile(Delta_X,q_in)\n",
    "\n",
    "    # Initialize Random Radius\n",
    "    rand_radius = Delta_in*alpha\n",
    "\n",
    "    # Initialize Data_sizes & ratios\n",
    "    N_tot = X_train_in.shape[0] #<- Total number of data-points in input data-set!\n",
    "    N_radios = np.array([])\n",
    "    N_pool_train_loop = N_tot\n",
    "    # Initialize List of Dataframes\n",
    "    X_internal_train_list = list()\n",
    "    y_internal_train_list = list()\n",
    "\n",
    "    # Initialize Partioned Data-pool\n",
    "    X_internal_train_pool = X_train_in_shuffled\n",
    "    y_internal_train_pool = y_train_in_shuffled\n",
    "\n",
    "    # Initialize counter \n",
    "    part_current_loop = 0\n",
    "\n",
    "    #----------------------------#\n",
    "    #----------------------------#\n",
    "    # 3) Iteratively Build Parts #\n",
    "    #----------------------------#\n",
    "    #----------------------------#\n",
    "\n",
    "    while ((N_pool_train_loop/N_tot > Min_data_size_percentage) or (X_internal_train_pool.empty == False)):\n",
    "        # Extract Current Center\n",
    "        center_loop = X_internal_train_pool.iloc[0]\n",
    "        # Compute Distances\n",
    "        ## Training\n",
    "        distances_pool_loop_train = X_internal_train_pool.sub(center_loop)\n",
    "        distances_pool_loop_train = np.array(np.sqrt(np.square(distances_pool_loop_train).sum(axis=1)))\n",
    "        # Evaluate which Distances are less than the given random radius\n",
    "        Part_train_loop = X_internal_train_pool[distances_pool_loop_train<rand_radius]\n",
    "        Part_train_loop_y = y_internal_train_pool[distances_pool_loop_train<rand_radius]\n",
    "\n",
    "        # Remove all data-points which are \"too small\"\n",
    "        if X_internal_train_pool.shape[0] > max(CV_folds,4):\n",
    "            # Append Current part to list\n",
    "            X_internal_train_list.append(Part_train_loop)\n",
    "            y_internal_train_list.append(Part_train_loop_y)\n",
    "\n",
    "        # Remove current part from pool \n",
    "        X_internal_train_pool = X_internal_train_pool[(np.logical_not(distances_pool_loop_train<rand_radius))]\n",
    "        y_internal_train_pool = y_internal_train_pool[(np.logical_not(distances_pool_loop_train<rand_radius))]\n",
    "\n",
    "        # Update Current size of pool of training data\n",
    "        N_pool_train_loop = X_internal_train_pool.shape[0]\n",
    "        N_radios = np.append(N_radios,(N_pool_train_loop/N_tot))\n",
    "\n",
    "        # Update Counter\n",
    "        part_current_loop = part_current_loop +1\n",
    "        \n",
    "        # Update User\n",
    "        print('pool train loop percentage:',(N_pool_train_loop/N_tot))\n",
    "\n",
    "\n",
    "    # Post processing #\n",
    "    #-----------------#\n",
    "    # Remove Empty Partitions\n",
    "    N_radios = N_radios[N_radios>0]\n",
    "    \n",
    "    \n",
    "    #-----------------------------------------------------------------#\n",
    "    # Combine parts which are too small to perform CV without an error\n",
    "    #-----------------------------------------------------------------#\n",
    "    # Initialize lists (partitions) with \"enough\" datums per part\n",
    "    X_internal_train_list_good = list()\n",
    "    y_internal_train_list_good = list()\n",
    "    X_small_parts = list()\n",
    "    y_small_parts = list()\n",
    "    # Initialize first list item test\n",
    "    is_first = True\n",
    "    # Initialize counter\n",
    "    goods_counter = 0\n",
    "    for search_i in range(len(X_internal_train_list)):\n",
    "        number_of_instances_in_part = len(X_internal_train_list[search_i]) \n",
    "        if number_of_instances_in_part < max(CV_folds_failsafe,min_size):\n",
    "            # Check if first \n",
    "            if is_first:\n",
    "                # Initialize set of small X_parts\n",
    "                X_small_parts = X_internal_train_list[search_i]\n",
    "                # Initialize set of small y_parts\n",
    "                y_small_parts = y_internal_train_list[search_i]\n",
    "\n",
    "                # Set is_first to false\n",
    "                is_first = False\n",
    "            else:\n",
    "                X_small_parts = X_small_parts.append(X_internal_train_list[search_i])\n",
    "                #y_small_parts = np.append(y_small_parts,y_internal_train_list[search_i])\n",
    "                y_small_parts = y_small_parts.append(y_internal_train_list[search_i])\n",
    "        else:\n",
    "            # Append to current list\n",
    "            X_internal_train_list_good.append(X_internal_train_list[search_i])\n",
    "            y_internal_train_list_good.append(y_internal_train_list[search_i])\n",
    "            # Update goods counter \n",
    "            goods_counter = goods_counter +1\n",
    "\n",
    "    # Append final one to good list\n",
    "    X_internal_train_list_good.append(X_small_parts)\n",
    "    y_internal_train_list_good.append(y_small_parts)\n",
    "\n",
    "    # reset is_first to false (inscase we want to re-run this particular block)\n",
    "    is_first = True\n",
    "\n",
    "    # Set good lists to regular lists\n",
    "    X_internal_train_list = X_internal_train_list_good\n",
    "    y_internal_train_list = y_internal_train_list_good\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Return Value #\n",
    "    #--------------#\n",
    "    return [X_internal_train_list, y_internal_train_list, N_radios]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Random Partitioner to the given Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "partitioning_time_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Option_Function == 'SnP':\n",
    "    q_in_auto = .8\n",
    "    Min_data_size_percentage_auto = .1\n",
    "    min_size_part = 100\n",
    "else:\n",
    "    if Option_Function == 'crypto':\n",
    "        q_in_auto = .99\n",
    "        Min_data_size_percentage_auto = .3\n",
    "        min_size_part = 100\n",
    "    if Option_Function == 'Motivational_Example':\n",
    "        q_in_auto = .5\n",
    "        Min_data_size_percentage_auto = .5\n",
    "        min_size_part = 10\n",
    "        # Partition Based on Y\n",
    "        holder_temp = data_y\n",
    "        data_y = X_train\n",
    "        X_train = holder_temp\n",
    "    if Option_Function == 'lorenz':\n",
    "        q_in_auto = .5\n",
    "        Min_data_size_percentage_auto = .5\n",
    "        min_size_part = 15000\n",
    "    else:\n",
    "        q_in_auto = .5\n",
    "        Min_data_size_percentage_auto = .3\n",
    "        min_size_part = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of Data driven radius: (43199,)\n",
      "pool train loop percentage: 0.9865274659135628\n",
      "pool train loop percentage: 0.9626843213963286\n",
      "pool train loop percentage: 0.9397902729229843\n",
      "pool train loop percentage: 0.9251834533206788\n",
      "pool train loop percentage: 0.9134702192180375\n",
      "pool train loop percentage: 0.8999050903956111\n",
      "pool train loop percentage: 0.867913609111322\n",
      "pool train loop percentage: 0.33966064029259935\n",
      "pool train loop percentage: 0.2664413528090928\n",
      "pool train loop percentage: 0.0055093867913609115\n",
      "pool train loop percentage: 0.003935276279543508\n",
      "pool train loop percentage: 0.003009328919650918\n",
      "pool train loop percentage: 0.0018055973517905506\n",
      "pool train loop percentage: 0.0003009328919650918\n",
      "pool train loop percentage: 2.3148683997314753e-05\n",
      "pool train loop percentage: 0.0\n",
      "The_parts_listhe number of parts in the input are: 2.\n",
      "X_parts_list: [              x          y          z\n",
      "53    -6.839236 -11.119703  31.736388\n",
      "54    -7.228739 -10.750087  31.660895\n",
      "55    -7.545777 -10.376179  31.598310\n",
      "56    -7.796951 -10.000365  31.538519\n",
      "57    -7.988473  -9.625315  31.473230\n",
      "...         ...        ...        ...\n",
      "43194 -8.092295  -4.927387  30.282290\n",
      "43195 -7.780484  -4.714503  29.862659\n",
      "43196 -7.480086  -4.542631  29.425034\n",
      "43197 -7.193820  -4.409718  28.974508\n",
      "43198 -6.923939  -4.313410  28.515588\n",
      "\n",
      "[22820 rows x 3 columns],                x          y          z\n",
      "0       5.894076  -6.415820  -8.194456\n",
      "1       4.821934  -4.429324  -8.263782\n",
      "2       4.022918  -2.797976  -8.203039\n",
      "3       3.441617  -1.433997  -8.064589\n",
      "4       3.035476  -0.265226  -7.879283\n",
      "...          ...        ...        ...\n",
      "36024  -7.133620  15.368830  41.766037\n",
      "36846  -8.745221  12.623038  43.021892\n",
      "40033  -8.550749  12.040661  42.445774\n",
      "40834 -10.428636  13.210012  45.516945\n",
      "40835  -8.107880  14.581092  43.047755\n",
      "\n",
      "[20378 rows x 3 columns]]\n",
      "The_parts_listhe number of parts in the output are: 2.\n",
      "y_parts_list: [              x          y          z\n",
      "53    -7.228739 -10.750087  31.660895\n",
      "54    -7.545777 -10.376179  31.598310\n",
      "55    -7.796951 -10.000365  31.538519\n",
      "56    -7.988473  -9.625315  31.473230\n",
      "57    -8.126233  -9.253953  31.395850\n",
      "...         ...        ...        ...\n",
      "43194  8.863777   9.073592  27.197825\n",
      "43195  8.882687   9.050673  27.275690\n",
      "43196  8.897304   9.021341  27.350710\n",
      "43197  8.907440   8.985900  27.422011\n",
      "43198  8.912959   8.944733  27.488760\n",
      "\n",
      "[22820 rows x 3 columns],                x         y          z\n",
      "0       4.821934 -4.429324  -8.263782\n",
      "1       4.022918 -2.797976  -8.203039\n",
      "2       3.441617 -1.433997  -8.064589\n",
      "3       3.035476 -0.265226  -7.879283\n",
      "4       2.772190  0.767175  -7.664677\n",
      "...          ...       ...        ...\n",
      "36024  -8.532483  5.053128  38.584164\n",
      "36846   6.071259  1.200728  32.845977\n",
      "40033  11.761765  4.486235  37.771384\n",
      "40834  -5.206357  5.048127  34.144523\n",
      "40835  -4.219409  5.259560  33.006513\n",
      "\n",
      "[20378 rows x 3 columns]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize Number of Parts currently generated\n",
    "N_parts_generated = 0\n",
    "\n",
    "# Generate Partition (with option to regenerate if only 1 part is randomly produced)\n",
    "while N_parts_generated < 2:\n",
    "    # Generate Parts\n",
    "    X_parts_list, y_parts_list, N_ratios = Random_Lipschitz_Partioner(Min_data_size_percentage=Min_data_size_percentage_auto, \n",
    "                                                                      q_in=q_in_auto, \n",
    "                                                                      X_train_in=X_train, \n",
    "                                                                      y_train_in=data_y, \n",
    "                                                                      CV_folds_failsafe=CV_folds,\n",
    "                                                                      min_size = min_size_part)\n",
    "    \n",
    "    # Update Number of Parts\n",
    "    N_parts_generated = len(X_parts_list)\n",
    "    # Shuffle hyperparameters\n",
    "    Min_data_size_percentage_auto = (Min_data_size_percentage_auto + random.uniform(0,.3)) % 1\n",
    "    q_in_auto = (q_in_auto + random.uniform(0,.3)) % 1\n",
    "    \n",
    "    # Update User\n",
    "    print('The_parts_listhe number of parts in the input are: ' + str(len(X_parts_list))+'.')\n",
    "    print('X_parts_list:', X_parts_list)\n",
    "    print('The_parts_listhe number of parts in the output are: ' + str(len(y_parts_list))+'.')\n",
    "    print('y_parts_list:', y_parts_list)\n",
    "    \n",
    "# Trash removal (removes empty parts)\n",
    "X_parts_list = list(filter(([]).__ne__, X_parts_list))\n",
    "y_parts_list = list(filter(([]).__ne__, y_parts_list))\n",
    "    \n",
    "    \n",
    "# ICML Rebuttle Deadline = Coersion!\n",
    "if Option_Function == 'Motivational_Example':\n",
    "    # Flipback After Partitioning Based on Y (since code was made for partitioning in X!)\n",
    "    holder_temp = data_y\n",
    "    data_y = X_train\n",
    "    X_train = holder_temp\n",
    "    holder_temp = y_parts_list\n",
    "    y_parts_list = X_parts_list\n",
    "    X_parts_list = holder_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iteration_Length = len(X_parts_list)\n",
    "#N_modify = []\n",
    "#for jj in range(Iteration_Length):\n",
    " #   N_modify = np.append(N_modify,(len(X_parts_list[jj])))\n",
    "    \n",
    "#print(N_modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitioning_time = time.time() - partitioning_time_begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The_parts_listhe number of parts are: 2.\n"
     ]
    }
   ],
   "source": [
    "print('The_parts_listhe number of parts are: ' + str(len(X_parts_list))+'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Training Predictions on each part (each part represent a different manifold) and Train the Deep Classifier\n",
    "- Train locally (on each \"naive part\" and after on each \"trained part\")\n",
    "- Generate predictions for (full) training and testings sets respectively, to be used in training the classifer and for prediction, respectively.  \n",
    "- Generate predictions on all of testing-set (will be selected between later using classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs for training interaction: 0\n",
      " \n",
      " \n",
      " \n",
      "----------------------------------------------------\n",
      "---------- Train each FFNN on each part ------------\n",
      "---------------- Deep  Classifier ------------------\n",
      "----------------------------------------------------\n",
      " \n",
      " \n",
      " \n",
      "[0.5282652 0.4717348]\n",
      "param_grid_Vanilla_Nets - input dim: [3]\n",
      "param_grid_Vanilla_Nets - output dim: [3]\n",
      "Status: Current part: 0 out of : 2 parts.\n",
      "Heights to iterate over: [30, 3, 3, 30]\n",
      "TYPE y_train: <class 'pandas.core.frame.DataFrame'>\n",
      "height: [30, 3, 3, 30]\n",
      "height1: 30 height2: 3 height3: 3\n",
      "INPUT LAYER: Tensor(\"input_1:0\", shape=(None, 3), dtype=float32) <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Y_TRAIN: [[ 4.82193361 -4.42932378 -8.2637822 ]\n",
      " [ 4.02291799 -2.79797594 -8.20303867]\n",
      " [ 3.44161713 -1.43399725 -8.06458898]\n",
      " ...\n",
      " [ 8.8973036   9.0213413  27.35070993]\n",
      " [ 8.90743987  8.98589956 27.42201135]\n",
      " [ 8.9129585   8.94473304 27.48875975]] <class 'numpy.ndarray'>\n",
      "WARNING:tensorflow:From /home/lenci/Documents/venv3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "CHECK 1 CHECK 1 ####################\n",
      "Train on 22820 samples\n",
      "Epoch 1/50\n",
      "22820/22820 [==============================] - 2s 82us/sample - loss: 9.4419 - mse: 142.6551 - mae: 9.4419 - mape: 143.0885\n",
      "Epoch 2/50\n",
      "22820/22820 [==============================] - 2s 69us/sample - loss: 9.1965 - mse: 134.7407 - mae: 9.1965 - mape: 137.8762\n",
      "Epoch 3/50\n",
      "22820/22820 [==============================] - 2s 69us/sample - loss: 9.1895 - mse: 134.8294 - mae: 9.1895 - mape: 139.4038\n",
      "Epoch 4/50\n",
      "22820/22820 [==============================] - 2s 74us/sample - loss: 9.1752 - mse: 134.5006 - mae: 9.1752 - mape: 140.0738\n",
      "Epoch 5/50\n",
      "22820/22820 [==============================] - 2s 69us/sample - loss: 9.1627 - mse: 134.3683 - mae: 9.1627 - mape: 145.0116\n",
      "Epoch 6/50\n",
      "22820/22820 [==============================] - 2s 70us/sample - loss: 9.1640 - mse: 134.4596 - mae: 9.1640 - mape: 141.6703\n",
      "Epoch 7/50\n",
      "22820/22820 [==============================] - 1s 62us/sample - loss: 9.1603 - mse: 134.4882 - mae: 9.1603 - mape: 145.1133\n",
      "Epoch 8/50\n",
      "22820/22820 [==============================] - 1s 61us/sample - loss: 9.1577 - mse: 134.5444 - mae: 9.1577 - mape: 143.7283\n",
      "Epoch 9/50\n",
      "22820/22820 [==============================] - 1s 58us/sample - loss: 9.1650 - mse: 134.4666 - mae: 9.1650 - mape: 141.5618\n",
      "Epoch 10/50\n",
      "22820/22820 [==============================] - 1s 64us/sample - loss: 9.1581 - mse: 134.4509 - mae: 9.1581 - mape: 141.4713\n",
      "Epoch 11/50\n",
      "22820/22820 [==============================] - 1s 54us/sample - loss: 9.1617 - mse: 134.4590 - mae: 9.1617 - mape: 144.8801\n",
      "Epoch 12/50\n",
      "22820/22820 [==============================] - 1s 53us/sample - loss: 9.1557 - mse: 134.4977 - mae: 9.1557 - mape: 140.9008\n",
      "Epoch 13/50\n",
      "22820/22820 [==============================] - 1s 61us/sample - loss: 9.1765 - mse: 134.7045 - mae: 9.1765 - mape: 135.1240\n",
      "Epoch 14/50\n",
      "22820/22820 [==============================] - 1s 56us/sample - loss: 9.1728 - mse: 134.5468 - mae: 9.1728 - mape: 136.4814\n",
      "Epoch 15/50\n",
      "22820/22820 [==============================] - 1s 61us/sample - loss: 9.1729 - mse: 134.5767 - mae: 9.1729 - mape: 140.2907\n",
      "Epoch 16/50\n",
      "22820/22820 [==============================] - 1s 62us/sample - loss: 9.1658 - mse: 134.5210 - mae: 9.1658 - mape: 140.8767\n",
      "Epoch 17/50\n",
      "22820/22820 [==============================] - 1s 58us/sample - loss: 9.1545 - mse: 134.3139 - mae: 9.1545 - mape: 142.8687\n",
      "Epoch 18/50\n",
      "22820/22820 [==============================] - 1s 57us/sample - loss: 9.1523 - mse: 134.4607 - mae: 9.1523 - mape: 142.4603\n",
      "Epoch 19/50\n",
      "22820/22820 [==============================] - 1s 63us/sample - loss: 9.1523 - mse: 134.3934 - mae: 9.1523 - mape: 143.0848\n",
      "Epoch 20/50\n",
      "22820/22820 [==============================] - 1s 56us/sample - loss: 9.1531 - mse: 134.4569 - mae: 9.1531 - mape: 144.4494\n",
      "Epoch 21/50\n",
      "22820/22820 [==============================] - 1s 56us/sample - loss: 9.1490 - mse: 134.4398 - mae: 9.1490 - mape: 144.8421\n",
      "Epoch 22/50\n",
      "22820/22820 [==============================] - 1s 57us/sample - loss: 9.1572 - mse: 134.4411 - mae: 9.1572 - mape: 141.5167\n",
      "Epoch 23/50\n",
      "22820/22820 [==============================] - 1s 57us/sample - loss: 9.1488 - mse: 134.5028 - mae: 9.1488 - mape: 147.7678\n",
      "Epoch 24/50\n",
      "22820/22820 [==============================] - 2s 70us/sample - loss: 9.1483 - mse: 134.3997 - mae: 9.1483 - mape: 141.9923\n",
      "Epoch 25/50\n",
      "22820/22820 [==============================] - 2s 70us/sample - loss: 9.1484 - mse: 134.4087 - mae: 9.1484 - mape: 143.0049\n",
      "Epoch 26/50\n",
      "22820/22820 [==============================] - 2s 72us/sample - loss: 9.1484 - mse: 134.4950 - mae: 9.1484 - mape: 145.3959\n",
      "Epoch 27/50\n",
      "22820/22820 [==============================] - 2s 73us/sample - loss: 9.1472 - mse: 134.2931 - mae: 9.1472 - mape: 144.0222\n",
      "Epoch 28/50\n",
      "22820/22820 [==============================] - 2s 70us/sample - loss: 9.1495 - mse: 134.5479 - mae: 9.1495 - mape: 147.9538\n",
      "Epoch 29/50\n",
      "22820/22820 [==============================] - 2s 71us/sample - loss: 9.1528 - mse: 134.4539 - mae: 9.1528 - mape: 143.9482\n",
      "Epoch 30/50\n",
      "22820/22820 [==============================] - 2s 76us/sample - loss: 9.1501 - mse: 134.3652 - mae: 9.1501 - mape: 144.1875\n",
      "Epoch 31/50\n",
      "22820/22820 [==============================] - 2s 67us/sample - loss: 9.1472 - mse: 134.3821 - mae: 9.1472 - mape: 144.0754\n",
      "Epoch 32/50\n",
      "22820/22820 [==============================] - 2s 72us/sample - loss: 9.1398 - mse: 134.3197 - mae: 9.1398 - mape: 145.1688\n",
      "Epoch 33/50\n",
      "22820/22820 [==============================] - 2s 77us/sample - loss: 9.1518 - mse: 134.4243 - mae: 9.1518 - mape: 145.2450\n",
      "Epoch 34/50\n",
      "22820/22820 [==============================] - 2s 79us/sample - loss: 9.1413 - mse: 134.4350 - mae: 9.1413 - mape: 147.5332\n",
      "Epoch 35/50\n",
      "22820/22820 [==============================] - 1s 64us/sample - loss: 9.1490 - mse: 134.5035 - mae: 9.1490 - mape: 144.1667\n",
      "Epoch 36/50\n",
      "22820/22820 [==============================] - 1s 65us/sample - loss: 9.1446 - mse: 134.3949 - mae: 9.1446 - mape: 149.3237\n",
      "Epoch 37/50\n",
      "22820/22820 [==============================] - 1s 60us/sample - loss: 9.1388 - mse: 134.3186 - mae: 9.1388 - mape: 144.4690\n",
      "Epoch 38/50\n",
      "22820/22820 [==============================] - 1s 62us/sample - loss: 9.1428 - mse: 134.4246 - mae: 9.1428 - mape: 149.5085\n",
      "Epoch 39/50\n",
      "22820/22820 [==============================] - 2s 67us/sample - loss: 9.1403 - mse: 134.4665 - mae: 9.1403 - mape: 147.6933\n",
      "Epoch 40/50\n",
      "22820/22820 [==============================] - 1s 59us/sample - loss: 9.1427 - mse: 134.3220 - mae: 9.1427 - mape: 146.6373\n",
      "Epoch 41/50\n",
      "22820/22820 [==============================] - 1s 55us/sample - loss: 9.1383 - mse: 134.2352 - mae: 9.1383 - mape: 145.2266\n",
      "Epoch 42/50\n",
      "22820/22820 [==============================] - 2s 68us/sample - loss: 9.1368 - mse: 134.2741 - mae: 9.1367 - mape: 146.7822\n",
      "Epoch 43/50\n",
      "22820/22820 [==============================] - 1s 61us/sample - loss: 9.1471 - mse: 134.5587 - mae: 9.1471 - mape: 146.1926\n",
      "Epoch 44/50\n",
      "22820/22820 [==============================] - 1s 58us/sample - loss: 9.1377 - mse: 134.2932 - mae: 9.1377 - mape: 143.9231\n",
      "Epoch 45/50\n",
      "22820/22820 [==============================] - 1s 64us/sample - loss: 9.1388 - mse: 134.4306 - mae: 9.1389 - mape: 145.8157\n",
      "Epoch 46/50\n",
      "22820/22820 [==============================] - 1s 63us/sample - loss: 9.1363 - mse: 134.2946 - mae: 9.1363 - mape: 148.3675\n",
      "Epoch 47/50\n",
      "22820/22820 [==============================] - 1s 60us/sample - loss: 9.1368 - mse: 134.4155 - mae: 9.1368 - mape: 147.1915\n",
      "Epoch 48/50\n",
      "22820/22820 [==============================] - 2s 70us/sample - loss: 9.1360 - mse: 134.2965 - mae: 9.1360 - mape: 144.2499\n",
      "Epoch 49/50\n",
      "22820/22820 [==============================] - 1s 59us/sample - loss: 9.1366 - mse: 134.5834 - mae: 9.1366 - mape: 146.4308\n",
      "Epoch 50/50\n",
      "22820/22820 [==============================] - 2s 71us/sample - loss: 9.1357 - mse: 134.5597 - mae: 9.1357 - mape: 152.3192\n",
      "EPOCHS 50\n",
      "weights layer: []\n",
      "weights layer: [array([[ 0.5873671 ,  0.5313786 ,  0.8486863 ,  0.4169838 ,  0.3860699 ,\n",
      "         0.4600118 ,  0.5165351 ,  0.45991325,  0.39966556,  0.69001734,\n",
      "         0.09778348,  0.4291271 ,  0.1667514 ,  0.13334571,  0.59620154,\n",
      "         0.6290837 ,  0.45654127,  0.4709876 , -3.0822394 ,  0.5784519 ,\n",
      "         3.846006  ,  0.5892024 ,  0.63408184,  0.12041046,  1.0268066 ,\n",
      "         0.14323464,  0.5967053 ,  0.3707764 ,  0.4761424 ,  0.4833403 ],\n",
      "       [ 0.5385828 , -0.43700695,  1.1104803 , -0.17711549,  0.6916286 ,\n",
      "         0.5261876 ,  0.5752284 ,  0.72041684,  0.2574136 ,  0.84649414,\n",
      "         0.85035914,  0.14603357,  0.7292606 ,  0.24663775,  0.12536944,\n",
      "         0.9875565 ,  0.15335943,  0.82181716,  1.1033905 ,  0.65803605,\n",
      "         2.7835548 ,  0.24304824,  0.528189  ,  0.4770867 ,  0.7790272 ,\n",
      "         0.8530644 ,  3.259506  ,  0.6524285 , -0.12258552,  0.6086368 ],\n",
      "       [-0.738446  , -0.8101915 , -0.8597211 , -0.47129616, -0.7630469 ,\n",
      "        -0.7604595 , -0.70702606, -0.7306186 , -0.7469039 , -0.8656559 ,\n",
      "        -0.6556522 , -0.9461086 , -0.7237783 , -0.29529247, -0.62830657,\n",
      "        -0.78940713, -1.0128206 , -0.8718818 , -0.36579144, -0.6961507 ,\n",
      "         0.03185099, -0.8887106 , -0.7311414 , -0.67117685, -0.4690364 ,\n",
      "        -0.8277267 ,  0.8153694 , -0.7424393 , -0.72161025, -0.81891847]],\n",
      "      dtype=float32), array([-0.55688345,  0.98662984, -0.5585512 ,  0.7203634 , -0.65456253,\n",
      "       -0.43936434, -0.34775466, -0.3597648 , -0.425953  , -0.35045862,\n",
      "       -1.097541  , -0.46269518, -0.93045783, -0.2799383 ,  0.24948241,\n",
      "       -0.39231703, -0.43739274, -0.26377633, -3.1539254 , -0.6343701 ,\n",
      "        0.52622736, -0.45018873, -0.40765703, -0.729324  , -1.2670395 ,\n",
      "       -0.9639026 ,  0.55392593, -0.5599523 , -0.46479583, -0.31953993],\n",
      "      dtype=float32)]\n",
      "weights layer: []\n",
      "weights layer: []\n",
      "weights layer: []\n",
      "weights layer: [array([[-1.04756832e+00, -7.33110905e-01, -8.45994234e-01],\n",
      "       [-3.52884650e-01, -5.58138084e+00, -1.17404312e-01],\n",
      "       [-7.51116216e-01, -8.14780354e-01, -3.99806798e-01],\n",
      "       [-5.05476492e-03, -5.14960718e+00, -1.30430564e-01],\n",
      "       [-1.67870790e-01, -2.08797947e-01, -5.73156357e-01],\n",
      "       [-1.37138367e-01,  2.73969263e-01, -1.37074769e-01],\n",
      "       [-1.16910291e+00, -6.34277940e-01, -1.26030111e+00],\n",
      "       [-1.55969903e-01,  1.83249220e-01, -7.19591379e-01],\n",
      "       [-3.21294218e-01, -4.83248681e-02, -3.68829161e-01],\n",
      "       [-7.25186884e-01, -4.67066467e-01,  3.30992788e-01],\n",
      "       [-5.15298665e-01, -3.06053907e-01, -7.21647263e-01],\n",
      "       [-1.70721185e+00, -1.61864817e+00, -1.15291595e+00],\n",
      "       [-2.41305724e-01,  1.05229415e-01, -5.40622711e-01],\n",
      "       [-6.03666842e-01,  8.94748271e-01, -4.97369081e-01],\n",
      "       [-2.21794933e-01, -9.77707803e-01, -1.24496245e+00],\n",
      "       [-4.52535391e-01,  2.68635094e-01,  3.35470229e-01],\n",
      "       [-1.81236672e+00, -1.67423010e+00, -9.29207444e-01],\n",
      "       [-1.57423806e+00, -1.74697745e+00, -4.53728050e-01],\n",
      "       [ 4.12361920e-01, -2.67873311e+00, -1.28143758e-01],\n",
      "       [-5.82550526e-01, -1.97030723e-01, -3.74542683e-01],\n",
      "       [-9.28450167e-01, -4.64922857e+00, -1.13904163e-01],\n",
      "       [-1.46942043e+00, -1.01155913e+00, -1.34991932e+00],\n",
      "       [-1.11487114e+00, -6.44856095e-01, -8.77607882e-01],\n",
      "       [-1.06011844e+00, -6.06544495e-01, -8.86487782e-01],\n",
      "       [ 4.25276496e-02, -3.76672566e-01, -2.57533878e-01],\n",
      "       [-5.93478009e-02, -2.49846026e-01, -5.22998989e-01],\n",
      "       [ 4.21210796e-01, -1.33616805e+00, -1.98260248e+00],\n",
      "       [-1.27925241e+00, -1.29402387e+00, -1.25778925e+00],\n",
      "       [-1.53250194e+00, -1.03983355e+00, -8.20724070e-01],\n",
      "       [-5.81024289e-01, -5.65668344e-01, -7.58374214e-01]], dtype=float32), array([-3.3530636, -3.920314 , -1.0181599], dtype=float32)]\n",
      "weights layer: []\n",
      "weights layer: []\n",
      "weights layer: []\n",
      "weights layer: [array([[ 0.00523593, -0.04804379,  0.29964113],\n",
      "       [-0.8502643 , -0.90945756,  2.2383225 ],\n",
      "       [ 0.18286458,  1.973076  ,  1.9103186 ]], dtype=float32), array([-0.01228365,  0.40153834,  0.21050435], dtype=float32)]\n",
      "weights layer: [array([[ 4.42421921e-02,  1.44692168e-01,  3.09845924e-01,\n",
      "        -1.01185746e-01, -6.78769723e-02,  2.23693866e-02,\n",
      "         1.03010565e-01,  2.82361060e-01,  1.63187578e-01,\n",
      "        -6.16598278e-02,  1.34416327e-01,  7.30432719e-02,\n",
      "        -1.54466666e-02,  1.13121057e-02,  3.14075015e-02,\n",
      "         6.45546019e-02,  1.15990832e-01,  2.95375707e-03,\n",
      "        -4.77672331e-02,  7.18002468e-02,  1.85601592e-01,\n",
      "        -2.89549142e-01,  2.88836122e-01, -2.89730132e-01,\n",
      "        -1.41160265e-02,  4.35473830e-01, -1.39423057e-01,\n",
      "        -1.07130624e-01,  1.23182684e-01,  4.94297713e-01],\n",
      "       [-3.28126028e-02,  2.98370808e-01,  1.65777951e-01,\n",
      "         3.64581883e-01, -1.21670226e-02,  1.26568321e-03,\n",
      "        -2.69413069e-02,  5.73453493e-02, -4.38934788e-02,\n",
      "        -2.28436247e-01,  1.63548723e-01, -1.76980451e-01,\n",
      "         4.19478640e-02,  1.97089277e-02, -3.78417224e-01,\n",
      "        -1.67371631e-01,  1.34310484e-01, -1.31810699e-02,\n",
      "         8.96665081e-02, -4.36118022e-02, -7.89895579e-02,\n",
      "         5.00710368e-01, -1.10144772e-01,  4.43046778e-01,\n",
      "        -4.91687655e-02,  5.46294034e-01,  8.91055286e-01,\n",
      "         6.13071546e-02,  2.18979418e-01,  1.90524042e+00],\n",
      "       [ 8.31924193e-03, -2.17925772e-01,  2.28799507e-02,\n",
      "        -2.91160345e-01,  2.94785295e-02, -4.40321135e-04,\n",
      "         9.00562014e-03, -1.13349995e-02,  7.23661995e-03,\n",
      "        -9.23578858e-01,  2.41205771e-03,  4.79908884e-01,\n",
      "         7.80417204e-01,  1.08650210e-03, -9.40159857e-02,\n",
      "        -1.21549353e-01,  4.22115484e-03, -1.33497827e-03,\n",
      "        -2.04579130e-01,  7.84476753e-03,  1.15210693e-02,\n",
      "        -4.98445332e-01, -1.14917299e-02, -8.73211086e-01,\n",
      "        -4.52952180e-03, -3.15845162e-01, -4.39559191e-01,\n",
      "        -6.04851451e-03,  3.64073403e-02, -4.17287499e-01]], dtype=float32), array([-2.5989092e-04, -1.3209109e+00, -1.2783198e+00, -1.3665332e+00,\n",
      "       -1.3308910e+00, -1.2769182e+00,  1.8987316e-03, -1.2655137e+00,\n",
      "        2.6834982e-03,  7.3193264e-01, -1.3025841e+00,  1.3164027e+00,\n",
      "        1.4022042e+00, -1.2772713e+00,  1.0123490e-02, -4.6996135e-02,\n",
      "       -1.2973255e+00, -1.2778422e+00, -1.3522191e+00,  2.4097380e-03,\n",
      "        4.9424060e-03, -1.9515617e-01, -1.2758303e+00, -1.8033880e+00,\n",
      "       -1.2825269e+00, -1.6330144e-01, -2.0794554e-01, -7.8859804e-03,\n",
      "       -1.2872548e+00, -9.3892150e-02], dtype=float32)]\n",
      "weights layer: []\n",
      "weights layer: []\n",
      "weights layer: []\n",
      "weights layer: [array([[ 1.3398445e-02, -3.9342674e-04,  1.1164409e-02],\n",
      "       [-4.6836805e-02,  2.7019003e-01, -4.6570058e+00],\n",
      "       [ 1.3471866e-01,  4.3082196e-01, -4.6652207e+00],\n",
      "       [-7.2068595e-03,  1.1857491e-01, -4.7987952e+00],\n",
      "       [-9.1665789e-02,  3.1172431e-01, -4.6587372e+00],\n",
      "       [ 8.5783489e-02,  5.9225768e-01, -4.5107536e+00],\n",
      "       [-2.5221144e-03,  8.5452050e-03,  4.9380041e-03],\n",
      "       [ 5.2187487e-02,  2.6586923e-01, -4.8249631e+00],\n",
      "       [-2.2635438e-02,  2.5258895e-02,  5.9137330e-03],\n",
      "       [-1.7660725e+00, -1.1134126e+00,  6.4504051e-01],\n",
      "       [-4.5728117e-02,  2.2018114e-01, -4.9008389e+00],\n",
      "       [ 3.1473622e-01,  5.3052610e-01,  1.0253767e+00],\n",
      "       [ 4.7829100e-01,  6.5551347e-01,  1.0933121e+00],\n",
      "       [-5.6086712e-02,  1.3723949e-01, -4.8985147e+00],\n",
      "       [-1.6426396e-01,  1.8684939e-01,  5.1989269e-02],\n",
      "       [-1.2157597e-01,  1.7942427e-01, -7.4157044e-02],\n",
      "       [ 6.8451837e-03,  4.3170702e-01, -4.6778150e+00],\n",
      "       [ 2.0558846e-01,  7.2738522e-01, -4.4785867e+00],\n",
      "       [ 8.5796833e-02,  3.2952380e-01, -4.5983610e+00],\n",
      "       [ 2.1897925e-03,  5.0443094e-03,  1.2398807e-02],\n",
      "       [-2.6250018e-02,  3.3201024e-02,  1.1924260e-02],\n",
      "       [ 6.2581666e-02,  5.8320938e-03, -4.6687115e-02],\n",
      "       [ 1.0556027e-01,  4.7012335e-01, -4.6486702e+00],\n",
      "       [ 9.2070681e-01,  1.6861402e+00, -3.9219406e+00],\n",
      "       [-1.0057209e-01,  1.5662019e-01, -4.8832402e+00],\n",
      "       [ 3.0377422e-02,  5.4435976e-02, -2.7459553e-01],\n",
      "       [ 2.2898106e-01, -8.3368772e-01, -1.6884904e-01],\n",
      "       [ 6.5826057e-03, -1.9514734e-03, -2.7713452e-02],\n",
      "       [ 2.6220541e-02,  3.8430354e-01, -4.6160049e+00],\n",
      "       [ 7.4751073e-01, -1.3970939e+00,  1.9848997e-02]], dtype=float32), array([0.16867313, 0.25520203, 4.5945444 ], dtype=float32)]\n",
      "y_train shape: (43199, 3)\n",
      "y_hat_train_full_loop shape: (43199, 3)\n",
      "y_test shape: (4800, 3)\n",
      "y_hat_test_full_loop shape: (4800, 3)\n",
      "training_quality shape: (43199, 3)\n",
      "param_grid_Vanilla_Nets - input dim: [3]\n",
      "param_grid_Vanilla_Nets - output dim: [3]\n",
      "Status: Current part: 1 out of : 2 parts.\n",
      "Heights to iterate over: [30, 3, 3, 30]\n",
      "TYPE y_train: <class 'pandas.core.frame.DataFrame'>\n",
      "height: [30, 3, 3, 30]\n",
      "height1: 30 height2: 3 height3: 3\n",
      "INPUT LAYER: Tensor(\"input_2:0\", shape=(None, 3), dtype=float32) <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Y_TRAIN: [[ 4.82193361 -4.42932378 -8.2637822 ]\n",
      " [ 4.02291799 -2.79797594 -8.20303867]\n",
      " [ 3.44161713 -1.43399725 -8.06458898]\n",
      " ...\n",
      " [ 8.8973036   9.0213413  27.35070993]\n",
      " [ 8.90743987  8.98589956 27.42201135]\n",
      " [ 8.9129585   8.94473304 27.48875975]] <class 'numpy.ndarray'>\n",
      "CHECK 1 CHECK 1 ####################\n",
      "Train on 20378 samples\n",
      "Epoch 1/50\n",
      "20378/20378 [==============================] - 2s 74us/sample - loss: 9.6391 - mse: 151.0035 - mae: 9.6391 - mape: 1181.0819\n",
      "Epoch 2/50\n",
      "20378/20378 [==============================] - 1s 70us/sample - loss: 9.2821 - mse: 138.3797 - mae: 9.2821 - mape: 202.1223\n",
      "Epoch 3/50\n",
      "20378/20378 [==============================] - 1s 63us/sample - loss: 9.2747 - mse: 138.1986 - mae: 9.2746 - mape: 314.6353\n",
      "Epoch 4/50\n",
      "20378/20378 [==============================] - 1s 63us/sample - loss: 9.2644 - mse: 137.7888 - mae: 9.2644 - mape: 291.6600\n",
      "Epoch 5/50\n",
      "20378/20378 [==============================] - 1s 62us/sample - loss: 9.2450 - mse: 137.3096 - mae: 9.2450 - mape: 241.6968\n",
      "Epoch 6/50\n",
      "20378/20378 [==============================] - 1s 63us/sample - loss: 9.2450 - mse: 137.0117 - mae: 9.2450 - mape: 1153.5656\n",
      "Epoch 7/50\n",
      "20378/20378 [==============================] - 2s 76us/sample - loss: 9.2304 - mse: 136.8129 - mae: 9.2304 - mape: 270.3938\n",
      "Epoch 8/50\n",
      "20378/20378 [==============================] - 1s 71us/sample - loss: 9.2320 - mse: 137.1740 - mae: 9.2320 - mape: 311.9792\n",
      "Epoch 9/50\n",
      "20378/20378 [==============================] - 1s 63us/sample - loss: 9.2269 - mse: 136.6539 - mae: 9.2269 - mape: 246.0982\n",
      "Epoch 10/50\n",
      "20378/20378 [==============================] - 1s 61us/sample - loss: 9.2188 - mse: 136.5091 - mae: 9.2188 - mape: 262.6976\n",
      "Epoch 11/50\n",
      "20378/20378 [==============================] - 1s 62us/sample - loss: 9.2205 - mse: 136.5443 - mae: 9.2205 - mape: 336.4155\n",
      "Epoch 12/50\n",
      "20378/20378 [==============================] - 1s 60us/sample - loss: 9.2251 - mse: 136.7508 - mae: 9.2251 - mape: 220.2166\n",
      "Epoch 13/50\n",
      "20378/20378 [==============================] - 1s 58us/sample - loss: 9.2285 - mse: 136.8085 - mae: 9.2285 - mape: 407.6310\n",
      "Epoch 14/50\n",
      "20378/20378 [==============================] - 1s 55us/sample - loss: 9.2339 - mse: 136.8036 - mae: 9.2339 - mape: 1040.1055\n",
      "Epoch 15/50\n",
      "20378/20378 [==============================] - 1s 63us/sample - loss: 9.2121 - mse: 136.5538 - mae: 9.2121 - mape: 354.6560\n",
      "Epoch 16/50\n",
      "20378/20378 [==============================] - 1s 60us/sample - loss: 9.2105 - mse: 136.4893 - mae: 9.2105 - mape: 451.4781\n",
      "Epoch 17/50\n",
      "20378/20378 [==============================] - 1s 62us/sample - loss: 9.2139 - mse: 136.5602 - mae: 9.2139 - mape: 964.8638\n",
      "Epoch 18/50\n",
      "20378/20378 [==============================] - 1s 64us/sample - loss: 9.2194 - mse: 136.7051 - mae: 9.2194 - mape: 1034.1469\n",
      "Epoch 19/50\n",
      "20378/20378 [==============================] - 1s 62us/sample - loss: 9.2110 - mse: 136.3380 - mae: 9.2110 - mape: 312.2680\n",
      "Epoch 20/50\n",
      "20378/20378 [==============================] - 1s 62us/sample - loss: 9.2044 - mse: 136.2390 - mae: 9.2044 - mape: 307.1873\n",
      "Epoch 21/50\n",
      "20378/20378 [==============================] - 1s 67us/sample - loss: 9.2089 - mse: 136.2204 - mae: 9.2089 - mape: 1110.8469\n",
      "Epoch 22/50\n",
      "20378/20378 [==============================] - 1s 65us/sample - loss: 9.2015 - mse: 136.3282 - mae: 9.2015 - mape: 441.6490\n",
      "Epoch 23/50\n",
      "20378/20378 [==============================] - 1s 67us/sample - loss: 9.2082 - mse: 136.3459 - mae: 9.2082 - mape: 319.8475\n",
      "Epoch 24/50\n",
      "20378/20378 [==============================] - 2s 76us/sample - loss: 9.1970 - mse: 136.3601 - mae: 9.1970 - mape: 299.3759\n",
      "Epoch 25/50\n",
      "20378/20378 [==============================] - 1s 64us/sample - loss: 9.2030 - mse: 136.7774 - mae: 9.2030 - mape: 372.1045\n",
      "Epoch 26/50\n",
      "20378/20378 [==============================] - 1s 62us/sample - loss: 9.1924 - mse: 136.0816 - mae: 9.1924 - mape: 300.6881\n",
      "Epoch 27/50\n",
      "20378/20378 [==============================] - 1s 59us/sample - loss: 9.1961 - mse: 136.2034 - mae: 9.1961 - mape: 311.2515\n",
      "Epoch 28/50\n",
      "20378/20378 [==============================] - 1s 63us/sample - loss: 9.1856 - mse: 135.6609 - mae: 9.1856 - mape: 331.6369\n",
      "Epoch 29/50\n",
      "20378/20378 [==============================] - 1s 63us/sample - loss: 9.2028 - mse: 136.5273 - mae: 9.2028 - mape: 787.1486\n",
      "Epoch 30/50\n",
      "20378/20378 [==============================] - 1s 66us/sample - loss: 9.1835 - mse: 135.9642 - mae: 9.1835 - mape: 642.7186\n",
      "Epoch 31/50\n",
      "20378/20378 [==============================] - 1s 68us/sample - loss: 9.1927 - mse: 136.1338 - mae: 9.1927 - mape: 1039.3743\n",
      "Epoch 32/50\n",
      "20378/20378 [==============================] - 1s 73us/sample - loss: 9.1785 - mse: 135.7346 - mae: 9.1785 - mape: 347.2789\n",
      "Epoch 33/50\n",
      "20378/20378 [==============================] - 1s 64us/sample - loss: 9.1874 - mse: 136.3366 - mae: 9.1874 - mape: 427.7591\n",
      "Epoch 34/50\n",
      "20378/20378 [==============================] - 1s 64us/sample - loss: 9.2153 - mse: 138.8749 - mae: 9.2153 - mape: 469.9795\n",
      "Epoch 35/50\n",
      "20378/20378 [==============================] - 1s 73us/sample - loss: 9.1848 - mse: 135.9448 - mae: 9.1848 - mape: 384.9873\n",
      "Epoch 36/50\n",
      "20378/20378 [==============================] - 1s 62us/sample - loss: 9.1939 - mse: 136.2337 - mae: 9.1939 - mape: 473.1559\n",
      "Epoch 37/50\n",
      "20378/20378 [==============================] - 1s 59us/sample - loss: 9.1955 - mse: 136.8464 - mae: 9.1955 - mape: 1151.7206\n",
      "Epoch 38/50\n",
      "20378/20378 [==============================] - 1s 60us/sample - loss: 9.1937 - mse: 136.1883 - mae: 9.1937 - mape: 1154.2766\n",
      "Epoch 39/50\n",
      "20378/20378 [==============================] - 1s 55us/sample - loss: 9.1860 - mse: 136.0757 - mae: 9.1860 - mape: 488.3337\n",
      "Epoch 40/50\n",
      "20378/20378 [==============================] - 1s 57us/sample - loss: 9.1803 - mse: 135.9102 - mae: 9.1803 - mape: 1173.7759\n",
      "Epoch 41/50\n",
      "20378/20378 [==============================] - 1s 57us/sample - loss: 9.1810 - mse: 135.8686 - mae: 9.1810 - mape: 1144.9542\n",
      "Epoch 42/50\n",
      "20378/20378 [==============================] - 1s 55us/sample - loss: 9.1718 - mse: 135.6862 - mae: 9.1718 - mape: 1007.2899\n",
      "Epoch 43/50\n",
      "20378/20378 [==============================] - 1s 56us/sample - loss: 9.1746 - mse: 136.2027 - mae: 9.1746 - mape: 480.1036\n",
      "Epoch 44/50\n",
      "20378/20378 [==============================] - 1s 61us/sample - loss: 9.1974 - mse: 136.3993 - mae: 9.1974 - mape: 1122.9487\n",
      "Epoch 45/50\n",
      "20378/20378 [==============================] - 1s 61us/sample - loss: 9.2020 - mse: 136.3559 - mae: 9.2020 - mape: 988.3032\n",
      "Epoch 46/50\n",
      "20378/20378 [==============================] - 1s 65us/sample - loss: 9.1812 - mse: 135.9475 - mae: 9.1812 - mape: 422.5485\n",
      "Epoch 47/50\n",
      "20378/20378 [==============================] - 1s 61us/sample - loss: 9.1850 - mse: 136.3408 - mae: 9.1850 - mape: 1158.0690\n",
      "Epoch 48/50\n",
      "20378/20378 [==============================] - 1s 69us/sample - loss: 9.1903 - mse: 136.2583 - mae: 9.1903 - mape: 1160.2262\n",
      "Epoch 49/50\n",
      "20378/20378 [==============================] - 1s 57us/sample - loss: 9.2126 - mse: 136.6223 - mae: 9.2126 - mape: 381.2960\n",
      "Epoch 50/50\n",
      "20378/20378 [==============================] - 1s 61us/sample - loss: 9.1772 - mse: 136.1306 - mae: 9.1772 - mape: 356.8116\n",
      "EPOCHS 50\n",
      "weights layer: []\n",
      "weights layer: [array([[ 1.8104676 , -0.20513181, -0.30437645, -0.47690445,  0.67755514,\n",
      "        -0.3662625 , -0.16130936,  2.101712  ,  0.01750377,  0.5297787 ,\n",
      "        -0.8183696 , -0.13748543, -0.273724  , -0.06616196, -0.36607385,\n",
      "         0.31167522, -0.28185767, -0.2914284 , -1.1978143 ,  0.6085591 ,\n",
      "        -0.2614332 , -1.3528863 , -0.10703253, -2.6242976 ,  0.1024758 ,\n",
      "         0.04014369, -0.17846759, -0.48408982, -0.53004175, -0.6266463 ],\n",
      "       [-1.1708319 , -0.24121028,  0.33080932,  0.32422587, -0.05532324,\n",
      "         0.35154083, -0.03254349, -0.6279292 ,  0.09882196, -0.48890612,\n",
      "         0.08784728,  0.0196235 , -0.23016462,  0.12140933,  0.77103156,\n",
      "         1.2547033 , -0.19488838, -0.31881508, -1.8896691 ,  0.45517525,\n",
      "        -0.22601408,  1.2624712 ,  0.07443611,  1.1534163 , -0.04207092,\n",
      "         1.093426  ,  1.0464864 , -0.07223924,  0.1633745 , -0.01370826],\n",
      "       [-0.32699963, -1.1423796 , -0.4546904 , -1.226583  , -0.5745853 ,\n",
      "        -1.1921451 , -0.71308744, -1.735477  , -0.8083744 , -1.0377069 ,\n",
      "        -0.71057236, -0.7211147 , -1.5742532 , -0.20829083, -1.0167673 ,\n",
      "        -0.73011094, -1.3120378 , -0.44802034, -1.9979498 , -1.0526128 ,\n",
      "        -1.4828652 , -1.4344908 , -0.79312545, -1.1768659 , -0.72370815,\n",
      "        -1.2397053 , -1.2891061 , -0.56301105, -0.98373127,  0.2013637 ]],\n",
      "      dtype=float32), array([-4.233877  , -4.970017  , -1.1775717 , -2.905912  , -2.3271947 ,\n",
      "       -4.0460963 , -3.0863302 ,  6.5192437 ,  0.14912714,  2.4731703 ,\n",
      "       -2.7152295 , -2.706311  , -3.299985  , -1.487504  , -1.2132381 ,\n",
      "       -1.3182195 , -2.6807559 , -2.4251864 , -1.6007973 , -0.25822827,\n",
      "       -3.3007092 ,  1.8833479 , -2.8009079 ,  5.876757  , -2.6324315 ,\n",
      "       -2.878019  , -4.9033628 , -3.0852318 , -2.4610133 , -2.7833238 ],\n",
      "      dtype=float32)]\n",
      "weights layer: []\n",
      "weights layer: []\n",
      "weights layer: []\n",
      "weights layer: [array([[ 1.19446754e-01, -1.25969946e-01, -1.86010778e-01],\n",
      "       [ 5.05878508e-01, -2.35396430e-01, -7.99351260e-02],\n",
      "       [ 4.48980659e-01, -6.85862601e-01, -2.82287455e+00],\n",
      "       [ 6.42584860e-01, -5.79762101e-01, -1.04422259e+00],\n",
      "       [ 2.29513526e+00,  4.31755990e-01, -1.51379362e-01],\n",
      "       [ 1.90104592e+00,  3.50655973e-01,  3.06072176e-01],\n",
      "       [-2.56696977e-02,  3.34631689e-02,  2.09031776e-01],\n",
      "       [-1.54617989e+00,  3.78033257e+00, -9.36174512e-01],\n",
      "       [-3.40906888e-01,  6.87211677e-02, -2.53966069e+00],\n",
      "       [-4.14074421e-01,  4.04783964e-01,  2.11970735e+00],\n",
      "       [ 6.17309570e-01, -3.61637510e-02, -8.87933195e-01],\n",
      "       [ 1.30175734e+00, -3.55881229e-02,  6.52204335e-01],\n",
      "       [-4.40400481e-01, -3.45652044e-01, -2.27250859e-01],\n",
      "       [ 1.61199534e+00,  1.99068204e-01, -2.14274049e+00],\n",
      "       [ 2.84950823e-01, -2.17629403e-01, -2.86884332e+00],\n",
      "       [-6.83923304e-01, -2.08942354e-01, -2.19502091e+00],\n",
      "       [ 1.45013356e+00, -9.80550110e-01, -6.68832064e-02],\n",
      "       [ 2.41879892e+00, -3.25787887e-02, -7.14256346e-01],\n",
      "       [-1.38541985e+00, -4.13721323e-01, -5.44408500e-01],\n",
      "       [-2.12696981e+00,  1.20945852e-02, -1.15915179e+00],\n",
      "       [-4.99546915e-01, -2.06834555e-01, -6.69903994e-01],\n",
      "       [-1.77055693e+00,  1.42365739e-01, -4.38368893e+00],\n",
      "       [ 1.02635193e+00, -1.57259271e-01,  7.75087774e-01],\n",
      "       [ 4.88465242e-02,  3.70869637e+00, -5.04118299e+00],\n",
      "       [ 5.86517870e-01,  6.61691418e-04,  3.91766518e-01],\n",
      "       [-2.36167264e+00,  3.22186857e-01, -9.89295363e-01],\n",
      "       [-2.49267983e+00, -7.10623920e-01, -1.52945489e-01],\n",
      "       [ 1.19522715e+00, -2.82934830e-02, -6.27480030e-01],\n",
      "       [-1.93891883e+00, -1.49876056e-02,  1.15165007e+00],\n",
      "       [ 1.10818319e-01, -3.83482724e-01, -1.83817670e-01]], dtype=float32), array([-3.6595361 ,  0.2256573 , -0.32531896], dtype=float32)]\n",
      "weights layer: []\n",
      "weights layer: []\n",
      "weights layer: []\n",
      "weights layer: [array([[-3.0864048 ,  3.7476914 ,  0.06873662],\n",
      "       [ 0.0732674 ,  0.38695076, -0.21736337],\n",
      "       [-0.3593663 ,  0.88813835,  1.641059  ]], dtype=float32), array([-0.39511746,  0.43387228,  0.19549179], dtype=float32)]\n",
      "weights layer: [array([[-0.121284  ,  0.18353781, -0.34500185, -0.1240551 ,  0.10076258,\n",
      "        -0.3606488 ,  0.44791088, -0.02971163,  0.5359146 , -0.04868054,\n",
      "        -0.5161392 , -0.35252678,  0.11046202,  0.62230676, -0.3756085 ,\n",
      "         0.8950393 ,  0.8716751 ,  0.9549488 ,  0.89505994,  0.7008586 ,\n",
      "        -0.4661249 ,  0.05109371, -0.26110658,  0.01747766, -0.3869138 ,\n",
      "         2.9789395 ,  0.6437294 , -0.03648463,  1.0229104 , -0.3470404 ],\n",
      "       [-0.7545804 , -0.4349346 , -0.8423049 , -0.27221173, -0.440138  ,\n",
      "        -0.42917374, -1.5051281 , -0.11986678, -0.6288297 , -0.2749841 ,\n",
      "         0.20454617, -0.8566943 , -0.6266746 , -0.69684964, -0.7779519 ,\n",
      "        -0.9059094 , -0.65858054, -0.32084417, -0.34848076, -0.9707949 ,\n",
      "        -0.5585653 , -0.5920166 , -0.73588073, -0.7481672 , -0.1031621 ,\n",
      "        -4.5699387 , -0.8805479 , -0.04360047, -1.4020364 , -0.84105504],\n",
      "       [-0.12842476, -0.26523355,  0.11382814,  0.14580938,  0.12853502,\n",
      "         0.16271965, -0.43862945,  0.17144918,  2.040154  ,  0.20190123,\n",
      "         2.0597677 , -0.01189547,  0.39698392, -0.22647358,  0.20095763,\n",
      "        -0.37410685, -0.17523524,  0.28398824,  0.3231154 , -0.3369329 ,\n",
      "         0.20472713,  0.30046868,  0.06695298,  0.45800993,  0.19657756,\n",
      "        -0.53106827, -0.33764046,  0.00628851, -0.66392756,  0.1236857 ]],\n",
      "      dtype=float32), array([-1.3947079 , -1.3167313 , -1.2868086 , -1.2291056 , -1.2324088 ,\n",
      "       -1.3587093 , -0.06308228, -1.2279725 , -1.0163907 , -1.1853331 ,\n",
      "        0.8478825 , -1.297831  ,  0.06822024,  1.010205  , -1.2967969 ,\n",
      "        0.61473   ,  0.3209264 ,  0.02808849,  0.06854878,  0.56760997,\n",
      "       -1.2844448 ,  0.07371321, -1.2743484 ,  0.08199416, -1.2850653 ,\n",
      "       -0.52063704,  0.7955645 , -1.0742785 ,  0.46720612, -1.2858055 ],\n",
      "      dtype=float32)]\n",
      "weights layer: []\n",
      "weights layer: []\n",
      "weights layer: []\n",
      "weights layer: [array([[ 0.30536863,  0.27973667, -4.8812027 ],\n",
      "       [ 0.09359024,  0.04408698, -4.585784  ],\n",
      "       [ 0.16434251,  0.12866406, -4.8648276 ],\n",
      "       [ 0.18076126,  0.19033702, -4.929896  ],\n",
      "       [ 0.07137734,  0.51486987, -4.4828734 ],\n",
      "       [ 0.13327062,  0.15448263, -4.47474   ],\n",
      "       [ 0.24793693,  0.40086755,  0.16899292],\n",
      "       [ 0.16395158,  0.10720691, -4.8752747 ],\n",
      "       [-0.95349735, -1.5257215 , -1.2005986 ],\n",
      "       [ 0.15806334,  0.0731706 , -4.542471  ],\n",
      "       [-0.17423144, -0.3082541 ,  1.0491354 ],\n",
      "       [ 0.18843831,  0.2743846 , -4.8260727 ],\n",
      "       [ 0.12495137, -0.30820417, -0.06615739],\n",
      "       [ 0.604026  ,  0.47764027,  1.3091636 ],\n",
      "       [ 0.37641856,  0.3839254 , -4.2000713 ],\n",
      "       [ 0.6895308 ,  0.4638664 ,  0.7042908 ],\n",
      "       [ 0.50861156,  0.1768544 ,  0.24675901],\n",
      "       [ 0.16080922, -0.04999495, -0.26256052],\n",
      "       [ 0.16027269, -0.09563235, -0.19857293],\n",
      "       [ 0.6286991 ,  0.41007993,  0.6820034 ],\n",
      "       [ 0.37929237,  0.36673865, -4.930733  ],\n",
      "       [ 0.08386523, -0.21419081, -0.05651185],\n",
      "       [ 0.24478473,  0.3123697 , -4.7629204 ],\n",
      "       [ 0.07092026, -0.28637627, -0.05097435],\n",
      "       [ 0.24298574,  0.30625075, -4.2258954 ],\n",
      "       [-0.56760544,  0.19283871,  1.9821446 ],\n",
      "       [ 0.62112564,  0.49160108,  1.0269278 ],\n",
      "       [ 0.10403131,  0.11713417, -4.67881   ],\n",
      "       [ 0.90682805,  0.5748942 ,  0.18011041],\n",
      "       [ 0.09579638,  0.20387748, -4.818478  ]], dtype=float32), array([-0.6721533 ,  0.00845694,  4.9410577 ], dtype=float32)]\n",
      "y_train shape: (43199, 3)\n",
      "y_hat_train_full_loop shape: (43199, 3)\n",
      "y_test shape: (4800, 3)\n",
      "y_hat_test_full_loop shape: (4800, 3)\n",
      "y_hat_train_loop shape: (43199, 3)\n",
      "predictions_train shape: (43199, 3, 2)\n",
      "y_hat_test_loop shape: (4800, 3)\n",
      "predictions_test shape: (4800, 3, 2)\n",
      "prediction_errors shape: (43199, 3)\n",
      "training_quality shape: (43199, 3, 2)\n",
      " \n",
      " \n",
      " \n",
      "----------------------------------------------------\n",
      "Feature Generation (Learning Phase): Score Generated\n",
      "----------------------------------------------------\n",
      " \n",
      " \n",
      " \n",
      "Time-Elapsed Training on Each Part: 142.433025598526\n",
      " \n",
      " \n",
      " \n",
      "----------------------------------------------------\n",
      "---------------- Train Classifier ------------------\n",
      "---------------- Deep  Classifier ------------------\n",
      "----------------------------------------------------\n",
      " \n",
      " \n",
      " \n",
      "partition_labels_training_integers shape: (43199,)\n",
      "partition_labels_training_integers: [1 1 1 ... 0 0 1]\n",
      "partition_labels_training shape: (43199, 1)\n",
      "partition_labels_training:            0\n",
      "0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "...      ...\n",
      "43194   True\n",
      "43195   True\n",
      "43196   True\n",
      "43197   True\n",
      "43198  False\n",
      "\n",
      "[43199 rows x 1 columns]\n",
      "partition_labels_training_new shape: (43199, 3, 2)\n",
      "partition_labels_training_new: [[[0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]]\n",
      "\n",
      " [[0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]]\n",
      "\n",
      " [[0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1. 0.]\n",
      "  [1. 0.]\n",
      "  [1. 0.]]\n",
      "\n",
      " [[1. 0.]\n",
      "  [1. 0.]\n",
      "  [1. 0.]]\n",
      "\n",
      " [[0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]]]\n",
      "Re-Load Grid and Redefine Relevant Input/Output dimensions in dictionary\n",
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "input_dim: 3\n",
      "output_dim: 2\n",
      "# epochs: [100]\n",
      "---- Train Deep Classifier ----\n",
      "Train on 43199 samples\n",
      "Epoch 1/100\n",
      "43199/43199 [==============================] - 5s 123us/sample - loss: 0.4568 - mse: 0.4079 - mae: 0.4568 - mape: 228767728.0000\n",
      "Epoch 2/100\n",
      "43199/43199 [==============================] - 5s 127us/sample - loss: 0.4509 - mse: 0.4272 - mae: 0.4509 - mape: 225426832.0000\n",
      "Epoch 3/100\n",
      "43199/43199 [==============================] - 5s 124us/sample - loss: 0.4501 - mse: 0.4355 - mae: 0.4501 - mape: 225812624.0000\n",
      "Epoch 4/100\n",
      "43199/43199 [==============================] - 5s 125us/sample - loss: 0.4481 - mse: 0.4383 - mae: 0.4481 - mape: 224006240.0000\n",
      "Epoch 5/100\n",
      "43199/43199 [==============================] - 5s 124us/sample - loss: 0.4478 - mse: 0.4367 - mae: 0.4478 - mape: 223541232.0000\n",
      "Epoch 6/100\n",
      "43199/43199 [==============================] - 5s 124us/sample - loss: 0.4463 - mse: 0.4380 - mae: 0.4463 - mape: 223066896.0000\n",
      "Epoch 7/100\n",
      "43199/43199 [==============================] - 5s 124us/sample - loss: 0.4461 - mse: 0.4373 - mae: 0.4461 - mape: 222913728.0000\n",
      "Epoch 8/100\n",
      "43199/43199 [==============================] - 6s 131us/sample - loss: 0.4446 - mse: 0.4330 - mae: 0.4446 - mape: 222935360.0000\n",
      "Epoch 9/100\n",
      "43199/43199 [==============================] - 6s 133us/sample - loss: 0.4442 - mse: 0.4321 - mae: 0.4442 - mape: 220783376.0000\n",
      "Epoch 10/100\n",
      "43199/43199 [==============================] - 6s 133us/sample - loss: 0.4421 - mse: 0.4307 - mae: 0.4421 - mape: 220869616.0000\n",
      "Epoch 11/100\n",
      "43199/43199 [==============================] - 6s 129us/sample - loss: 0.4422 - mse: 0.4307 - mae: 0.4422 - mape: 221704896.0000\n",
      "Epoch 12/100\n",
      "43199/43199 [==============================] - 5s 125us/sample - loss: 0.4420 - mse: 0.4309 - mae: 0.4420 - mape: 221094576.0000\n",
      "Epoch 13/100\n",
      "43199/43199 [==============================] - 6s 134us/sample - loss: 0.4429 - mse: 0.4348 - mae: 0.4429 - mape: 221165136.0000\n",
      "Epoch 14/100\n",
      "43199/43199 [==============================] - 6s 135us/sample - loss: 0.4434 - mse: 0.4344 - mae: 0.4434 - mape: 221851600.0000\n",
      "Epoch 15/100\n",
      "43199/43199 [==============================] - 6s 128us/sample - loss: 0.4415 - mse: 0.4339 - mae: 0.4415 - mape: 220480512.0000\n",
      "Epoch 16/100\n",
      "43199/43199 [==============================] - 5s 126us/sample - loss: 0.4409 - mse: 0.4334 - mae: 0.4409 - mape: 220604640.0000\n",
      "Epoch 17/100\n",
      "43199/43199 [==============================] - 5s 123us/sample - loss: 0.4420 - mse: 0.4342 - mae: 0.4420 - mape: 221922288.0000\n",
      "Epoch 18/100\n",
      "43199/43199 [==============================] - 5s 124us/sample - loss: 0.4422 - mse: 0.4349 - mae: 0.4422 - mape: 220691344.0000\n",
      "Epoch 19/100\n",
      "43199/43199 [==============================] - 5s 124us/sample - loss: 0.4412 - mse: 0.4353 - mae: 0.4412 - mape: 218091744.0000\n",
      "Epoch 20/100\n",
      "43199/43199 [==============================] - 5s 121us/sample - loss: 0.4408 - mse: 0.4343 - mae: 0.4408 - mape: 219738272.0000\n",
      "Epoch 21/100\n",
      "43199/43199 [==============================] - 6s 128us/sample - loss: 0.4423 - mse: 0.4366 - mae: 0.4423 - mape: 221545888.0000\n",
      "Epoch 22/100\n",
      "43199/43199 [==============================] - 5s 122us/sample - loss: 0.4410 - mse: 0.4355 - mae: 0.4410 - mape: 220833104.0000\n",
      "Epoch 23/100\n",
      "43199/43199 [==============================] - 6s 133us/sample - loss: 0.4417 - mse: 0.4351 - mae: 0.4417 - mape: 217898752.0000\n",
      "Epoch 24/100\n",
      "43199/43199 [==============================] - 6s 140us/sample - loss: 0.4401 - mse: 0.4343 - mae: 0.4401 - mape: 219080736.0000\n",
      "Epoch 25/100\n",
      "43199/43199 [==============================] - 5s 126us/sample - loss: 0.4417 - mse: 0.4363 - mae: 0.4417 - mape: 221202464.0000\n",
      "Epoch 26/100\n",
      "43199/43199 [==============================] - 6s 132us/sample - loss: 0.4416 - mse: 0.4365 - mae: 0.4416 - mape: 220217120.0000\n",
      "Epoch 27/100\n",
      "43199/43199 [==============================] - 6s 132us/sample - loss: 0.4419 - mse: 0.4378 - mae: 0.4419 - mape: 218095440.0000\n",
      "Epoch 28/100\n",
      "43199/43199 [==============================] - 6s 129us/sample - loss: 0.4422 - mse: 0.4379 - mae: 0.4422 - mape: 218029872.0000\n",
      "Epoch 29/100\n",
      "43199/43199 [==============================] - 6s 128us/sample - loss: 0.4412 - mse: 0.4363 - mae: 0.4412 - mape: 219428848.0000\n",
      "Epoch 30/100\n",
      "43199/43199 [==============================] - 6s 130us/sample - loss: 0.4400 - mse: 0.4350 - mae: 0.4400 - mape: 219176464.0000\n",
      "Epoch 31/100\n",
      "43199/43199 [==============================] - 5s 125us/sample - loss: 0.4403 - mse: 0.4353 - mae: 0.4403 - mape: 219758192.0000\n",
      "Epoch 32/100\n",
      "43199/43199 [==============================] - 6s 132us/sample - loss: 0.4404 - mse: 0.4357 - mae: 0.4404 - mape: 220367984.0000\n",
      "Epoch 33/100\n",
      "43199/43199 [==============================] - 6s 132us/sample - loss: 0.4396 - mse: 0.4346 - mae: 0.4396 - mape: 218823312.0000\n",
      "Epoch 34/100\n",
      "43199/43199 [==============================] - 6s 131us/sample - loss: 0.4419 - mse: 0.4375 - mae: 0.4419 - mape: 221019136.0000\n",
      "Epoch 35/100\n",
      "43199/43199 [==============================] - 6s 130us/sample - loss: 0.4416 - mse: 0.4365 - mae: 0.4416 - mape: 219283440.0000\n",
      "Epoch 36/100\n",
      "43199/43199 [==============================] - 6s 127us/sample - loss: 0.4404 - mse: 0.4359 - mae: 0.4404 - mape: 219279184.0000\n",
      "Epoch 37/100\n",
      "43199/43199 [==============================] - 5s 120us/sample - loss: 0.4393 - mse: 0.4346 - mae: 0.4393 - mape: 219483376.0000\n",
      "Epoch 38/100\n",
      "43199/43199 [==============================] - 5s 127us/sample - loss: 0.4408 - mse: 0.4359 - mae: 0.4408 - mape: 220683488.0000\n",
      "Epoch 39/100\n",
      "43199/43199 [==============================] - 5s 127us/sample - loss: 0.4407 - mse: 0.4364 - mae: 0.4407 - mape: 220985568.0000\n",
      "Epoch 40/100\n",
      "43199/43199 [==============================] - 5s 127us/sample - loss: 0.4407 - mse: 0.4358 - mae: 0.4407 - mape: 221154368.0000\n",
      "Epoch 41/100\n",
      "43199/43199 [==============================] - 5s 126us/sample - loss: 0.4416 - mse: 0.4374 - mae: 0.4416 - mape: 220868576.0000\n",
      "Epoch 42/100\n",
      "43199/43199 [==============================] - 5s 122us/sample - loss: 0.4385 - mse: 0.4344 - mae: 0.4385 - mape: 219207216.0000\n",
      "Epoch 43/100\n",
      "43199/43199 [==============================] - 6s 129us/sample - loss: 0.4398 - mse: 0.4357 - mae: 0.4398 - mape: 220343712.0000\n",
      "Epoch 44/100\n",
      "43199/43199 [==============================] - 6s 128us/sample - loss: 0.4402 - mse: 0.4363 - mae: 0.4402 - mape: 220904544.0000\n",
      "Epoch 45/100\n",
      "43199/43199 [==============================] - 6s 133us/sample - loss: 0.4393 - mse: 0.4354 - mae: 0.4393 - mape: 220030320.0000\n",
      "Epoch 46/100\n",
      "43199/43199 [==============================] - 5s 124us/sample - loss: 0.4405 - mse: 0.4366 - mae: 0.4405 - mape: 220840384.0000\n",
      "Epoch 47/100\n",
      "43199/43199 [==============================] - 6s 133us/sample - loss: 0.4397 - mse: 0.4353 - mae: 0.4397 - mape: 219838464.0000\n",
      "Epoch 48/100\n",
      "43199/43199 [==============================] - 5s 127us/sample - loss: 0.4391 - mse: 0.4347 - mae: 0.4391 - mape: 219651488.0000\n",
      "Epoch 49/100\n",
      "43199/43199 [==============================] - 6s 130us/sample - loss: 0.4397 - mse: 0.4353 - mae: 0.4397 - mape: 219798480.0000\n",
      "Epoch 50/100\n",
      "43199/43199 [==============================] - 6s 129us/sample - loss: 0.4386 - mse: 0.4342 - mae: 0.4386 - mape: 219216736.0000\n",
      "Epoch 51/100\n",
      "43199/43199 [==============================] - 5s 126us/sample - loss: 0.4393 - mse: 0.4352 - mae: 0.4393 - mape: 219512032.0000\n",
      "Epoch 52/100\n",
      "43199/43199 [==============================] - 5s 124us/sample - loss: 0.4386 - mse: 0.4346 - mae: 0.4386 - mape: 219389296.0000\n",
      "Epoch 53/100\n",
      "43199/43199 [==============================] - 5s 119us/sample - loss: 0.4390 - mse: 0.4350 - mae: 0.4390 - mape: 219671952.0000\n",
      "Epoch 54/100\n",
      "43199/43199 [==============================] - 6s 128us/sample - loss: 0.4410 - mse: 0.4380 - mae: 0.4410 - mape: 220922016.0000\n",
      "Epoch 55/100\n",
      "43199/43199 [==============================] - 5s 124us/sample - loss: 0.4422 - mse: 0.4386 - mae: 0.4422 - mape: 222271408.0000\n",
      "Epoch 56/100\n",
      "43199/43199 [==============================] - 5s 125us/sample - loss: 0.4392 - mse: 0.4360 - mae: 0.4392 - mape: 220471344.0000\n",
      "Epoch 57/100\n",
      "43199/43199 [==============================] - 6s 128us/sample - loss: 0.4392 - mse: 0.4359 - mae: 0.4392 - mape: 219973392.0000\n",
      "Epoch 58/100\n",
      "43199/43199 [==============================] - 6s 136us/sample - loss: 0.4381 - mse: 0.4347 - mae: 0.4381 - mape: 219418784.0000\n",
      "Epoch 59/100\n",
      "43199/43199 [==============================] - 6s 128us/sample - loss: 0.4380 - mse: 0.4345 - mae: 0.4380 - mape: 218650096.0000\n",
      "Epoch 60/100\n",
      "43199/43199 [==============================] - 5s 127us/sample - loss: 0.4396 - mse: 0.4367 - mae: 0.4396 - mape: 219803360.0000\n",
      "Epoch 61/100\n",
      "43199/43199 [==============================] - 6s 131us/sample - loss: 0.4406 - mse: 0.4373 - mae: 0.4406 - mape: 220216400.0000\n",
      "Epoch 62/100\n",
      "43199/43199 [==============================] - 6s 129us/sample - loss: 0.4390 - mse: 0.4359 - mae: 0.4390 - mape: 219801984.0000\n",
      "Epoch 63/100\n",
      "43199/43199 [==============================] - 6s 131us/sample - loss: 0.4392 - mse: 0.4361 - mae: 0.4392 - mape: 219619840.0000\n",
      "Epoch 64/100\n",
      "43199/43199 [==============================] - 6s 134us/sample - loss: 0.4384 - mse: 0.4349 - mae: 0.4384 - mape: 219130288.0000\n",
      "Epoch 65/100\n",
      "43199/43199 [==============================] - 5s 127us/sample - loss: 0.4390 - mse: 0.4342 - mae: 0.4390 - mape: 219810496.0000\n",
      "Epoch 66/100\n",
      "43199/43199 [==============================] - 5s 125us/sample - loss: 0.4392 - mse: 0.4351 - mae: 0.4392 - mape: 221514528.0000\n",
      "Epoch 67/100\n",
      "43199/43199 [==============================] - 6s 130us/sample - loss: 0.4377 - mse: 0.4344 - mae: 0.4377 - mape: 220469840.0000\n",
      "Epoch 68/100\n",
      "43199/43199 [==============================] - 5s 123us/sample - loss: 0.4399 - mse: 0.4360 - mae: 0.4399 - mape: 220293808.0000\n",
      "Epoch 69/100\n",
      "43199/43199 [==============================] - 5s 126us/sample - loss: 0.4384 - mse: 0.4354 - mae: 0.4384 - mape: 219322224.0000\n",
      "Epoch 70/100\n",
      "43199/43199 [==============================] - 5s 125us/sample - loss: 0.4392 - mse: 0.4358 - mae: 0.4392 - mape: 220201136.0000\n",
      "Epoch 71/100\n",
      "43199/43199 [==============================] - 6s 130us/sample - loss: 0.4370 - mse: 0.4340 - mae: 0.4370 - mape: 219412080.0000\n",
      "Epoch 72/100\n",
      "43199/43199 [==============================] - 5s 127us/sample - loss: 0.4384 - mse: 0.4349 - mae: 0.4384 - mape: 220344416.0000\n",
      "Epoch 73/100\n",
      "43199/43199 [==============================] - 5s 124us/sample - loss: 0.4390 - mse: 0.4358 - mae: 0.4390 - mape: 219874000.0000\n",
      "Epoch 74/100\n",
      "43199/43199 [==============================] - 6s 131us/sample - loss: 0.4384 - mse: 0.4356 - mae: 0.4384 - mape: 220295984.0000\n",
      "Epoch 75/100\n",
      "43199/43199 [==============================] - 5s 126us/sample - loss: 0.4383 - mse: 0.4354 - mae: 0.4383 - mape: 220960688.0000\n",
      "Epoch 76/100\n",
      "43199/43199 [==============================] - 6s 137us/sample - loss: 0.4378 - mse: 0.4348 - mae: 0.4378 - mape: 219734336.0000\n",
      "Epoch 77/100\n",
      "43199/43199 [==============================] - 6s 133us/sample - loss: 0.4375 - mse: 0.4344 - mae: 0.4375 - mape: 217179456.0000\n",
      "Epoch 78/100\n",
      "43199/43199 [==============================] - 6s 135us/sample - loss: 0.4378 - mse: 0.4327 - mae: 0.4378 - mape: 218260448.0000\n",
      "Epoch 79/100\n",
      "43199/43199 [==============================] - 5s 120us/sample - loss: 0.4370 - mse: 0.4340 - mae: 0.4370 - mape: 218345616.0000\n",
      "Epoch 80/100\n",
      "43199/43199 [==============================] - 5s 120us/sample - loss: 0.4391 - mse: 0.4312 - mae: 0.4391 - mape: 219334992.0000\n",
      "Epoch 81/100\n",
      "43199/43199 [==============================] - 5s 123us/sample - loss: 0.4392 - mse: 0.4345 - mae: 0.4392 - mape: 219429728.0000\n",
      "Epoch 82/100\n",
      "43199/43199 [==============================] - 6s 135us/sample - loss: 0.4393 - mse: 0.4356 - mae: 0.4393 - mape: 219460160.0000\n",
      "Epoch 83/100\n",
      "43199/43199 [==============================] - 5s 126us/sample - loss: 0.4385 - mse: 0.4358 - mae: 0.4385 - mape: 219238016.0000\n",
      "Epoch 84/100\n",
      "43199/43199 [==============================] - 5s 123us/sample - loss: 0.4362 - mse: 0.4333 - mae: 0.4362 - mape: 217867392.0000\n",
      "Epoch 85/100\n",
      "43199/43199 [==============================] - 6s 135us/sample - loss: 0.4386 - mse: 0.4340 - mae: 0.4386 - mape: 218342144.0000\n",
      "Epoch 86/100\n",
      "43199/43199 [==============================] - 6s 138us/sample - loss: 0.4368 - mse: 0.4324 - mae: 0.4368 - mape: 217307632.0000\n",
      "Epoch 87/100\n",
      "43199/43199 [==============================] - 5s 125us/sample - loss: 0.4371 - mse: 0.4329 - mae: 0.4371 - mape: 218211680.0000\n",
      "Epoch 88/100\n",
      "43199/43199 [==============================] - 6s 129us/sample - loss: 0.4368 - mse: 0.4285 - mae: 0.4368 - mape: 215894176.0000\n",
      "Epoch 89/100\n",
      "43199/43199 [==============================] - 6s 128us/sample - loss: 0.4371 - mse: 0.4319 - mae: 0.4371 - mape: 215897088.0000\n",
      "Epoch 90/100\n",
      "43199/43199 [==============================] - 6s 136us/sample - loss: 0.4370 - mse: 0.4317 - mae: 0.4370 - mape: 216651552.0000\n",
      "Epoch 91/100\n",
      "43199/43199 [==============================] - 6s 131us/sample - loss: 0.4354 - mse: 0.4244 - mae: 0.4354 - mape: 215077984.0000\n",
      "Epoch 92/100\n",
      "43199/43199 [==============================] - 6s 134us/sample - loss: 0.4341 - mse: 0.4262 - mae: 0.4341 - mape: 216611888.0000\n",
      "Epoch 93/100\n",
      "43199/43199 [==============================] - 6s 134us/sample - loss: 0.4355 - mse: 0.4260 - mae: 0.4355 - mape: 217888096.0000\n",
      "Epoch 94/100\n",
      "43199/43199 [==============================] - 5s 122us/sample - loss: 0.4329 - mse: 0.4244 - mae: 0.4329 - mape: 216585600.0000\n",
      "Epoch 95/100\n",
      "43199/43199 [==============================] - 6s 131us/sample - loss: 0.4331 - mse: 0.4211 - mae: 0.4331 - mape: 216291072.0000\n",
      "Epoch 96/100\n",
      "43199/43199 [==============================] - 5s 124us/sample - loss: 0.4319 - mse: 0.4218 - mae: 0.4319 - mape: 216301088.0000\n",
      "Epoch 97/100\n",
      "43199/43199 [==============================] - 5s 126us/sample - loss: 0.4319 - mse: 0.4219 - mae: 0.4319 - mape: 216065792.0000\n",
      "Epoch 98/100\n",
      "43199/43199 [==============================] - 6s 136us/sample - loss: 0.4305 - mse: 0.4219 - mae: 0.4305 - mape: 215387472.0000\n",
      "Epoch 99/100\n",
      "43199/43199 [==============================] - 6s 133us/sample - loss: 0.4349 - mse: 0.4250 - mae: 0.4349 - mape: 217880464.0000\n",
      "Epoch 100/100\n",
      "43199/43199 [==============================] - 5s 124us/sample - loss: 0.4345 - mse: 0.4257 - mae: 0.4345 - mape: 217419840.0000\n",
      "predicted_classes_train shape: (43199, 2)\n",
      "predicted_classes_train_update shape: (43199, 3, 2)\n",
      "predictions_train shape : (43199, 3, 2)\n",
      "predicted_classes_test shape: (4800, 2)\n",
      "predicted_classes_test_update shape: (4800, 3, 2)\n",
      "predictions_test shape : (4800, 3, 2)\n",
      "X_manifold               x         y          z\n",
      "59    -8.215848 -8.889377  31.301354\n",
      "60    -8.262696 -8.534749  31.186147\n",
      "61    -8.271947 -8.193172  31.047923\n",
      "62    -8.248562 -7.867578  30.885508\n",
      "63    -8.197301 -7.560628  30.698699\n",
      "...         ...       ...        ...\n",
      "43194 -8.092295 -4.927387  30.282290\n",
      "43195 -7.780484 -4.714503  29.862659\n",
      "43196 -7.480086 -4.542631  29.425034\n",
      "43197 -7.193820 -4.409718  28.974508\n",
      "43198 -6.923939 -4.313410  28.515588\n",
      "\n",
      "[19062 rows x 3 columns]\n",
      "=============================\n",
      "=============================\n",
      "y_manifold               x         y          z\n",
      "59    -8.262696 -8.534749  31.186147\n",
      "60    -8.271947 -8.193172  31.047923\n",
      "61    -8.248562 -7.867578  30.885508\n",
      "62    -8.197301 -7.560628  30.698699\n",
      "63    -8.122704 -7.274631  30.488101\n",
      "...         ...       ...        ...\n",
      "43194  8.863777  9.073592  27.197825\n",
      "43195  8.882687  9.050673  27.275690\n",
      "43196  8.897304  9.021341  27.350710\n",
      "43197  8.907440  8.985900  27.422011\n",
      "43198  8.912959  8.944733  27.488760\n",
      "\n",
      "[19062 rows x 3 columns]\n",
      "=============================\n",
      "=============================\n",
      "X_parts_list [              x         y          z\n",
      "59    -8.215848 -8.889377  31.301354\n",
      "60    -8.262696 -8.534749  31.186147\n",
      "61    -8.271947 -8.193172  31.047923\n",
      "62    -8.248562 -7.867578  30.885508\n",
      "63    -8.197301 -7.560628  30.698699\n",
      "...         ...       ...        ...\n",
      "43194 -8.092295 -4.927387  30.282290\n",
      "43195 -7.780484 -4.714503  29.862659\n",
      "43196 -7.480086 -4.542631  29.425034\n",
      "43197 -7.193820 -4.409718  28.974508\n",
      "43198 -6.923939 -4.313410  28.515588\n",
      "\n",
      "[19062 rows x 3 columns]]\n",
      "=============================\n",
      "=============================\n",
      "y_parts_list [              x         y          z\n",
      "59    -8.262696 -8.534749  31.186147\n",
      "60    -8.271947 -8.193172  31.047923\n",
      "61    -8.248562 -7.867578  30.885508\n",
      "62    -8.197301 -7.560628  30.698699\n",
      "63    -8.122704 -7.274631  30.488101\n",
      "...         ...       ...        ...\n",
      "43194  8.863777  9.073592  27.197825\n",
      "43195  8.882687  9.050673  27.275690\n",
      "43196  8.897304  9.021341  27.350710\n",
      "43197  8.907440  8.985900  27.422011\n",
      "43198  8.912959  8.944733  27.488760\n",
      "\n",
      "[19062 rows x 3 columns]]\n",
      "X_manifold               x          y          z\n",
      "0      5.894076  -6.415820  -8.194456\n",
      "1      4.821934  -4.429324  -8.263782\n",
      "2      4.022918  -2.797976  -8.203039\n",
      "3      3.441617  -1.433997  -8.064589\n",
      "4      3.035476  -0.265226  -7.879283\n",
      "...         ...        ...        ...\n",
      "43164 -8.021697 -10.891058  22.443896\n",
      "43165 -8.310868 -11.222189  22.744536\n",
      "43166 -8.603348 -11.538229  23.096059\n",
      "43167 -8.897098 -11.833147  23.497691\n",
      "43168 -9.189679 -12.100521  23.947720\n",
      "\n",
      "[24097 rows x 3 columns]\n",
      "=============================\n",
      "=============================\n",
      "y_manifold               x         y          z\n",
      "0      4.821934 -4.429324  -8.263782\n",
      "1      4.022918 -2.797976  -8.203039\n",
      "2      3.441617 -1.433997  -8.064589\n",
      "3      3.035476 -0.265226  -7.879283\n",
      "4      2.772190  0.767175  -7.664677\n",
      "...         ...       ...        ...\n",
      "43164  8.008598  7.976339  26.756591\n",
      "43165  8.006579  7.998977  26.683628\n",
      "43166  8.007171  8.027042  26.614533\n",
      "43167  8.010627  8.060189  26.549837\n",
      "43168  8.017139  8.098042  26.490050\n",
      "\n",
      "[24097 rows x 3 columns]\n",
      "=============================\n",
      "=============================\n",
      "X_parts_list [              x         y          z\n",
      "59    -8.215848 -8.889377  31.301354\n",
      "60    -8.262696 -8.534749  31.186147\n",
      "61    -8.271947 -8.193172  31.047923\n",
      "62    -8.248562 -7.867578  30.885508\n",
      "63    -8.197301 -7.560628  30.698699\n",
      "...         ...       ...        ...\n",
      "43194 -8.092295 -4.927387  30.282290\n",
      "43195 -7.780484 -4.714503  29.862659\n",
      "43196 -7.480086 -4.542631  29.425034\n",
      "43197 -7.193820 -4.409718  28.974508\n",
      "43198 -6.923939 -4.313410  28.515588\n",
      "\n",
      "[19062 rows x 3 columns],               x          y          z\n",
      "0      5.894076  -6.415820  -8.194456\n",
      "1      4.821934  -4.429324  -8.263782\n",
      "2      4.022918  -2.797976  -8.203039\n",
      "3      3.441617  -1.433997  -8.064589\n",
      "4      3.035476  -0.265226  -7.879283\n",
      "...         ...        ...        ...\n",
      "43164 -8.021697 -10.891058  22.443896\n",
      "43165 -8.310868 -11.222189  22.744536\n",
      "43166 -8.603348 -11.538229  23.096059\n",
      "43167 -8.897098 -11.833147  23.497691\n",
      "43168 -9.189679 -12.100521  23.947720\n",
      "\n",
      "[24097 rows x 3 columns]]\n",
      "=============================\n",
      "=============================\n",
      "y_parts_list [              x         y          z\n",
      "59    -8.262696 -8.534749  31.186147\n",
      "60    -8.271947 -8.193172  31.047923\n",
      "61    -8.248562 -7.867578  30.885508\n",
      "62    -8.197301 -7.560628  30.698699\n",
      "63    -8.122704 -7.274631  30.488101\n",
      "...         ...       ...        ...\n",
      "43194  8.863777  9.073592  27.197825\n",
      "43195  8.882687  9.050673  27.275690\n",
      "43196  8.897304  9.021341  27.350710\n",
      "43197  8.907440  8.985900  27.422011\n",
      "43198  8.912959  8.944733  27.488760\n",
      "\n",
      "[19062 rows x 3 columns],               x         y          z\n",
      "0      4.821934 -4.429324  -8.263782\n",
      "1      4.022918 -2.797976  -8.203039\n",
      "2      3.441617 -1.433997  -8.064589\n",
      "3      3.035476 -0.265226  -7.879283\n",
      "4      2.772190  0.767175  -7.664677\n",
      "...         ...       ...        ...\n",
      "43164  8.008598  7.976339  26.756591\n",
      "43165  8.006579  7.998977  26.683628\n",
      "43166  8.007171  8.027042  26.614533\n",
      "43167  8.010627  8.060189  26.549837\n",
      "43168  8.017139  8.098042  26.490050\n",
      "\n",
      "[24097 rows x 3 columns]]\n",
      "epochs for training interaction: 1\n",
      " \n",
      " \n",
      " \n",
      "----------------------------------------------------\n",
      "---------- Train each FFNN on each part ------------\n",
      "---------------- Deep  Classifier ------------------\n",
      "----------------------------------------------------\n",
      " \n",
      " \n",
      " \n",
      "[0.44166918 0.55833082]\n",
      "param_grid_Vanilla_Nets - input dim: [3]\n",
      "param_grid_Vanilla_Nets - output dim: [3]\n",
      "Status: Current part: 0 out of : 2 parts.\n",
      "Heights to iterate over: [30, 3, 3, 30]\n",
      "TYPE y_train: <class 'pandas.core.frame.DataFrame'>\n",
      "height: [30, 3, 3, 30]\n",
      "height1: 30 height2: 3 height3: 3\n",
      "INPUT LAYER: Tensor(\"input_4:0\", shape=(None, 3), dtype=float32) <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Y_TRAIN: [[ 4.82193361 -4.42932378 -8.2637822 ]\n",
      " [ 4.02291799 -2.79797594 -8.20303867]\n",
      " [ 3.44161713 -1.43399725 -8.06458898]\n",
      " ...\n",
      " [ 8.8973036   9.0213413  27.35070993]\n",
      " [ 8.90743987  8.98589956 27.42201135]\n",
      " [ 8.9129585   8.94473304 27.48875975]] <class 'numpy.ndarray'>\n",
      "CHECK 1 CHECK 1 ####################\n",
      "Train on 19062 samples\n",
      "Epoch 1/50\n",
      "19062/19062 [==============================] - 2s 81us/sample - loss: 9.5240 - mse: 145.2020 - mae: 9.5240 - mape: 144.8108\n",
      "Epoch 2/50\n",
      "19062/19062 [==============================] - 1s 70us/sample - loss: 9.2056 - mse: 135.6906 - mae: 9.2056 - mape: 140.2508\n",
      "Epoch 3/50\n",
      "19062/19062 [==============================] - 1s 67us/sample - loss: 9.1815 - mse: 135.5874 - mae: 9.1815 - mape: 148.5378\n",
      "Epoch 4/50\n",
      "19062/19062 [==============================] - 1s 73us/sample - loss: 9.1791 - mse: 135.9767 - mae: 9.1791 - mape: 153.3075\n",
      "Epoch 5/50\n",
      "19062/19062 [==============================] - 1s 64us/sample - loss: 9.1699 - mse: 135.5120 - mae: 9.1699 - mape: 148.4993\n",
      "Epoch 6/50\n",
      "19062/19062 [==============================] - 1s 64us/sample - loss: 9.1702 - mse: 135.6333 - mae: 9.1702 - mape: 145.9883\n",
      "Epoch 7/50\n",
      "19062/19062 [==============================] - 1s 61us/sample - loss: 9.1655 - mse: 135.8211 - mae: 9.1655 - mape: 158.9901\n",
      "Epoch 8/50\n",
      "19062/19062 [==============================] - 1s 70us/sample - loss: 9.1613 - mse: 135.4924 - mae: 9.1613 - mape: 149.2217\n",
      "Epoch 9/50\n",
      "19062/19062 [==============================] - 1s 74us/sample - loss: 9.1643 - mse: 135.7750 - mae: 9.1643 - mape: 153.6776\n",
      "Epoch 10/50\n",
      "19062/19062 [==============================] - 1s 64us/sample - loss: 9.1565 - mse: 135.5729 - mae: 9.1565 - mape: 150.3858\n",
      "Epoch 11/50\n",
      "19062/19062 [==============================] - 1s 72us/sample - loss: 9.1521 - mse: 135.4621 - mae: 9.1522 - mape: 148.0608\n",
      "Epoch 12/50\n",
      "19062/19062 [==============================] - 1s 66us/sample - loss: 9.1540 - mse: 135.4972 - mae: 9.1540 - mape: 148.3483\n",
      "Epoch 13/50\n",
      "19062/19062 [==============================] - 1s 68us/sample - loss: 9.1477 - mse: 135.3870 - mae: 9.1477 - mape: 147.5963\n",
      "Epoch 14/50\n",
      "19062/19062 [==============================] - 1s 63us/sample - loss: 9.1425 - mse: 135.4328 - mae: 9.1425 - mape: 152.3858\n",
      "Epoch 15/50\n",
      "19062/19062 [==============================] - 1s 58us/sample - loss: 9.1408 - mse: 135.4297 - mae: 9.1408 - mape: 150.7547\n",
      "Epoch 16/50\n",
      "19062/19062 [==============================] - 1s 57us/sample - loss: 9.1399 - mse: 135.4464 - mae: 9.1399 - mape: 152.1984\n",
      "Epoch 17/50\n",
      "19062/19062 [==============================] - 1s 61us/sample - loss: 9.1367 - mse: 135.2151 - mae: 9.1367 - mape: 158.2755\n",
      "Epoch 18/50\n",
      "19062/19062 [==============================] - 1s 69us/sample - loss: 9.1294 - mse: 135.1335 - mae: 9.1294 - mape: 153.1637\n",
      "Epoch 19/50\n",
      "19062/19062 [==============================] - 1s 62us/sample - loss: 9.1292 - mse: 135.0911 - mae: 9.1292 - mape: 151.0372\n",
      "Epoch 20/50\n",
      "19062/19062 [==============================] - 2s 84us/sample - loss: 9.1245 - mse: 135.0441 - mae: 9.1245 - mape: 150.3203\n",
      "Epoch 21/50\n",
      "19062/19062 [==============================] - 1s 77us/sample - loss: 9.1256 - mse: 135.1593 - mae: 9.1256 - mape: 150.8341\n",
      "Epoch 22/50\n",
      "19062/19062 [==============================] - 1s 68us/sample - loss: 9.1244 - mse: 135.0172 - mae: 9.1244 - mape: 151.0056\n",
      "Epoch 23/50\n",
      "19062/19062 [==============================] - 1s 68us/sample - loss: 9.1188 - mse: 135.0154 - mae: 9.1188 - mape: 150.1974\n",
      "Epoch 24/50\n",
      "19062/19062 [==============================] - 1s 66us/sample - loss: 9.1234 - mse: 135.0248 - mae: 9.1234 - mape: 150.5429\n",
      "Epoch 25/50\n",
      "19062/19062 [==============================] - 1s 61us/sample - loss: 9.1188 - mse: 134.9392 - mae: 9.1188 - mape: 151.5328\n",
      "Epoch 26/50\n",
      "19062/19062 [==============================] - 1s 60us/sample - loss: 9.1259 - mse: 135.0394 - mae: 9.1260 - mape: 148.0180\n",
      "Epoch 27/50\n",
      "19062/19062 [==============================] - 1s 73us/sample - loss: 9.1173 - mse: 135.0928 - mae: 9.1173 - mape: 149.1624\n",
      "Epoch 28/50\n",
      "19062/19062 [==============================] - 2s 86us/sample - loss: 9.1183 - mse: 135.0434 - mae: 9.1183 - mape: 151.2651\n",
      "Epoch 29/50\n",
      "19062/19062 [==============================] - 1s 69us/sample - loss: 9.1200 - mse: 134.9757 - mae: 9.1200 - mape: 147.2596\n",
      "Epoch 30/50\n",
      "19062/19062 [==============================] - 1s 70us/sample - loss: 9.1168 - mse: 134.8876 - mae: 9.1168 - mape: 150.0904\n",
      "Epoch 31/50\n",
      "19062/19062 [==============================] - ETA: 0s - loss: 9.1264 - mse: 135.2306 - mae: 9.1264 - mape: 150.51 - 1s 73us/sample - loss: 9.1144 - mse: 134.8792 - mae: 9.1144 - mape: 150.6755\n",
      "Epoch 32/50\n",
      "19062/19062 [==============================] - 2s 82us/sample - loss: 9.1182 - mse: 134.9795 - mae: 9.1182 - mape: 151.4777\n",
      "Epoch 33/50\n",
      "19062/19062 [==============================] - 1s 76us/sample - loss: 9.1086 - mse: 134.8269 - mae: 9.1086 - mape: 152.2220\n",
      "Epoch 34/50\n",
      "19062/19062 [==============================] - 1s 66us/sample - loss: 9.1144 - mse: 134.9849 - mae: 9.1144 - mape: 154.4781\n",
      "Epoch 35/50\n",
      "19062/19062 [==============================] - 2s 80us/sample - loss: 9.1188 - mse: 135.0077 - mae: 9.1188 - mape: 151.1193\n",
      "Epoch 36/50\n",
      "19062/19062 [==============================] - 1s 78us/sample - loss: 9.1117 - mse: 134.8965 - mae: 9.1117 - mape: 149.6875\n",
      "Epoch 37/50\n",
      "19062/19062 [==============================] - 1s 76us/sample - loss: 9.1101 - mse: 134.9377 - mae: 9.1101 - mape: 150.8420\n",
      "Epoch 38/50\n",
      "19062/19062 [==============================] - 1s 69us/sample - loss: 9.1665 - mse: 146.7144 - mae: 9.1665 - mape: 152.6563\n",
      "Epoch 39/50\n",
      "19062/19062 [==============================] - 1s 68us/sample - loss: 9.1164 - mse: 135.0489 - mae: 9.1164 - mape: 149.1992\n",
      "Epoch 40/50\n",
      "19062/19062 [==============================] - 1s 67us/sample - loss: 9.1097 - mse: 134.8637 - mae: 9.1097 - mape: 146.3896\n",
      "Epoch 41/50\n",
      "19062/19062 [==============================] - 1s 71us/sample - loss: 9.1139 - mse: 135.0899 - mae: 9.1139 - mape: 153.2586\n",
      "Epoch 42/50\n",
      "19062/19062 [==============================] - 1s 61us/sample - loss: 9.1082 - mse: 134.9651 - mae: 9.1082 - mape: 150.9247\n",
      "Epoch 43/50\n",
      "19062/19062 [==============================] - 1s 63us/sample - loss: 9.1112 - mse: 134.9716 - mae: 9.1112 - mape: 147.7065\n",
      "Epoch 44/50\n",
      "19062/19062 [==============================] - 1s 74us/sample - loss: 9.1088 - mse: 134.8690 - mae: 9.1088 - mape: 151.6916\n",
      "Epoch 45/50\n",
      "19062/19062 [==============================] - 1s 77us/sample - loss: 9.1153 - mse: 135.3735 - mae: 9.1153 - mape: 153.2939\n",
      "Epoch 46/50\n",
      "19062/19062 [==============================] - 1s 62us/sample - loss: 9.1044 - mse: 134.7471 - mae: 9.1043 - mape: 151.2714\n",
      "Epoch 47/50\n",
      "19062/19062 [==============================] - 1s 72us/sample - loss: 9.1036 - mse: 134.9200 - mae: 9.1036 - mape: 150.1533\n",
      "Epoch 48/50\n",
      "19062/19062 [==============================] - 1s 63us/sample - loss: 9.1073 - mse: 134.9593 - mae: 9.1073 - mape: 149.8198\n",
      "Epoch 49/50\n",
      "19062/19062 [==============================] - 1s 76us/sample - loss: 9.0966 - mse: 135.1080 - mae: 9.0966 - mape: 155.7650\n",
      "Epoch 50/50\n",
      "19062/19062 [==============================] - 1s 74us/sample - loss: 9.1012 - mse: 134.9948 - mae: 9.1012 - mape: 156.4594\n",
      "EPOCHS 50\n",
      "weights layer: []\n",
      "weights layer: [array([[ 1.1508645e+00,  2.6860382e-02,  2.8047553e-01,  6.8061846e-01,\n",
      "        -8.5938133e-02,  3.7444276e-01,  1.0709198e+00,  3.7124982e-01,\n",
      "         2.1875735e-01,  2.6596099e-01,  7.2833049e-01,  4.2198268e-01,\n",
      "         4.4081458e-01,  2.5552800e-01,  4.0402082e-01,  4.1526404e-01,\n",
      "         6.2886989e-01,  5.0426096e-01,  4.6673119e-01,  7.0357060e-01,\n",
      "         4.4884828e-01, -2.5570118e+00,  5.0126666e-01,  5.2161521e-01,\n",
      "         6.8821949e-01,  3.5319048e-01,  3.5766223e-01,  6.3435823e-01,\n",
      "         5.2076960e-01,  3.6138934e-01],\n",
      "       [ 3.4193903e-01,  2.6133856e-01,  1.3236040e-01,  3.3370039e-01,\n",
      "         3.9064233e+00,  1.7965280e-03,  6.2257618e-01,  1.0333728e-02,\n",
      "         7.9455376e-02,  1.6838759e-01,  4.2870852e-01, -1.8201543e-02,\n",
      "        -1.8867004e-01,  1.5077229e-01, -1.8277953e-03,  3.4419796e-01,\n",
      "         5.1138010e+00,  4.5719302e-01,  8.3750361e-01,  1.1352648e+00,\n",
      "         6.7540807e-01,  1.1573633e+00,  4.9260291e-01,  8.4912324e-01,\n",
      "         7.7694339e-01,  7.4012697e-01,  2.1221254e-02,  3.7094718e-01,\n",
      "         3.4149495e-01,  5.7786945e-02],\n",
      "       [-2.1058087e-01, -5.0015759e-01, -7.8857374e-01, -4.9806911e-01,\n",
      "         5.0716960e-01, -1.0514982e+00, -2.1430324e-01, -1.0119718e+00,\n",
      "        -9.6206528e-01, -8.6753726e-01, -2.5657976e-01, -1.0177418e+00,\n",
      "        -8.5905522e-01, -8.7485278e-01, -1.0198088e+00, -8.6191010e-01,\n",
      "        -2.7696687e-01, -4.7754940e-01, -4.6988881e-01, -2.5704715e-01,\n",
      "        -4.5958260e-01,  8.4022647e-03, -4.4686839e-01, -4.6400088e-01,\n",
      "        -3.1532693e-01, -4.2742956e-01, -1.0499465e+00, -4.8659241e-01,\n",
      "        -4.8460910e-01, -1.0332443e+00]], dtype=float32), array([ 4.8496607e-01, -8.5947782e-01, -4.8374215e-01,  7.4195111e-01,\n",
      "        1.5955402e+00, -5.7484800e-01,  1.8716351e-03, -3.1868133e-01,\n",
      "       -6.6390222e-01, -7.0816213e-01,  9.0067631e-01, -4.8170686e-01,\n",
      "       -2.9676220e-01, -8.0000079e-01, -3.4692159e-01, -8.1873733e-01,\n",
      "        1.0408275e-01,  6.1071116e-01, -2.6828009e-01,  4.7910362e-01,\n",
      "        4.6439311e-03, -5.1800203e+00,  1.9678327e-01, -8.1187189e-02,\n",
      "        3.7923628e-01, -9.2342414e-02, -5.8807456e-01,  7.1180731e-01,\n",
      "       -4.0480420e-02, -6.7014283e-01], dtype=float32)]\n",
      "weights layer: []\n",
      "weights layer: []\n",
      "weights layer: []\n",
      "weights layer: [array([[ 1.330254  ,  0.27199802, -0.46525934],\n",
      "       [ 0.29691502,  0.1586671 , -0.8343023 ],\n",
      "       [-0.19475536,  0.9734015 , -0.20182864],\n",
      "       [ 1.145474  ,  0.70004207, -1.2546705 ],\n",
      "       [ 0.43463027, -0.42959848, -4.2096157 ],\n",
      "       [-0.13293229, -0.58587515, -0.48042452],\n",
      "       [ 0.33320233,  0.8882984 , -2.6047802 ],\n",
      "       [-0.0573021 , -0.8488465 , -0.37588635],\n",
      "       [-0.09259821, -0.07945514,  0.4982027 ],\n",
      "       [ 1.1182288 ,  0.148795  , -0.7183228 ],\n",
      "       [ 2.4148679 ,  1.743651  , -0.25535646],\n",
      "       [-0.13312553, -0.7776046 , -0.45798293],\n",
      "       [-0.13235147,  0.41406712, -0.21846911],\n",
      "       [ 0.8328751 , -0.16598953, -0.8123564 ],\n",
      "       [-0.06481832, -0.76746935, -0.41071117],\n",
      "       [ 0.7870275 ,  0.14283551, -0.55641824],\n",
      "       [-1.0210048 , -1.5602446 ,  0.41510618],\n",
      "       [ 1.1700816 ,  1.1913551 , -1.1258705 ],\n",
      "       [ 0.76790535,  1.3375832 ,  0.6870233 ],\n",
      "       [ 0.9591967 ,  0.47461128, -0.82080454],\n",
      "       [ 0.8959889 ,  1.3308846 ,  0.3367967 ],\n",
      "       [ 0.26895437, -2.614841  , -1.1376034 ],\n",
      "       [ 1.5387633 ,  2.28871   , -1.9405962 ],\n",
      "       [ 1.197457  ,  2.0775979 ,  1.0737243 ],\n",
      "       [ 1.0269876 ,  1.3134288 , -1.2832035 ],\n",
      "       [ 0.23411436,  1.831438  ,  0.91547465],\n",
      "       [-0.02020466, -0.5073138 , -0.5506858 ],\n",
      "       [ 1.4086173 ,  0.90462106, -1.3136166 ],\n",
      "       [ 1.7648432 ,  1.8480334 , -2.358381  ],\n",
      "       [-0.04968658, -0.63445723, -0.5747509 ]], dtype=float32), array([-3.6779296 , -0.72858965, -1.5772278 ], dtype=float32)]\n",
      "weights layer: []\n",
      "weights layer: []\n",
      "weights layer: []\n",
      "weights layer: [array([[ 0.03977182,  0.03430669, -0.3807794 ],\n",
      "       [ 1.6506116 ,  2.0128782 , -0.61134446],\n",
      "       [-2.9756787 , -2.6288977 , -2.9711897 ]], dtype=float32), array([-0.22958824, -0.18445155, -0.29913533], dtype=float32)]\n",
      "weights layer: [array([[ 9.92032349e-01, -2.83266336e-01, -5.04293442e-02,\n",
      "         6.23944588e-02, -2.00932002e+00,  4.15544659e-02,\n",
      "         8.38826448e-02,  7.59833217e-01, -8.69854838e-02,\n",
      "         6.92331851e-01,  3.81476432e-01,  3.50557685e-01,\n",
      "         9.67839956e-02, -5.38665056e-02, -3.89827758e-01,\n",
      "        -9.77749974e-02,  9.08399880e-01,  4.18487787e-02,\n",
      "         8.72154415e-01, -3.72629791e-01, -4.59920257e-01,\n",
      "        -1.25057444e-01,  2.95575317e-02, -2.53001880e-02,\n",
      "         2.97649711e-01, -4.64143343e-02, -2.86776990e-01,\n",
      "        -5.82543612e-02, -1.69558618e-02, -6.75546587e-01],\n",
      "       [-1.35585800e-01, -5.65455034e-02,  6.25993013e-02,\n",
      "        -1.49517089e-01, -2.48525286e+00, -3.24674957e-02,\n",
      "         1.65854707e-01,  1.59732014e-01,  1.97719142e-01,\n",
      "         1.34066418e-01, -5.30225597e-02,  2.02037081e-01,\n",
      "         6.39613792e-02,  4.76519875e-02, -4.50754285e-01,\n",
      "         1.07993826e-01, -3.32186297e-02, -8.39108974e-03,\n",
      "         4.37200218e-02,  1.61158696e-01, -1.17708765e-01,\n",
      "        -1.27669036e-01, -6.38288483e-02, -1.59517214e-01,\n",
      "         2.85441458e-01, -3.01385343e-01, -7.89770670e-03,\n",
      "         6.69401363e-02, -1.12570092e-01, -3.11549962e-01],\n",
      "       [ 2.40271091e+00,  1.34151086e-01,  1.58158585e-03,\n",
      "         2.50234958e-02,  1.98467195e+00, -2.57659354e-04,\n",
      "         4.70767111e-01,  1.80971777e+00,  9.48999971e-02,\n",
      "         1.70495296e+00,  4.34756540e-02, -2.44964063e-01,\n",
      "         4.59663153e-01,  7.78488873e-04, -6.18145108e-01,\n",
      "         4.48283507e-03,  2.08956504e+00,  3.20731997e-02,\n",
      "         2.02291036e+00,  4.15918469e-01,  6.80120170e-01,\n",
      "        -1.99100059e-02, -3.79671366e-03,  3.81881654e-01,\n",
      "        -3.15260291e-01,  3.87883008e-01,  1.94259390e-01,\n",
      "         2.46902509e-03,  4.32131797e-01,  1.13468909e+00]], dtype=float32), array([-3.0286121e+00, -1.2090305e+00, -1.2772387e+00, -2.3008087e-03,\n",
      "       -8.1033969e-01, -1.2771343e+00,  1.8392070e-01, -2.7982910e+00,\n",
      "       -1.1931502e+00, -2.7010829e+00,  5.8515653e-02,  1.4509676e+00,\n",
      "        1.7263964e-01, -1.2821023e+00,  1.6081283e+00, -1.2793339e+00,\n",
      "       -2.8877664e+00, -1.2784898e+00, -2.8875961e+00,  1.5084474e-01,\n",
      "       -1.2737777e+00, -1.3010136e+00, -1.2811457e+00,  1.4470553e-01,\n",
      "        1.5222870e+00,  1.6196041e-01, -1.1845360e+00, -1.2784438e+00,\n",
      "        1.5846178e-01, -1.2808000e+00], dtype=float32)]\n",
      "weights layer: []\n",
      "weights layer: []\n",
      "weights layer: []\n",
      "weights layer: [array([[ 2.8991084 ,  3.1824944 , -1.6663578 ],\n",
      "       [-0.0571247 ,  0.15906298, -4.734434  ],\n",
      "       [-0.01469867,  0.10182758, -4.526305  ],\n",
      "       [ 0.03371193, -0.0254926 , -0.0085032 ],\n",
      "       [ 2.87448   ,  3.3732133 , -1.1076094 ],\n",
      "       [-0.03228139, -0.04604919, -4.7418556 ],\n",
      "       [-0.3474809 , -1.1553549 , -0.37911296],\n",
      "       [ 2.4507523 ,  2.4788187 , -1.5943909 ],\n",
      "       [ 0.2935472 ,  0.677352  , -4.117014  ],\n",
      "       [ 2.3608274 ,  2.3095243 , -1.6907367 ],\n",
      "       [ 0.01993788, -0.07883787,  0.04279868],\n",
      "       [ 0.2299925 ,  0.33054522,  1.0854167 ],\n",
      "       [-0.24986443, -1.0287884 , -0.35404366],\n",
      "       [-0.00745932,  0.16221616, -4.778307  ],\n",
      "       [ 0.49027646,  0.63275987,  1.3293755 ],\n",
      "       [-0.12623152, -0.01463819, -4.503609  ],\n",
      "       [ 2.6344783 ,  2.7040863 , -1.457071  ],\n",
      "       [-0.02217158,  0.1045225 , -4.6659775 ],\n",
      "       [ 2.5574093 ,  2.692589  , -1.5173898 ],\n",
      "       [ 0.10864932, -0.62334394, -0.08881456],\n",
      "       [ 0.692791  ,  1.3448265 , -3.919746  ],\n",
      "       [ 0.02873067,  0.22147869, -4.7255993 ],\n",
      "       [ 0.09904227,  0.06435014, -4.7781353 ],\n",
      "       [-0.01397404, -0.28761172, -0.0522408 ],\n",
      "       [ 0.2304521 ,  0.37203982,  1.1589339 ],\n",
      "       [ 0.1335116 , -0.38865885, -0.05469148],\n",
      "       [ 0.05526581,  0.09335995, -4.6668315 ],\n",
      "       [-0.19773382, -0.02753184, -4.4257946 ],\n",
      "       [ 0.0780254 , -0.8863817 , -0.22827613],\n",
      "       [ 1.1797609 ,  2.0765548 , -3.5616233 ]], dtype=float32), array([ 0.04285064, -0.08501928,  4.7630177 ], dtype=float32)]\n",
      "y_train shape: (43199, 3)\n",
      "y_hat_train_full_loop shape: (43199, 3)\n",
      "y_test shape: (4800, 3)\n",
      "y_hat_test_full_loop shape: (4800, 3)\n",
      "training_quality shape: (43199, 3)\n",
      "param_grid_Vanilla_Nets - input dim: [3]\n",
      "param_grid_Vanilla_Nets - output dim: [3]\n",
      "Status: Current part: 1 out of : 2 parts.\n",
      "Heights to iterate over: [30, 3, 3, 30]\n",
      "TYPE y_train: <class 'pandas.core.frame.DataFrame'>\n",
      "height: [30, 3, 3, 30]\n",
      "height1: 30 height2: 3 height3: 3\n",
      "INPUT LAYER: Tensor(\"input_5:0\", shape=(None, 3), dtype=float32) <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Y_TRAIN: [[ 4.82193361 -4.42932378 -8.2637822 ]\n",
      " [ 4.02291799 -2.79797594 -8.20303867]\n",
      " [ 3.44161713 -1.43399725 -8.06458898]\n",
      " ...\n",
      " [ 8.8973036   9.0213413  27.35070993]\n",
      " [ 8.90743987  8.98589956 27.42201135]\n",
      " [ 8.9129585   8.94473304 27.48875975]] <class 'numpy.ndarray'>\n",
      "CHECK 1 CHECK 1 ####################\n",
      "Train on 24097 samples\n",
      "Epoch 1/50\n",
      "24097/24097 [==============================] - 2s 70us/sample - loss: 9.4790 - mse: 144.3061 - mae: 9.4790 - mape: 816.8020\n",
      "Epoch 2/50\n",
      "24097/24097 [==============================] - 2s 75us/sample - loss: 9.2245 - mse: 136.7890 - mae: 9.2245 - mape: 779.5375\n",
      "Epoch 3/50\n",
      "24097/24097 [==============================] - 2s 72us/sample - loss: 9.1911 - mse: 136.3667 - mae: 9.1911 - mape: 845.8718\n",
      "Epoch 4/50\n",
      "24097/24097 [==============================] - 2s 63us/sample - loss: 9.1939 - mse: 136.3470 - mae: 9.1939 - mape: 854.9837\n",
      "Epoch 5/50\n",
      "24097/24097 [==============================] - 2s 76us/sample - loss: 9.1892 - mse: 136.5872 - mae: 9.1892 - mape: 790.7411\n",
      "Epoch 6/50\n",
      "24097/24097 [==============================] - 2s 77us/sample - loss: 9.1864 - mse: 136.3673 - mae: 9.1864 - mape: 766.5573\n",
      "Epoch 7/50\n",
      "24097/24097 [==============================] - 2s 68us/sample - loss: 9.1793 - mse: 136.1453 - mae: 9.1793 - mape: 458.1466\n",
      "Epoch 8/50\n",
      "24097/24097 [==============================] - 2s 66us/sample - loss: 9.1711 - mse: 136.0160 - mae: 9.1711 - mape: 495.4274\n",
      "Epoch 9/50\n",
      "24097/24097 [==============================] - 2s 63us/sample - loss: 9.1644 - mse: 135.8985 - mae: 9.1644 - mape: 462.0514\n",
      "Epoch 10/50\n",
      "24097/24097 [==============================] - 2s 67us/sample - loss: 9.1623 - mse: 135.7690 - mae: 9.1623 - mape: 554.2021\n",
      "Epoch 11/50\n",
      "24097/24097 [==============================] - 2s 69us/sample - loss: 9.1642 - mse: 136.0892 - mae: 9.1642 - mape: 464.8506\n",
      "Epoch 12/50\n",
      "24097/24097 [==============================] - 2s 75us/sample - loss: 9.1540 - mse: 135.8972 - mae: 9.1540 - mape: 416.0665\n",
      "Epoch 13/50\n",
      "24097/24097 [==============================] - 2s 81us/sample - loss: 9.1621 - mse: 135.7742 - mae: 9.1621 - mape: 639.4299\n",
      "Epoch 14/50\n",
      "24097/24097 [==============================] - 2s 69us/sample - loss: 9.1617 - mse: 135.9382 - mae: 9.1617 - mape: 528.3568\n",
      "Epoch 15/50\n",
      "24097/24097 [==============================] - 2s 80us/sample - loss: 9.1657 - mse: 135.8585 - mae: 9.1657 - mape: 356.6874\n",
      "Epoch 16/50\n",
      "24097/24097 [==============================] - 2s 87us/sample - loss: 9.1503 - mse: 135.5753 - mae: 9.1503 - mape: 468.8491\n",
      "Epoch 17/50\n",
      "24097/24097 [==============================] - 2s 76us/sample - loss: 9.1446 - mse: 135.6937 - mae: 9.1446 - mape: 449.5615\n",
      "Epoch 18/50\n",
      "24097/24097 [==============================] - 2s 64us/sample - loss: 9.1530 - mse: 135.6311 - mae: 9.1530 - mape: 282.1475\n",
      "Epoch 19/50\n",
      "24097/24097 [==============================] - 2s 81us/sample - loss: 9.1465 - mse: 135.5305 - mae: 9.1465 - mape: 362.9763\n",
      "Epoch 20/50\n",
      "24097/24097 [==============================] - 2s 71us/sample - loss: 9.1615 - mse: 135.9105 - mae: 9.1615 - mape: 672.1124\n",
      "Epoch 21/50\n",
      "24097/24097 [==============================] - 2s 65us/sample - loss: 9.1514 - mse: 135.6564 - mae: 9.1515 - mape: 457.8725\n",
      "Epoch 22/50\n",
      "24097/24097 [==============================] - 2s 69us/sample - loss: 9.1514 - mse: 135.8123 - mae: 9.1514 - mape: 421.7643\n",
      "Epoch 23/50\n",
      "24097/24097 [==============================] - 2s 68us/sample - loss: 9.1510 - mse: 135.6084 - mae: 9.1510 - mape: 461.4829\n",
      "Epoch 24/50\n",
      "24097/24097 [==============================] - 1s 57us/sample - loss: 9.1548 - mse: 135.7902 - mae: 9.1548 - mape: 437.2477\n",
      "Epoch 25/50\n",
      "24097/24097 [==============================] - 1s 61us/sample - loss: 9.1448 - mse: 135.6349 - mae: 9.1448 - mape: 481.6880\n",
      "Epoch 26/50\n",
      "24097/24097 [==============================] - 1s 62us/sample - loss: 9.1435 - mse: 135.5296 - mae: 9.1435 - mape: 383.6675\n",
      "Epoch 27/50\n",
      "24097/24097 [==============================] - 2s 64us/sample - loss: 9.1512 - mse: 135.6857 - mae: 9.1512 - mape: 431.2281\n",
      "Epoch 28/50\n",
      "24097/24097 [==============================] - 2s 62us/sample - loss: 9.1502 - mse: 135.8772 - mae: 9.1502 - mape: 457.8762\n",
      "Epoch 29/50\n",
      "24097/24097 [==============================] - 1s 60us/sample - loss: 9.1401 - mse: 135.4363 - mae: 9.1401 - mape: 525.2997\n",
      "Epoch 30/50\n",
      "24097/24097 [==============================] - 2s 66us/sample - loss: 9.1498 - mse: 135.5359 - mae: 9.1498 - mape: 361.7658\n",
      "Epoch 31/50\n",
      "24097/24097 [==============================] - 1s 60us/sample - loss: 9.1532 - mse: 135.7026 - mae: 9.1532 - mape: 429.3026\n",
      "Epoch 32/50\n",
      "24097/24097 [==============================] - 2s 76us/sample - loss: 9.1556 - mse: 135.6252 - mae: 9.1556 - mape: 376.6167\n",
      "Epoch 33/50\n",
      "24097/24097 [==============================] - 2s 74us/sample - loss: 9.1453 - mse: 135.7444 - mae: 9.1453 - mape: 507.7916\n",
      "Epoch 34/50\n",
      "24097/24097 [==============================] - 2s 71us/sample - loss: 9.1529 - mse: 135.7859 - mae: 9.1529 - mape: 523.8054\n",
      "Epoch 35/50\n",
      "24097/24097 [==============================] - 2s 63us/sample - loss: 9.1553 - mse: 136.0426 - mae: 9.1553 - mape: 438.0196\n",
      "Epoch 36/50\n",
      "24097/24097 [==============================] - 2s 68us/sample - loss: 9.1682 - mse: 136.0349 - mae: 9.1682 - mape: 781.6912\n",
      "Epoch 37/50\n",
      "24097/24097 [==============================] - 2s 74us/sample - loss: 9.1406 - mse: 135.4402 - mae: 9.1406 - mape: 528.7144\n",
      "Epoch 38/50\n",
      "24097/24097 [==============================] - 2s 70us/sample - loss: 9.1291 - mse: 135.1696 - mae: 9.1291 - mape: 504.3914\n",
      "Epoch 39/50\n",
      "24097/24097 [==============================] - 2s 68us/sample - loss: 9.1297 - mse: 135.4720 - mae: 9.1297 - mape: 336.2818\n",
      "Epoch 40/50\n",
      "24097/24097 [==============================] - 2s 67us/sample - loss: 9.1259 - mse: 135.3760 - mae: 9.1259 - mape: 1065.3750 - loss: 9.0975\n",
      "Epoch 41/50\n",
      "24097/24097 [==============================] - 2s 72us/sample - loss: 9.1593 - mse: 136.1653 - mae: 9.1593 - mape: 1068.5815\n",
      "Epoch 42/50\n",
      "24097/24097 [==============================] - 2s 76us/sample - loss: 9.1281 - mse: 135.3914 - mae: 9.1281 - mape: 431.2134\n",
      "Epoch 43/50\n",
      "24097/24097 [==============================] - 2s 68us/sample - loss: 9.1398 - mse: 135.6496 - mae: 9.1398 - mape: 418.1063\n",
      "Epoch 44/50\n",
      "24097/24097 [==============================] - 2s 62us/sample - loss: 9.1432 - mse: 135.7780 - mae: 9.1432 - mape: 398.1719\n",
      "Epoch 45/50\n",
      "24097/24097 [==============================] - 2s 69us/sample - loss: 9.1295 - mse: 135.7985 - mae: 9.1295 - mape: 541.4708\n",
      "Epoch 46/50\n",
      "24097/24097 [==============================] - 2s 68us/sample - loss: 9.1202 - mse: 135.1507 - mae: 9.1202 - mape: 525.9958\n",
      "Epoch 47/50\n",
      "24097/24097 [==============================] - 2s 82us/sample - loss: 9.1317 - mse: 135.5089 - mae: 9.1317 - mape: 417.7638\n",
      "Epoch 48/50\n",
      "24097/24097 [==============================] - 2s 75us/sample - loss: 9.1281 - mse: 135.6228 - mae: 9.1280 - mape: 522.4101\n",
      "Epoch 49/50\n",
      "24097/24097 [==============================] - 1s 61us/sample - loss: 9.1266 - mse: 135.3357 - mae: 9.1266 - mape: 400.2404\n",
      "Epoch 50/50\n",
      "24097/24097 [==============================] - 1s 57us/sample - loss: 9.1251 - mse: 135.2748 - mae: 9.1251 - mape: 542.6233\n",
      "EPOCHS 50\n",
      "weights layer: []\n",
      "weights layer: [array([[-0.36647254, -0.16236545, -0.17927283,  0.75327677, -0.37094763,\n",
      "        -0.53311926, -0.8114256 , -1.6760551 , -1.3228781 ,  0.12401292,\n",
      "        -0.06754402, -0.33965692,  0.09108168, -0.66283584, -1.3789777 ,\n",
      "         1.2902514 ,  0.36174077, -2.9470804 ,  0.5913227 , -0.23540941,\n",
      "        -0.203651  , -0.38946068, -0.89597464, -0.6580875 , -2.4867892 ,\n",
      "        -0.45417732, -0.30555725, -0.55880976,  2.465142  , -0.39541125],\n",
      "       [ 0.01826284,  0.23700516,  0.23397477,  0.09482077,  0.66789705,\n",
      "         0.95627064,  0.5621708 ,  0.8957944 , -0.81823975,  0.34814146,\n",
      "         0.44391572,  0.49170974,  0.29813665, -0.46488163,  0.24436699,\n",
      "        -2.2982748 ,  0.59432703,  0.19359091,  0.28678644,  0.641171  ,\n",
      "        -0.07588624,  0.24022275,  0.7209294 ,  0.6299097 ,  1.6022072 ,\n",
      "         0.40571788, -0.0064556 ,  0.2911239 ,  0.03070579,  0.25559026],\n",
      "       [-2.1424947 , -1.8433594 , -1.5914323 , -2.7187226 , -1.7585971 ,\n",
      "        -2.330366  , -1.5651783 ,  0.10252833, -1.7732643 , -1.8818152 ,\n",
      "        -1.4075125 , -1.8343952 , -1.9489508 , -2.4107823 ,  0.40657446,\n",
      "        -0.0645418 , -1.4880083 , -0.5077534 , -1.9518533 , -1.5229903 ,\n",
      "        -2.0805967 , -1.4600533 , -1.6256181 , -1.5883844 , -1.075919  ,\n",
      "        -2.104588  ,  1.3091398 , -1.456691  , -2.4542227 , -1.7116085 ]],\n",
      "      dtype=float32), array([-2.441446  , -3.5464826 , -3.2260299 , -0.6395011 , -2.5025733 ,\n",
      "        0.945857  , -0.69625765, -7.4193845 , -1.2068236 , -3.1881847 ,\n",
      "       -5.3840885 ,  0.242016  , -2.9750268 , -2.278463  , -4.569172  ,\n",
      "        1.2636633 , -3.0237243 ,  1.7025975 , -2.9918547 , -2.4971118 ,\n",
      "       -2.7329543 , -2.4568126 , -3.1754346 ,  1.1213374 ,  3.456431  ,\n",
      "       -0.7509501 , -3.582074  , -3.269434  ,  2.4749863 , -4.6752877 ],\n",
      "      dtype=float32)]\n",
      "weights layer: []\n",
      "weights layer: []\n",
      "weights layer: []\n",
      "weights layer: [array([[-0.8588314 , -1.0078157 , -0.62324315],\n",
      "       [-0.10318758, -0.768668  , -1.2369596 ],\n",
      "       [ 0.6338709 , -0.78806335, -1.0703942 ],\n",
      "       [-0.5393816 , -1.9025558 , -0.6544668 ],\n",
      "       [ 0.05693386, -1.332617  , -2.098508  ],\n",
      "       [-1.6975428 , -1.6347548 ,  0.0153071 ],\n",
      "       [ 0.5171678 , -1.4193763 ,  0.18264711],\n",
      "       [ 1.3013018 ,  0.26166993, -0.3056628 ],\n",
      "       [-1.0354141 , -0.6450675 , -1.5448658 ],\n",
      "       [ 0.6537646 , -0.7200098 , -0.60919297],\n",
      "       [ 0.43672055, -0.6254177 , -0.5255237 ],\n",
      "       [ 0.19888632, -2.1542935 , -0.90516436],\n",
      "       [ 0.35547975, -0.7897125 , -0.25932106],\n",
      "       [-0.509899  , -0.5727099 , -1.5573815 ],\n",
      "       [ 0.5501755 , -0.73169523,  0.60249543],\n",
      "       [ 0.8960274 , -1.3902612 ,  0.1820764 ],\n",
      "       [ 0.07868309, -0.57324255, -1.0085528 ],\n",
      "       [-1.0459014 , -5.167913  , -5.971825  ],\n",
      "       [-0.2578026 , -1.1954253 , -0.34253028],\n",
      "       [ 1.2395785 , -1.4549603 , -0.68924963],\n",
      "       [-0.8246895 , -0.61829114, -1.0674816 ],\n",
      "       [-0.15001997, -0.917122  , -0.92726487],\n",
      "       [ 0.03828965,  0.31391957, -1.4479625 ],\n",
      "       [-0.18944915, -2.6007168 ,  0.02664177],\n",
      "       [-2.9601815 , -0.05303263, -2.379019  ],\n",
      "       [-0.09103965, -2.7645392 , -1.6121439 ],\n",
      "       [ 0.5183366 , -0.6088695 , -0.7123605 ],\n",
      "       [ 0.32760414, -0.68676573, -0.4769618 ],\n",
      "       [-2.7400525 , -2.8633797 , -2.4805877 ],\n",
      "       [ 0.06343138, -0.28809756, -0.8251947 ]], dtype=float32), array([-0.18327674, -0.6997253 , -0.92197335], dtype=float32)]\n",
      "weights layer: []\n",
      "weights layer: []\n",
      "weights layer: []\n",
      "weights layer: [array([[-0.3065117 ,  0.06689934, -0.02514514],\n",
      "       [ 0.58458525,  4.246983  , -2.5386071 ],\n",
      "       [ 0.6146006 ,  3.076344  , -2.154877  ]], dtype=float32), array([ 0.5827469 ,  0.04698804, -0.02520937], dtype=float32)]\n",
      "weights layer: [array([[ 1.3253919 ,  1.0859321 ,  0.16822048,  1.2735473 ,  0.14936742,\n",
      "         0.01229958,  1.2968209 ,  0.49555337, -0.5237247 ,  1.1256487 ,\n",
      "         4.553227  ,  1.7571086 ,  0.9811542 ,  0.46710363,  1.0648938 ,\n",
      "         1.1905077 ,  0.1395263 ,  1.9426577 ,  2.0571978 ,  0.76339775,\n",
      "         0.02398997,  0.89413935,  1.1612399 ,  0.5589326 ,  0.05441916,\n",
      "         0.518484  ,  1.3170114 ,  0.7993435 ,  0.06244888,  0.4126728 ],\n",
      "       [-0.16441496, -0.01394277, -0.3657266 ,  0.01837448, -0.06578124,\n",
      "         0.10342994,  0.19919719,  0.11967312,  0.03358276,  0.01449235,\n",
      "        -2.5293386 , -0.09155722, -0.06068851,  0.12721878, -0.71505314,\n",
      "         0.02258244, -0.04812336, -0.16576189, -0.22683935,  0.00898244,\n",
      "         0.15724784, -0.01842905,  0.15414053,  0.07858247, -0.10693508,\n",
      "         0.06982479, -1.9786443 ,  0.19586742,  0.00520673,  0.09398419],\n",
      "       [ 0.0540193 ,  0.10140901,  0.49197692, -0.09213516, -0.01002882,\n",
      "        -0.1280518 , -0.16661908,  0.02470607, -0.08371857,  0.16176467,\n",
      "         1.6781886 ,  0.20807758,  0.02472213,  0.07738426,  0.6186241 ,\n",
      "         0.29533678,  0.13204475,  0.19257523,  0.11025836, -0.11210311,\n",
      "         0.11331476, -0.05663574,  0.08464902, -0.07150129,  0.43249568,\n",
      "        -0.11762917,  1.5226513 , -0.15101646, -0.07592005, -0.32685632]],\n",
      "      dtype=float32), array([-1.0268139 , -0.42227787, -0.07565948,  0.20095633, -0.9528243 ,\n",
      "       -1.1507568 , -0.7447411 ,  0.09281369,  3.2841122 , -0.24955499,\n",
      "       -0.08828748,  0.09093103, -0.7106826 , -0.00416261, -3.3042686 ,\n",
      "       -0.10292058,  1.9829469 , -0.38319448, -0.4665375 , -0.24937427,\n",
      "       -0.09148265, -0.25559017,  0.16475649,  0.23204353,  0.0931647 ,\n",
      "        0.14366357,  0.31194866,  1.566767  , -1.043587  ,  1.1959703 ],\n",
      "      dtype=float32)]\n",
      "weights layer: []\n",
      "weights layer: []\n",
      "weights layer: []\n",
      "weights layer: [array([[ 1.3831968e+00,  1.3367175e+00, -2.8673372e+00],\n",
      "       [ 1.3553574e+00,  2.3243465e+00, -2.1867447e+00],\n",
      "       [-1.3681839e-01, -6.2749907e-02, -1.8279772e-01],\n",
      "       [ 4.3893498e-01,  1.2345335e+00, -1.9234584e-01],\n",
      "       [-5.8832439e-03, -4.5428121e-01, -3.7609925e+00],\n",
      "       [ 2.8191121e-02, -6.3083631e-01, -3.7003782e+00],\n",
      "       [-7.0780456e-02,  3.2794982e-01, -6.6376016e-02],\n",
      "       [ 7.9902875e-01,  7.1154809e-01, -3.4472985e+00],\n",
      "       [ 4.1565886e-01,  2.7828258e-01,  2.1784444e+00],\n",
      "       [ 1.4584433e+00,  2.5514472e+00, -2.1914773e+00],\n",
      "       [-2.0651071e+00, -3.3742032e+00,  8.2848817e-02],\n",
      "       [ 1.2282803e+00,  1.4762406e+00, -3.2366178e+00],\n",
      "       [ 1.8659574e-01,  1.8814270e-01, -2.4100958e-01],\n",
      "       [ 7.1255630e-01,  5.5207771e-01, -3.5521798e+00],\n",
      "       [ 1.9305768e+00,  1.1524688e+00, -2.0244973e+00],\n",
      "       [ 5.4803389e-01,  7.8255820e-01, -2.4295148e-01],\n",
      "       [ 6.4191841e-02,  1.9237006e-01,  7.7093881e-01],\n",
      "       [ 8.0270404e-01,  4.1514406e-01, -3.2578983e+00],\n",
      "       [ 5.7838440e-01, -4.1095395e-02, -3.2180109e+00],\n",
      "       [ 1.1466628e+00,  2.1782331e+00, -2.4469895e+00],\n",
      "       [ 1.5242482e-02,  2.2582680e-02,  2.4345061e-02],\n",
      "       [ 1.1717979e+00,  2.2560172e+00, -2.2733221e+00],\n",
      "       [ 1.1955115e+00,  2.6380310e+00, -2.2271757e+00],\n",
      "       [ 8.8593388e-01,  1.2605556e+00, -3.2522595e+00],\n",
      "       [-8.1146888e-02, -2.4971673e-03,  6.2504791e-02],\n",
      "       [ 9.5625061e-01,  9.4553119e-01, -3.4765601e+00],\n",
      "       [-2.2715276e-01,  2.8635231e-01,  1.2897792e+00],\n",
      "       [-1.4953710e-01, -4.2163992e-01, -9.1904825e-01],\n",
      "       [-1.2095636e-01, -5.8751214e-01, -4.0425663e+00],\n",
      "       [-2.4836656e-01, -4.9581010e-02,  1.6176586e-01]], dtype=float32), array([-0.38456634,  0.6187169 ,  6.043542  ], dtype=float32)]\n",
      "y_train shape: (43199, 3)\n",
      "y_hat_train_full_loop shape: (43199, 3)\n",
      "y_test shape: (4800, 3)\n",
      "y_hat_test_full_loop shape: (4800, 3)\n",
      "y_hat_train_loop shape: (43199, 3)\n",
      "predictions_train shape: (43199, 3, 2)\n",
      "y_hat_test_loop shape: (4800, 3)\n",
      "predictions_test shape: (4800, 3, 2)\n",
      "prediction_errors shape: (43199, 3)\n",
      "training_quality shape: (43199, 3, 2)\n",
      " \n",
      " \n",
      " \n",
      "----------------------------------------------------\n",
      "Feature Generation (Learning Phase): Score Generated\n",
      "----------------------------------------------------\n",
      " \n",
      " \n",
      " \n",
      "Time-Elapsed Training on Each Part: 155.27671122550964\n",
      " \n",
      " \n",
      " \n",
      "----------------------------------------------------\n",
      "---------------- Train Classifier ------------------\n",
      "---------------- Deep  Classifier ------------------\n",
      "----------------------------------------------------\n",
      " \n",
      " \n",
      " \n",
      "partition_labels_training_integers shape: (43199,)\n",
      "partition_labels_training_integers: [1 1 1 ... 1 1 1]\n",
      "partition_labels_training shape: (43199, 1)\n",
      "partition_labels_training:            0\n",
      "0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "...      ...\n",
      "43194  False\n",
      "43195  False\n",
      "43196  False\n",
      "43197  False\n",
      "43198  False\n",
      "\n",
      "[43199 rows x 1 columns]\n",
      "partition_labels_training_new shape: (43199, 3, 2)\n",
      "partition_labels_training_new: [[[0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]]\n",
      "\n",
      " [[0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]]\n",
      "\n",
      " [[0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]]\n",
      "\n",
      " [[0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]]\n",
      "\n",
      " [[0. 1.]\n",
      "  [0. 1.]\n",
      "  [0. 1.]]]\n",
      "Re-Load Grid and Redefine Relevant Input/Output dimensions in dictionary\n",
      "Deep Feature Builder - Ready\n",
      "Deep Classifier - Ready\n",
      "input_dim: 3\n",
      "output_dim: 2\n",
      "# epochs: [100]\n",
      "---- Train Deep Classifier ----\n",
      "Train on 43199 samples\n",
      "Epoch 1/100\n",
      "43199/43199 [==============================] - 6s 147us/sample - loss: 0.4584 - mse: 0.4060 - mae: 0.4584 - mape: 227637792.0000\n",
      "Epoch 2/100\n",
      "43199/43199 [==============================] - 6s 140us/sample - loss: 0.4614 - mse: 0.4603 - mae: 0.4614 - mape: 230635040.0000\n",
      "Epoch 3/100\n",
      "43199/43199 [==============================] - 6s 135us/sample - loss: 0.4611 - mse: 0.4609 - mae: 0.4611 - mape: 230518000.0000\n",
      "Epoch 4/100\n",
      "43199/43199 [==============================] - 6s 144us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230498112.0000\n",
      "Epoch 5/100\n",
      "43199/43199 [==============================] - 6s 136us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230493280.0000\n",
      "Epoch 6/100\n",
      "43199/43199 [==============================] - 6s 134us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230491616.0000\n",
      "Epoch 7/100\n",
      "43199/43199 [==============================] - 5s 127us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230491328.0000\n",
      "Epoch 8/100\n",
      "43199/43199 [==============================] - 6s 139us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490928.0000\n",
      "Epoch 9/100\n",
      "43199/43199 [==============================] - 6s 130us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490960.0000\n",
      "Epoch 10/100\n",
      "43199/43199 [==============================] - 6s 141us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490976.0000\n",
      "Epoch 11/100\n",
      "43199/43199 [==============================] - 6s 138us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230491056.0000\n",
      "Epoch 12/100\n",
      "43199/43199 [==============================] - 6s 139us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490736.0000\n",
      "Epoch 13/100\n",
      "43199/43199 [==============================] - 6s 144us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490832.0000\n",
      "Epoch 14/100\n",
      "43199/43199 [==============================] - 6s 146us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490544.0000\n",
      "Epoch 15/100\n",
      "43199/43199 [==============================] - 6s 144us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490864.0000\n",
      "Epoch 16/100\n",
      "43199/43199 [==============================] - 6s 135us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490928.0000\n",
      "Epoch 17/100\n",
      "43199/43199 [==============================] - 6s 136us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490768.0000\n",
      "Epoch 18/100\n",
      "43199/43199 [==============================] - 6s 138us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490768.0000\n",
      "Epoch 19/100\n",
      "43199/43199 [==============================] - 6s 143us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490864.0000\n",
      "Epoch 20/100\n",
      "43199/43199 [==============================] - 6s 131us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490832.0000\n",
      "Epoch 21/100\n",
      "43199/43199 [==============================] - 6s 138us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490720.0000\n",
      "Epoch 22/100\n",
      "43199/43199 [==============================] - 6s 141us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490832.0000\n",
      "Epoch 23/100\n",
      "43199/43199 [==============================] - 6s 136us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490816.0000\n",
      "Epoch 24/100\n",
      "43199/43199 [==============================] - 6s 147us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490864.0000\n",
      "Epoch 25/100\n",
      "43199/43199 [==============================] - 6s 143us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490864.0000\n",
      "Epoch 26/100\n",
      "43199/43199 [==============================] - 6s 145us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490864.0000\n",
      "Epoch 27/100\n",
      "43199/43199 [==============================] - 6s 147us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490720.0000\n",
      "Epoch 28/100\n",
      "43199/43199 [==============================] - 6s 143us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230491232.0000\n",
      "Epoch 29/100\n",
      "43199/43199 [==============================] - 6s 141us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490928.0000\n",
      "Epoch 30/100\n",
      "43199/43199 [==============================] - 6s 134us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490928.0000\n",
      "Epoch 31/100\n",
      "43199/43199 [==============================] - 6s 129us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490864.0000\n",
      "Epoch 32/100\n",
      "43199/43199 [==============================] - 6s 139us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490832.0000\n",
      "Epoch 33/100\n",
      "43199/43199 [==============================] - 6s 143us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230491024.0000\n",
      "Epoch 34/100\n",
      "43199/43199 [==============================] - 6s 129us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490928.0000\n",
      "Epoch 35/100\n",
      "43199/43199 [==============================] - 6s 137us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490720.0000\n",
      "Epoch 36/100\n",
      "43199/43199 [==============================] - 6s 140us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490960.0000\n",
      "Epoch 37/100\n",
      "43199/43199 [==============================] - 6s 137us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490880.0000\n",
      "Epoch 38/100\n",
      "43199/43199 [==============================] - 6s 140us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490864.0000\n",
      "Epoch 39/100\n",
      "43199/43199 [==============================] - 6s 139us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490912.0000\n",
      "Epoch 40/100\n",
      "43199/43199 [==============================] - 6s 132us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490960.0000\n",
      "Epoch 41/100\n",
      "43199/43199 [==============================] - 6s 144us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490768.0000\n",
      "Epoch 42/100\n",
      "43199/43199 [==============================] - 6s 139us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490768.0000\n",
      "Epoch 43/100\n",
      "43199/43199 [==============================] - 6s 130us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490736.0000\n",
      "Epoch 44/100\n",
      "43199/43199 [==============================] - 6s 134us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490736.0000\n",
      "Epoch 45/100\n",
      "43199/43199 [==============================] - 6s 137us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230491008.0000\n",
      "Epoch 46/100\n",
      "43199/43199 [==============================] - 6s 143us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490912.0000\n",
      "Epoch 47/100\n",
      "43199/43199 [==============================] - 6s 138us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490720.0000\n",
      "Epoch 48/100\n",
      "43199/43199 [==============================] - 6s 143us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490736.0000\n",
      "Epoch 49/100\n",
      "43199/43199 [==============================] - 6s 137us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490640.0000\n",
      "Epoch 50/100\n",
      "43199/43199 [==============================] - 6s 148us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230491168.0000\n",
      "Epoch 51/100\n",
      "43199/43199 [==============================] - 6s 140us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490960.0000\n",
      "Epoch 52/100\n",
      "43199/43199 [==============================] - 6s 135us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490768.0000\n",
      "Epoch 53/100\n",
      "43199/43199 [==============================] - 6s 136us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490736.0000\n",
      "Epoch 54/100\n",
      "43199/43199 [==============================] - 7s 157us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230491024.0000\n",
      "Epoch 55/100\n",
      "43199/43199 [==============================] - 6s 136us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490960.0000\n",
      "Epoch 56/100\n",
      "43199/43199 [==============================] - 7s 160us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490880.0000\n",
      "Epoch 57/100\n",
      "43199/43199 [==============================] - 6s 149us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490912.0000\n",
      "Epoch 58/100\n",
      "43199/43199 [==============================] - 6s 140us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490816.0000\n",
      "Epoch 59/100\n",
      "43199/43199 [==============================] - 6s 140us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490768.0000\n",
      "Epoch 60/100\n",
      "43199/43199 [==============================] - 6s 142us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490864.0000\n",
      "Epoch 61/100\n",
      "43199/43199 [==============================] - 7s 156us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490544.0000\n",
      "Epoch 62/100\n",
      "43199/43199 [==============================] - 7s 155us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490960.0000\n",
      "Epoch 63/100\n",
      "43199/43199 [==============================] - 6s 144us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490816.0000\n",
      "Epoch 64/100\n",
      "43199/43199 [==============================] - 6s 149us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490976.0000\n",
      "Epoch 65/100\n",
      "43199/43199 [==============================] - 6s 140us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490736.0000\n",
      "Epoch 66/100\n",
      "43199/43199 [==============================] - 6s 136us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490880.0000\n",
      "Epoch 67/100\n",
      "43199/43199 [==============================] - 6s 131us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490960.0000\n",
      "Epoch 68/100\n",
      "43199/43199 [==============================] - 6s 130us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490736.0000\n",
      "Epoch 69/100\n",
      "43199/43199 [==============================] - 5s 126us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490912.0000\n",
      "Epoch 70/100\n",
      "43199/43199 [==============================] - 5s 122us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490864.0000\n",
      "Epoch 71/100\n",
      "43199/43199 [==============================] - 6s 138us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490880.0000\n",
      "Epoch 72/100\n",
      "43199/43199 [==============================] - 5s 124us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490736.0000\n",
      "Epoch 73/100\n",
      "43199/43199 [==============================] - 6s 138us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490688.0000\n",
      "Epoch 74/100\n",
      "43199/43199 [==============================] - 6s 136us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490864.0000\n",
      "Epoch 75/100\n",
      "43199/43199 [==============================] - 6s 128us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490912.0000\n",
      "Epoch 76/100\n",
      "43199/43199 [==============================] - 6s 139us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230491024.0000\n",
      "Epoch 77/100\n",
      "43199/43199 [==============================] - 6s 140us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490816.0000\n",
      "Epoch 78/100\n",
      "43199/43199 [==============================] - 6s 138us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490912.0000\n",
      "Epoch 79/100\n",
      "43199/43199 [==============================] - 6s 137us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230491104.0000\n",
      "Epoch 80/100\n",
      "43199/43199 [==============================] - 6s 131us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490912.0000\n",
      "Epoch 81/100\n",
      "43199/43199 [==============================] - 5s 117us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490912.0000\n",
      "Epoch 82/100\n",
      "43199/43199 [==============================] - 6s 128us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490816.0000\n",
      "Epoch 83/100\n",
      "43199/43199 [==============================] - 6s 130us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490816.0000\n",
      "Epoch 84/100\n",
      "43199/43199 [==============================] - 6s 131us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490912.0000\n",
      "Epoch 85/100\n",
      "43199/43199 [==============================] - 6s 140us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230491168.0000\n",
      "Epoch 86/100\n",
      "43199/43199 [==============================] - 6s 134us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490784.0000\n",
      "Epoch 87/100\n",
      "43199/43199 [==============================] - 6s 133us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490912.0000\n",
      "Epoch 88/100\n",
      "43199/43199 [==============================] - 6s 142us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490912.0000\n",
      "Epoch 89/100\n",
      "43199/43199 [==============================] - 6s 141us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230491120.0000\n",
      "Epoch 90/100\n",
      "43199/43199 [==============================] - 6s 140us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490912.0000\n",
      "Epoch 91/100\n",
      "43199/43199 [==============================] - 6s 149us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490736.0000\n",
      "Epoch 92/100\n",
      "43199/43199 [==============================] - 6s 143us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490816.0000\n",
      "Epoch 93/100\n",
      "43199/43199 [==============================] - 6s 135us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490832.0000\n",
      "Epoch 94/100\n",
      "43199/43199 [==============================] - 6s 129us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230491024.0000\n",
      "Epoch 95/100\n",
      "43199/43199 [==============================] - 5s 124us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490880.0000\n",
      "Epoch 96/100\n",
      "43199/43199 [==============================] - 6s 128us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490864.0000\n",
      "Epoch 97/100\n",
      "43199/43199 [==============================] - 5s 125us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490720.0000\n",
      "Epoch 98/100\n",
      "43199/43199 [==============================] - 5s 126us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490784.0000\n",
      "Epoch 99/100\n",
      "43199/43199 [==============================] - 6s 133us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490768.0000\n",
      "Epoch 100/100\n",
      "43199/43199 [==============================] - 6s 136us/sample - loss: 0.4610 - mse: 0.4610 - mae: 0.4610 - mape: 230490864.0000\n",
      "predicted_classes_train shape: (43199, 2)\n",
      "predicted_classes_train_update shape: (43199, 3, 2)\n",
      "predictions_train shape : (43199, 3, 2)\n",
      "predicted_classes_test shape: (4800, 2)\n",
      "predicted_classes_test_update shape: (4800, 3, 2)\n",
      "predictions_test shape : (4800, 3, 2)\n",
      "X_manifold Empty DataFrame\n",
      "Columns: [x, y, z]\n",
      "Index: []\n",
      "=============================\n",
      "=============================\n",
      "y_manifold Empty DataFrame\n",
      "Columns: [x, y, z]\n",
      "Index: []\n",
      "=============================\n",
      "=============================\n",
      "X_parts_list [Empty DataFrame\n",
      "Columns: [x, y, z]\n",
      "Index: []]\n",
      "=============================\n",
      "=============================\n",
      "y_parts_list [Empty DataFrame\n",
      "Columns: [x, y, z]\n",
      "Index: []]\n",
      "X_manifold               x         y          z\n",
      "0      5.894076 -6.415820  -8.194456\n",
      "1      4.821934 -4.429324  -8.263782\n",
      "2      4.022918 -2.797976  -8.203039\n",
      "3      3.441617 -1.433997  -8.064589\n",
      "4      3.035476 -0.265226  -7.879283\n",
      "...         ...       ...        ...\n",
      "43194 -8.092295 -4.927387  30.282290\n",
      "43195 -7.780484 -4.714503  29.862659\n",
      "43196 -7.480086 -4.542631  29.425034\n",
      "43197 -7.193820 -4.409718  28.974508\n",
      "43198 -6.923939 -4.313410  28.515588\n",
      "\n",
      "[43199 rows x 3 columns]\n",
      "=============================\n",
      "=============================\n",
      "y_manifold               x         y          z\n",
      "0      4.821934 -4.429324  -8.263782\n",
      "1      4.022918 -2.797976  -8.203039\n",
      "2      3.441617 -1.433997  -8.064589\n",
      "3      3.035476 -0.265226  -7.879283\n",
      "4      2.772190  0.767175  -7.664677\n",
      "...         ...       ...        ...\n",
      "43194  8.863777  9.073592  27.197825\n",
      "43195  8.882687  9.050673  27.275690\n",
      "43196  8.897304  9.021341  27.350710\n",
      "43197  8.907440  8.985900  27.422011\n",
      "43198  8.912959  8.944733  27.488760\n",
      "\n",
      "[43199 rows x 3 columns]\n",
      "=============================\n",
      "=============================\n",
      "X_parts_list [Empty DataFrame\n",
      "Columns: [x, y, z]\n",
      "Index: [],               x         y          z\n",
      "0      5.894076 -6.415820  -8.194456\n",
      "1      4.821934 -4.429324  -8.263782\n",
      "2      4.022918 -2.797976  -8.203039\n",
      "3      3.441617 -1.433997  -8.064589\n",
      "4      3.035476 -0.265226  -7.879283\n",
      "...         ...       ...        ...\n",
      "43194 -8.092295 -4.927387  30.282290\n",
      "43195 -7.780484 -4.714503  29.862659\n",
      "43196 -7.480086 -4.542631  29.425034\n",
      "43197 -7.193820 -4.409718  28.974508\n",
      "43198 -6.923939 -4.313410  28.515588\n",
      "\n",
      "[43199 rows x 3 columns]]\n",
      "=============================\n",
      "=============================\n",
      "y_parts_list [Empty DataFrame\n",
      "Columns: [x, y, z]\n",
      "Index: [],               x         y          z\n",
      "0      4.821934 -4.429324  -8.263782\n",
      "1      4.022918 -2.797976  -8.203039\n",
      "2      3.441617 -1.433997  -8.064589\n",
      "3      3.035476 -0.265226  -7.879283\n",
      "4      2.772190  0.767175  -7.664677\n",
      "...         ...       ...        ...\n",
      "43194  8.863777  9.073592  27.197825\n",
      "43195  8.882687  9.050673  27.275690\n",
      "43196  8.897304  9.021341  27.350710\n",
      "43197  8.907440  8.985900  27.422011\n",
      "43198  8.912959  8.944733  27.488760\n",
      "\n",
      "[43199 rows x 3 columns]]\n",
      "epochs for training interaction: 2\n",
      " \n",
      " \n",
      " \n",
      "----------------------------------------------------\n",
      "---------- Train each FFNN on each part ------------\n",
      "---------------- Deep  Classifier ------------------\n",
      "----------------------------------------------------\n",
      " \n",
      " \n",
      " \n",
      "[0. 1.]\n",
      "param_grid_Vanilla_Nets - input dim: [3]\n",
      "param_grid_Vanilla_Nets - output dim: [3]\n",
      "Status: Current part: 0 out of : 2 parts.\n",
      "Heights to iterate over: [30, 3, 3, 30]\n",
      "TYPE y_train: <class 'pandas.core.frame.DataFrame'>\n",
      "height: [30, 3, 3, 30]\n",
      "height1: 30 height2: 3 height3: 3\n",
      "INPUT LAYER: Tensor(\"input_7:0\", shape=(None, 3), dtype=float32) <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Y_TRAIN: [[ 4.82193361 -4.42932378 -8.2637822 ]\n",
      " [ 4.02291799 -2.79797594 -8.20303867]\n",
      " [ 3.44161713 -1.43399725 -8.06458898]\n",
      " ...\n",
      " [ 8.8973036   9.0213413  27.35070993]\n",
      " [ 8.90743987  8.98589956 27.42201135]\n",
      " [ 8.9129585   8.94473304 27.48875975]] <class 'numpy.ndarray'>\n",
      "CHECK 1 CHECK 1 ####################\n",
      "Train on 0 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Empty training data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-54a8de6a2592>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     96\u001b[0m                                                                                           \u001b[0mX_test_partial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                                                                                           \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                                                                                           NOCV=True)\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;31m#put shape formats in order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid_Vanilla_Nets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output_dim'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mbuild_ffNN\u001b[0;34m(n_folds, n_jobs, n_iter, param_grid_in, X_train, y_train, X_test_partial, X_test, NOCV)\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/Documents/venv3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/Documents/venv3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m           \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m     \u001b[0maggregator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/venv3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mfinalize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Empty training data.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Empty training data."
     ]
    }
   ],
   "source": [
    "epochs_training_interaction = 10\n",
    "for ntrain_interaction in range(epochs_training_interaction):\n",
    "    print('epochs for training interaction:',ntrain_interaction)\n",
    "    #############################################################\n",
    "    #############################################################\n",
    "    ############--- Train each FFNN on each part ---#############\n",
    "    #############################################################\n",
    "    #############################################################\n",
    "    print(' ')\n",
    "    print(' ')\n",
    "    print(' ')\n",
    "    print('----------------------------------------------------')\n",
    "    print('---------- Train each FFNN on each part ------------')\n",
    "    print('---------------- Deep  Classifier ------------------')\n",
    "    print('----------------------------------------------------')\n",
    "    print(' ')\n",
    "    print(' ')\n",
    "    print(' ')\n",
    "    # Time-Elapse (Start) for Training on Each Part\n",
    "    Architope_partition_training_begin = time.time()\n",
    "    # Initialize running max for Parallel time\n",
    "    Architope_partitioning_max_time_running = -math.inf # Initialize slowest-time at - infinity to force updating!\n",
    "    # Initialize N_parameter counter for Architope\n",
    "    N_params_Architope = 0\n",
    "    #\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    # Silly Coercsion for ICML rebuttle deadline timeline\n",
    "    if Option_Function == 'Motivational_Example':\n",
    "        Iteration_Length = len(X_parts_list) -1\n",
    "    else:\n",
    "        Iteration_Length = len(X_parts_list)\n",
    "    #\n",
    "    N_modify0 = []\n",
    "    for kk in range(Iteration_Length):\n",
    "        N_modify0 = np.append(N_modify0,(len(X_parts_list[kk])))\n",
    "    #\n",
    "    N_modify_tot = sum(N_modify0)\n",
    "    #\n",
    "    N_modify = []\n",
    "    for jj in range(Iteration_Length):\n",
    "        N_modify = np.append(N_modify,(len(X_parts_list[jj])/N_modify_tot))\n",
    "    #\n",
    "    print(N_modify)\n",
    "    #\n",
    "    # Train each part!\n",
    "    for current_part in range(Iteration_Length):\n",
    "        #==============#\n",
    "        # Timer(begin) #\n",
    "        #==============#\n",
    "        current_part_training_time_for_parallel_begin = time.time()\n",
    "        #\n",
    "        Iteration_Length = len(X_parts_list)\n",
    "        #\n",
    "        #    \n",
    "        # Initializations #\n",
    "        #-----------------#\n",
    "        # Reload Grid\n",
    "        exec(open('Grid_Enhanced_Network.py').read())\n",
    "        # Modify heights according to optimal (data-driven) rule (with threshold)\n",
    "        ## current_height = np.ceil(np.array(param_grid_Vanilla_Nets['height'])*N_ratios[current_part])\n",
    "        ## print('N_ratios',N_ratios,'Iteration_Length',Iteration_Length)\n",
    "        ##################################################################################################\n",
    "        ##################################################################################################\n",
    "        ##################################################################################################\n",
    "        # Modify heights of the ANN in order to make it more interpretable for our approach\n",
    "        current_height = np.ceil(np.array(param_grid_Vanilla_Nets['height']))#*N_modify[current_part])\n",
    "        ##################################################################################################\n",
    "        ##################################################################################################\n",
    "        current_height_threshold = np.repeat(min_height,(current_height.shape[0]))\n",
    "        current_height = np.maximum(current_height,current_height_threshold)\n",
    "        current_height = current_height.astype(int).tolist()\n",
    "        # current_height = X_parts_list.shape[curerent_part,row]\n",
    "        param_grid_Vanilla_Nets['height'] = current_height\n",
    "        # Automatically Fix Input Dimension\n",
    "        param_grid_Vanilla_Nets['input_dim'] = [X_train.shape[1]]\n",
    "        param_grid_Vanilla_Nets['output_dim'] = [3]\n",
    "        print('param_grid_Vanilla_Nets - input dim:',param_grid_Vanilla_Nets['input_dim'])\n",
    "        print('param_grid_Vanilla_Nets - output dim:',param_grid_Vanilla_Nets['output_dim'])\n",
    "        #\n",
    "        # Update User #\n",
    "        #-------------#\n",
    "        print('Status: Current part: ' + str(current_part) + ' out of : '+str(len(X_parts_list)) +' parts.')\n",
    "        print('Heights to iterate over: '+str(current_height))\n",
    "        #\n",
    "        # Generate Prediction(s) on current Part #\n",
    "        #----------------------------------------#\n",
    "        # Failsafe (number of data-points)\n",
    "        CV_folds_failsafe = min(CV_folds,max(1,(X_train.shape[0]-1)))\n",
    "        # Train Network\n",
    "        y_hat_train_full_loop, y_hat_test_full_loop, N_params_Architope_loop = build_ffNN(n_folds = CV_folds_failsafe, \n",
    "                                                                                          n_jobs = n_jobs,\n",
    "                                                                                          n_iter = n_iter, \n",
    "                                                                                          param_grid_in = param_grid_Vanilla_Nets, \n",
    "                                                                                          X_train= X_parts_list[current_part], \n",
    "                                                                                          y_train=y_parts_list[current_part],\n",
    "                                                                                          X_test_partial=X_train,\n",
    "                                                                                          X_test=X_test,\n",
    "                                                                                          NOCV=True)\n",
    "        #put shape formats in order\n",
    "        y_train.shape = (y_train.shape[0], param_grid_Vanilla_Nets['output_dim'][0])\n",
    "        y_hat_train_full_loop.shape = (y_hat_train_full_loop.shape[0], param_grid_Vanilla_Nets['output_dim'][0])\n",
    "        y_test.shape = (y_test.shape[0], param_grid_Vanilla_Nets['output_dim'][0])\n",
    "        y_hat_test_full_loop.shape = (y_hat_test_full_loop.shape[0], param_grid_Vanilla_Nets['output_dim'][0])\n",
    "        print('y_train shape:',y_train.shape)\n",
    "        print('y_hat_train_full_loop shape:',y_hat_train_full_loop.shape)\n",
    "        print('y_test shape:',y_test.shape)\n",
    "        print('y_hat_test_full_loop shape:',y_hat_test_full_loop.shape)\n",
    "        # Append predictions to data-frames\n",
    "        ## If first prediction we initialize data-frames\n",
    "        if current_part==0:\n",
    "            # Register quality\n",
    "            training_quality = np.array(np.abs(y_hat_train_full_loop-y_train))\n",
    "            print('training_quality shape:',training_quality.shape)\n",
    "            #training_quality = training_quality.reshape(training_quality.shape[0],1)\n",
    "            #print('training_quality shape after reshape:',training_quality.shape)\n",
    "            #\n",
    "            # Save Predictions\n",
    "            predictions_train = y_hat_train_full_loop\n",
    "            #predictions_train = predictions_train.reshape(predictions_train.shape[0],1)\n",
    "            predictions_test = y_hat_test_full_loop\n",
    "            #predictions_test = predictions_test.reshape(predictions_test.shape[0],1)\n",
    "            #\n",
    "            #        \n",
    "        ## If not first prediction we append to already initialized dataframes\n",
    "        else:\n",
    "            # Register Best Scores\n",
    "            #----------------------#\n",
    "            # Write Predictions \n",
    "            # Save Predictions\n",
    "            y_hat_train_loop = y_hat_train_full_loop.reshape(predictions_train.shape[0],predictions_train.shape[1])\n",
    "            print('y_hat_train_loop shape:',y_hat_train_loop.shape)\n",
    "            predictions_train = np.dstack([predictions_train,y_hat_train_loop]) # stack along a new axis in last axis of the result\n",
    "            print('predictions_train shape:',predictions_train.shape)\n",
    "            y_hat_test_loop = y_hat_test_full_loop.reshape(predictions_test.shape[0],predictions_test.shape[1])\n",
    "            print('y_hat_test_loop shape:',y_hat_test_loop.shape)\n",
    "            predictions_test = np.dstack([predictions_test,y_hat_test_loop]) # stack along a new axis in last axis of the result\n",
    "            print('predictions_test shape:',predictions_test.shape)\n",
    "            #\n",
    "            # Evaluate Errors #\n",
    "            #-----------------#\n",
    "            # Training\n",
    "            prediction_errors = np.abs(y_hat_train_loop-y_train)\n",
    "            print('prediction_errors shape:', prediction_errors.shape)\n",
    "            training_quality = np.dstack([training_quality,prediction_errors.reshape(training_quality.shape[0],training_quality.shape[1])])\n",
    "            print('training_quality shape:', training_quality.shape)\n",
    "            #\n",
    "        #============#\n",
    "        # Timer(end) #\n",
    "        #============#\n",
    "        current_part_training_time_for_parallel = time.time() - current_part_training_time_for_parallel_begin\n",
    "        Architope_partitioning_max_time_running = max(Architope_partitioning_max_time_running,current_part_training_time_for_parallel)\n",
    "        #\n",
    "        #============---===============#\n",
    "        #\n",
    "        # N_parameter Counter (Update) #\n",
    "        #------------===---------------#\n",
    "        N_params_Architope = N_params_Architope + N_params_Architope_loop\n",
    "        #\n",
    "    # Update User\n",
    "    #-------------#\n",
    "    print(' ')\n",
    "    print(' ')\n",
    "    print(' ')\n",
    "    print('----------------------------------------------------')\n",
    "    print('Feature Generation (Learning Phase): Score Generated')\n",
    "    print('----------------------------------------------------')\n",
    "    print(' ')\n",
    "    print(' ')\n",
    "    print(' ')\n",
    "    #\n",
    "    # Time-Elapsed Training on Each Part\n",
    "    Architope_partition_training = time.time() - Architope_partition_training_begin\n",
    "    print('Time-Elapsed Training on Each Part:', Architope_partition_training)\n",
    "    #\n",
    "    #############################################################\n",
    "    #############################################################\n",
    "    ###################-- Train Classifier --####################\n",
    "    #############################################################\n",
    "    #############################################################\n",
    "    print(' ')\n",
    "    print(' ')\n",
    "    print(' ')\n",
    "    print('----------------------------------------------------')\n",
    "    print('---------------- Train Classifier ------------------')\n",
    "    print('---------------- Deep  Classifier ------------------')\n",
    "    print('----------------------------------------------------')\n",
    "    print(' ')\n",
    "    print(' ')\n",
    "    print(' ')\n",
    "    #Deep Classifier\n",
    "    #Prepare Labels/Classes\n",
    "    # Time-Elapsed Training Deep Classifier\n",
    "    Architope_deep_classifier_training_begin = time.time()\n",
    "    # Initialize Classes Labels\n",
    "    partition_labels_training_integers = np.argmin(np.sum(training_quality, axis=1),axis=-1)\n",
    "    print('partition_labels_training_integers shape:', partition_labels_training_integers.shape)\n",
    "    print('partition_labels_training_integers:', partition_labels_training_integers)\n",
    "    partition_labels_training = pd.DataFrame(pd.DataFrame(partition_labels_training_integers) == 0)\n",
    "    print('partition_labels_training shape:', partition_labels_training.shape)\n",
    "    print('partition_labels_training:', partition_labels_training)\n",
    "    # Build Classes\n",
    "    for part_column_i in range(1,(training_quality.shape[-1])):\n",
    "        partition_labels_training = pd.concat([partition_labels_training,\n",
    "                                               (pd.DataFrame(partition_labels_training_integers) == part_column_i)\n",
    "                                              ],axis=1)\n",
    "    # Convert to integers\n",
    "    partition_labels_training = partition_labels_training+0\n",
    "    partition_labels_training_new = np.zeros(predictions_train.shape)\n",
    "    for jj in range(X_train.shape[1]):\n",
    "        partition_labels_training_new[:,jj,:] = partition_labels_training\n",
    "    #\n",
    "    print('partition_labels_training_new shape:', partition_labels_training_new.shape)\n",
    "    print('partition_labels_training_new:', partition_labels_training_new)\n",
    "    #Re-Load Grid and Redefine Relevant Input/Output dimensions in dictionary.\n",
    "    print('Re-Load Grid and Redefine Relevant Input/Output dimensions in dictionary')\n",
    "    # Re-Load Hyper-parameter Grid\n",
    "    exec(open('Grid_Enhanced_Network.py').read())\n",
    "    # Re-Load Helper Function(s)\n",
    "    exec(open('Helper_Functions.py').read())\n",
    "    param_grid_Deep_Classifier['input_dim'] = [X_train.shape[1]]\n",
    "    print('input_dim:', X_train.shape[1])\n",
    "    param_grid_Deep_Classifier['output_dim'] = [partition_labels_training_new.shape[-1]]\n",
    "    print('output_dim:', partition_labels_training_new.shape[-1])\n",
    "    param_grid_Deep_Classifier['epochs'] = [int(np.maximum(round(param_grid_Deep_Classifier['epochs'][0]),min_epochs_classifier))]\n",
    "    print('# epochs:',param_grid_Deep_Classifier['epochs'])\n",
    "    print('---- Train Deep Classifier ----')\n",
    "    # Train simple deep classifier\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    predicted_classes_train, predicted_classes_test, N_params_deep_classifier = build_simple_deep_classifier(n_folds = CV_folds, \n",
    "                                                                                                             n_jobs = n_jobs, \n",
    "                                                                                                             n_iter =n_iter, \n",
    "                                                                                                             param_grid_in=param_grid_Deep_Classifier, \n",
    "                                                                                                             X_train = X_train.values, \n",
    "                                                                                                             y_train = partition_labels_training.values,\n",
    "                                                                                                             X_test = X_test.values)\n",
    "    # COMMENT: .values() is used to convert the Pandas Dataframes here, and not in the vanilla ffNNs, since the former is coded in Keras and the latter in tensorflow.\n",
    "    # Time-Elapsed Training Deep Classifier\n",
    "    Architope_deep_classifier_training = time.time() - Architope_deep_classifier_training_begin\n",
    "    \n",
    "    #GET BINARY CLASSES (DISCONTINUOUS UNIT)\n",
    "    # Training Set\n",
    "    predicted_classes_train = ((predicted_classes_train>.5)*1).astype(int)\n",
    "    #### OLD: Architope_prediction_y_train = np.take_along_axis(predictions_train, predicted_classes_train[:,None], axis=1)\n",
    "    # Testing Set\n",
    "    predicted_classes_test = ((predicted_classes_test > .5)*1).astype(int)\n",
    "    #### OLD: Architope_prediction_y_test = np.take_along_axis(predictions_test, predicted_classes_test[:,None], axis=1)\n",
    "    \n",
    "    #UPDATE to improve the interaction between the clustering and the regression problem\n",
    "    # Train\n",
    "    predicted_classes_train_update = np.zeros(predictions_train.shape)\n",
    "    for jj in range(X_train.shape[1]):\n",
    "        predicted_classes_train_update[:,jj,:] = predicted_classes_train\n",
    "    \n",
    "    \n",
    "    print('predicted_classes_train shape:', predicted_classes_train.shape)\n",
    "    print('predicted_classes_train_update shape:', predicted_classes_train_update.shape)\n",
    "    print('predictions_train shape :', predictions_train.shape)\n",
    "    \n",
    "    # Test\n",
    "    predicted_classes_test_update = np.zeros(predictions_test.shape)\n",
    "    for jj in range(X_test.shape[1]):\n",
    "        predicted_classes_test_update[:,jj,:] = predicted_classes_test\n",
    "    \n",
    "    \n",
    "    print('predicted_classes_test shape:', predicted_classes_test.shape)\n",
    "    print('predicted_classes_test_update shape:', predicted_classes_test_update.shape)\n",
    "    print('predictions_test shape :', predictions_test.shape)\n",
    "    \n",
    "    X_parts_list = list()\n",
    "    y_parts_list = list()\n",
    "    #X_parts_list = np.zeros(predictions_test.shape)\n",
    "    #y_parts_list = np.zeros(predictions_test.shape)\n",
    "    num_kkkk = predictions_test[1,1,:].shape\n",
    "    num_kkkk = int(num_kkkk[0])\n",
    "    for kkkk in range(num_kkkk):\n",
    "        X_manifold = []\n",
    "        Elementindex = []\n",
    "        elementindex = int(-1)\n",
    "        while True:\n",
    "            try:\n",
    "                predicted_classes_train_update1 = []\n",
    "                predicted_classes_train_update1 = predicted_classes_train_update[:,1,kkkk]\n",
    "                predicted_classes_train_update1 = predicted_classes_train_update1.tolist()\n",
    "                elementindex = predicted_classes_train_update1.index(1,elementindex+1) #here we can fix the dimension 1 because in this step procedure we look for only the occurence of a model\n",
    "                Elementindex.append(elementindex)\n",
    "            except  ValueError:\n",
    "                break\n",
    "        #print(\"Element index \", Elementindex)\n",
    "        X_manifold = X_train.iloc[Elementindex]\n",
    "        y_manifold = data_y.iloc[Elementindex]\n",
    "        print('X_manifold',X_manifold)\n",
    "        print('=============================')\n",
    "        print('=============================')\n",
    "        print('y_manifold',y_manifold)\n",
    "        print('=============================')\n",
    "        print('=============================')\n",
    "        #X_manifold = X_manifold.tolist()\n",
    "        X_parts_list.append(X_manifold)\n",
    "        y_parts_list.append(y_manifold)\n",
    "        print('X_parts_list',X_parts_list)\n",
    "        print('=============================')\n",
    "        print('=============================')\n",
    "        print('y_parts_list',y_parts_list)\n",
    "        #print('kkkk',kkkk)\n",
    "        \n",
    "    #print('X_manifold',X_manifold)\n",
    "    #print('X_parts_list',X_parts_list)\n",
    "    #print('=============================')\n",
    "    #print('=============================')\n",
    "    #print('y_manifold',y_manifold)\n",
    "    #print('y_parts_list',y_parts_list)\n",
    "    #print('kkkk',kkkk)\n",
    "        \n",
    "        #y_parts_list[:,:,kkkk] = data_y.iloc[Elementindex]\n",
    "        #X_train_list.append(X_train[Elementindex,:])\n",
    "        #print('X_train_list_shape',X_train_list.shape)\n",
    "        #print('X_train_list',X_train_list)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('predictions_test shape',predictions_test[1,1,:].shape)\n",
    "#A = predictions_test[1,1,:].shape\n",
    "#A = int(A[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Binary Classes (Discontinuous Unit)\n",
    "Maps deep classifier's outputs $\\tilde{C}(x)\\triangleq \\hat{s}(x)$ to deep zero-sets $I_{(.5,1]}\\circ \\sigma_{\\mbox{sigmoid}}(\\tilde{C}(x))$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get PC-NN Prediction(s)\n",
    "Comuptes $\\sum_{n=1}^N \\, \\hat{f}(x)\\cdot I_{K_n}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "predicted_classes_train_new = np.zeros(predictions_train.shape)\n",
    "for jj in range(X_train.shape[1]):\n",
    "    predicted_classes_train_new[:,jj,:] = predicted_classes_train\n",
    "    \n",
    "print('predicted_classes_train shape:', predicted_classes_train.shape)\n",
    "print('predicted_classes_train_new shape:', predicted_classes_train_new.shape)\n",
    "print('predictions_train shape :', predictions_train.shape)\n",
    "Architope_prediction_y_train = (predictions_train*predicted_classes_train_new).sum(axis=-1)\n",
    "print('Architope_prediction_y_train shape :', Architope_prediction_y_train.shape)\n",
    "Architope_manifolds_prediction_y_train = (predictions_train*predicted_classes_train_new)\n",
    "print('Architope_manifolds_prediction_y_train shape :', Architope_manifolds_prediction_y_train.shape)\n",
    "\n",
    "\n",
    "# Test\n",
    "predicted_classes_test_new = np.zeros(predictions_test.shape)\n",
    "for jj in range(X_test.shape[1]):\n",
    "    predicted_classes_test_new[:,jj,:] = predicted_classes_test\n",
    "    \n",
    "print('predicted_classes_test shape:', predicted_classes_test.shape)\n",
    "print('predicted_classes_test_new shape:', predicted_classes_test_new.shape)\n",
    "print('predictions_test shape :', predictions_test.shape)\n",
    "Architope_prediction_y_test = (predictions_test*predicted_classes_test_new).sum(axis=-1)\n",
    "print('Architope_prediction_y_test shape :', Architope_prediction_y_test.shape)\n",
    "Architope_manifolds_prediction_y_test = (predictions_test*predicted_classes_test_new)\n",
    "print('Architope_manifolds_prediction_y_test shape :', Architope_manifolds_prediction_y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, Architope_prediction_y_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "# Plot PC-NN prediction(s)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from scipy import integrate\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "rcParams.update({'font.size':10})\n",
    "plt.rcParams['figure.figsize'] = [12, 12]\n",
    "\n",
    "num_traj = 1;\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "y_train_plot = np.matrix(y_train)\n",
    "y_test_plot = np.matrix(y_test)\n",
    "print('y_train_plot shape:',y_train_plot.shape)\n",
    "print('y_test_plot shape:',y_test_plot.shape)\n",
    "Architope_prediction_y_train_plot = np.matrix(Architope_prediction_y_train)\n",
    "Architope_prediction_y_test_plot = np.matrix(Architope_prediction_y_test)\n",
    "print('Architope_prediction_y_train_plot shape:',Architope_prediction_y_train_plot.shape)\n",
    "print('Architope_prediction_y_test_plot shape:',Architope_prediction_y_test_plot.shape)\n",
    "#for jj in range(num_traj):\n",
    "    #x, y, z = y_train_plot.T\n",
    "#training\n",
    "x1_star = np.array(y_train_plot[:,0])\n",
    "y1_star = np.array(y_train_plot[:,1])\n",
    "z1_star = np.array(y_train_plot[:,2])\n",
    "x_star = x1_star.flatten()\n",
    "y_star = y1_star.flatten()\n",
    "z_star = z1_star.flatten()\n",
    "# test\n",
    "x1_test_star = np.array(y_test_plot[:,0])\n",
    "y1_test_star = np.array(y_test_plot[:,1])\n",
    "z1_test_star = np.array(y_test_plot[:,2])\n",
    "x_test_star = x1_test_star.flatten()\n",
    "y_test_star = y1_test_star.flatten()\n",
    "z_test_star = z1_test_star.flatten()\n",
    "#print(x.shape)\n",
    "#x = np.reshape(x,7200)\n",
    "#y = np.reshape(y,7200)\n",
    "#z = np.reshape(z,7200)\n",
    "# training\n",
    "xd1_star = np.array(Architope_prediction_y_train_plot[:,0])\n",
    "yd1_star = np.array(Architope_prediction_y_train_plot[:,1])\n",
    "zd1_star = np.array(Architope_prediction_y_train_plot[:,2])\n",
    "xd_star = xd1_star.flatten()\n",
    "yd_star = yd1_star.flatten()\n",
    "zd_star = zd1_star.flatten()\n",
    "# test\n",
    "xd1_test_star = np.array(Architope_prediction_y_test_plot[:,0])\n",
    "yd1_test_star = np.array(Architope_prediction_y_test_plot[:,1])\n",
    "zd1_test_star = np.array(Architope_prediction_y_test_plot[:,2])\n",
    "xd_test_star = xd1_test_star.flatten()\n",
    "yd_test_star = yd1_test_star.flatten()\n",
    "zd_test_star = zd1_test_star.flatten()\n",
    "#xd, yd, zd = Architope_prediction_y_train_plot.T\n",
    "#####################################################\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "#norm1_x = x / np.linalg.norm(x)\n",
    "#norm2_x = normalize(x[:,np.newaxis], axis=0).ravel()\n",
    "#print(np.all(norm1_x == norm2_x))\n",
    "#norm1_y = y / np.linalg.norm(y)\n",
    "#norm2_y = normalize(y[:,np.newaxis], axis=0).ravel()\n",
    "#print(np.all(norm1_x == norm2_x))\n",
    "#norm1_z = z / np.linalg.norm(z)\n",
    "#norm2_z = normalize(z[:,np.newaxis], axis=0).ravel()\n",
    "#print(np.all(norm1_x == norm2_x))\n",
    "####################################################\n",
    "plt.figure()\n",
    "# training\n",
    "#ax.plot(x_test, y_test, z_test, color='r', linewidth=1)\n",
    "#ax.plot(xd_test, yd_test, zd_test, '--', lw=1)\n",
    "ax.plot(x_star, y_star, z_star, color='r', linewidth=1)\n",
    "ax.plot(xd_star, yd_star, zd_star, '--', lw=1)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z')\n",
    "    #ax.scatter(x_plot[0,0], y_plot[0,0], color='r')\n",
    "\n",
    "#ax.view_init(18, -13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "# Plot PC-NN prediction(s)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from scipy import integrate\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "rcParams.update({'font.size':10})\n",
    "plt.rcParams['figure.figsize'] = [12, 12]\n",
    "\n",
    "num_traj = 1;\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "y_train_plot = np.matrix(y_train)\n",
    "y_test_plot = np.matrix(y_test)\n",
    "print('y_train_plot shape:',y_train_plot.shape)\n",
    "print('y_test_plot shape:',y_test_plot.shape)\n",
    "Architope_prediction_y_train_plot = np.matrix(Architope_prediction_y_train)\n",
    "Architope_prediction_y_test_plot = np.matrix(Architope_prediction_y_test)\n",
    "print('Architope_prediction_y_train_plot shape:',Architope_prediction_y_train_plot.shape)\n",
    "print('Architope_prediction_y_test_plot shape:',Architope_prediction_y_test_plot.shape)\n",
    "#for jj in range(num_traj):\n",
    "    #x, y, z = y_train_plot.T\n",
    "#training\n",
    "x1_star = np.array(y_train_plot[:,0])\n",
    "y1_star = np.array(y_train_plot[:,1])\n",
    "z1_star = np.array(y_train_plot[:,2])\n",
    "x_star = x1_star.flatten()\n",
    "y_star = y1_star.flatten()\n",
    "z_star = z1_star.flatten()\n",
    "# test\n",
    "x1_test_star = np.array(y_test_plot[:,0])\n",
    "y1_test_star = np.array(y_test_plot[:,1])\n",
    "z1_test_star = np.array(y_test_plot[:,2])\n",
    "x_test_star = x1_test_star.flatten()\n",
    "y_test_star = y1_test_star.flatten()\n",
    "z_test_star = z1_test_star.flatten()\n",
    "#print(x.shape)\n",
    "#x = np.reshape(x,7200)\n",
    "#y = np.reshape(y,7200)\n",
    "#z = np.reshape(z,7200)\n",
    "# training\n",
    "xd1_star = np.array(Architope_prediction_y_train_plot[:,0])\n",
    "yd1_star = np.array(Architope_prediction_y_train_plot[:,1])\n",
    "zd1_star = np.array(Architope_prediction_y_train_plot[:,2])\n",
    "xd_star = xd1_star.flatten()\n",
    "yd_star = yd1_star.flatten()\n",
    "zd_star = zd1_star.flatten()\n",
    "# test\n",
    "xd1_test_star = np.array(Architope_prediction_y_test_plot[:,0])\n",
    "yd1_test_star = np.array(Architope_prediction_y_test_plot[:,1])\n",
    "zd1_test_star = np.array(Architope_prediction_y_test_plot[:,2])\n",
    "xd_test_star = xd1_test_star.flatten()\n",
    "yd_test_star = yd1_test_star.flatten()\n",
    "zd_test_star = zd1_test_star.flatten()\n",
    "#xd, yd, zd = Architope_prediction_y_train_plot.T\n",
    "#####################################################\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "#norm1_x = x / np.linalg.norm(x)\n",
    "#norm2_x = normalize(x[:,np.newaxis], axis=0).ravel()\n",
    "#print(np.all(norm1_x == norm2_x))\n",
    "#norm1_y = y / np.linalg.norm(y)\n",
    "#norm2_y = normalize(y[:,np.newaxis], axis=0).ravel()\n",
    "#print(np.all(norm1_x == norm2_x))\n",
    "#norm1_z = z / np.linalg.norm(z)\n",
    "#norm2_z = normalize(z[:,np.newaxis], axis=0).ravel()\n",
    "#print(np.all(norm1_x == norm2_x))\n",
    "####################################################\n",
    "plt.figure()\n",
    "# training\n",
    "ax.plot(x_test_star, y_test_star, z_test_star, color='r', linewidth=1)\n",
    "ax.plot(xd_test_star, yd_test_star, zd_test_star, '--', lw=1)\n",
    "#ax.plot(x_star, y_star, z_star, color='r', linewidth=1)\n",
    "#ax.plot(xd_star, yd_star, zd_star, '--', lw=1)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z')\n",
    "    #ax.scatter(x_plot[0,0], y_plot[0,0], color='r')\n",
    "\n",
    "#ax.view_init(18, -13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test_in = y_test[:,jj]\n",
    "#print(y_test[:,jj].shape,y_test_in.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Peformance\n",
    "print('y_train shape:',y_train.shape)\n",
    "print('Architope_prediction_y_train shape:', Architope_prediction_y_train.shape)\n",
    "print('y_test shape:',y_test.shape)\n",
    "print('Architope_prediction_y_test shape:', Architope_prediction_y_test.shape)\n",
    "performance_Architope_C = np.zeros((3,3))\n",
    "for jj in range(3):\n",
    "    performance_Architope = reporter(y_train_hat_in=Architope_prediction_y_train[:,jj],\n",
    "                                    y_test_hat_in=Architope_prediction_y_test[:,jj],\n",
    "                                    y_train_in=y_train[:,jj],\n",
    "                                    y_test_in=y_test[:,jj])\n",
    "    # Update User\n",
    "    print('dimension:',jj,performance_Architope)\n",
    "    #performance_Architope = np.sum(performance_Architope_C, axis=1)\n",
    "# Write Performance\n",
    "performance_Architope.to_latex((results_tables_path+\"Architopes_full_performance.tex\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes for the user update reported above\n",
    "- dimension 0 corrispond to the x dimension\n",
    "- dimension 1 corrispond to the y dimension\n",
    "- dimension 2 corrispond to the z dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(xd_star.shape)\n",
    "print(yd_star.shape)\n",
    "print(zd_star.shape)\n",
    "row = np.array(['xdot', 'ydot', 'zdot']).T\n",
    "row_n = row.shape[0] ##last row\n",
    "Xdot_lorenz_outputPCNN_dataframe = pd.DataFrame(Architope_prediction_y_train_plot, columns=['xdot', 'ydot', 'zdot'])\n",
    "Xdot_lorenz_outputPCNN_dataframe.index.names = ['index']\n",
    "Xdot_lorenz_outputPCNN_dataframe.to_csv('lorenz_PCNN_train.csv')\n",
    "np.savetxt(\"lorenz_PCNN_train.csv\", Xdot_lorenz_outputPCNN_dataframe, delimiter=\",\")\n",
    "#lorenz_data = pd.read_csv(\"lorenz_PCNN.csv\", header=None)\n",
    "#lorenz_data.to_csv(\"lorenz_data.csv\", header=[\"x\", \"y\", \"z\"], index=False)\n",
    "\n",
    "#########################################################\n",
    "Xdot_lorenz_outputPCNN_dataframe_test = pd.DataFrame(Architope_prediction_y_test_plot, columns=['xdot', 'ydot', 'zdot'])\n",
    "Xdot_lorenz_outputPCNN_dataframe_test.index.names = ['index']\n",
    "Xdot_lorenz_outputPCNN_dataframe_test.to_csv('lorenz_PCNN_test.csv')\n",
    "np.savetxt(\"lorenz_PCNN_test.csv\", Xdot_lorenz_outputPCNN_dataframe_test, delimiter=\",\")\n",
    "#lorenz_data = pd.read_csv(\"lorenz_PCNN.csv\", header=None)\n",
    "#lorenz_data.to_csv(\"lorenz_data.csv\", header=[\"x\", \"y\", \"z\"], index=False)\n",
    " \n",
    "# print dataframes.\n",
    "Xdot_lorenz_outputPCNN_dataframe\n",
    "#########################################################\n",
    "############## -- save data manifold -- #################\n",
    "#########################################################\n",
    "print('Architope_manifolds_prediction_y_train',Architope_manifolds_prediction_y_train.shape)\n",
    "print('Architope_manifolds_prediction_y_test',Architope_manifolds_prediction_y_test.shape)\n",
    "################ --- manifold 1 train --- #####################\n",
    "Architope_manifold1_prediction_y_train = pd.DataFrame(Architope_manifolds_prediction_y_train[:,:,0], columns=['xdot', 'ydot', 'zdot'])\n",
    "Architope_manifold1_prediction_y_train.index.names = ['index']\n",
    "Architope_manifold1_prediction_y_train.to_csv('lorenz_PCNN_manifold1.csv')\n",
    "np.savetxt(\"lorenz_PCNN_manifold1.csv\", Architope_manifold1_prediction_y_train, delimiter=\",\")\n",
    "################ --- manifold 2 train --- #####################\n",
    "Architope_manifold2_prediction_y_train = pd.DataFrame(Architope_manifolds_prediction_y_train[:,:,1], columns=['xdot', 'ydot', 'zdot'])\n",
    "Architope_manifold2_prediction_y_train.index.names = ['index']\n",
    "Architope_manifold2_prediction_y_train.to_csv('lorenz_PCNN_manifold2.csv')\n",
    "np.savetxt(\"lorenz_PCNN_manifold2.csv\", Architope_manifold2_prediction_y_train, delimiter=\",\")\n",
    "################ --- manifold 3 train --- #####################\n",
    "#Architope_manifold3_prediction_y_train = pd.DataFrame(Architope_manifolds_prediction_y_train[:,:,2], columns=['xdot', 'ydot', 'zdot'])\n",
    "#Architope_manifold3_prediction_y_train.index.names = ['index']\n",
    "#Architope_manifold3_prediction_y_train.to_csv('lorenz_PCNN_manifold3.csv')\n",
    "#np.savetxt(\"lorenz_PCNN_manifold3.csv\", Architope_manifold3_prediction_y_train, delimiter=\",\")\n",
    "\n",
    "################ --- manifold 1 test --- #####################\n",
    "Architope_manifold1_prediction_y_test = pd.DataFrame(Architope_manifolds_prediction_y_test[:,:,0], columns=['xdot', 'ydot', 'zdot'])\n",
    "Architope_manifold1_prediction_y_test.index.names = ['index']\n",
    "Architope_manifold1_prediction_y_test.to_csv('lorenz_PCNN_manifold1_test.csv')\n",
    "np.savetxt(\"lorenz_PCNN_manifold1_test.csv\", Architope_manifold1_prediction_y_test, delimiter=\",\")\n",
    "################ --- manifold 2 test --- #####################\n",
    "Architope_manifold2_prediction_y_test = pd.DataFrame(Architope_manifolds_prediction_y_test[:,:,1], columns=['xdot', 'ydot', 'zdot'])\n",
    "Architope_manifold2_prediction_y_test.index.names = ['index']\n",
    "Architope_manifold2_prediction_y_test.to_csv('lorenz_PCNN_manifold2_test.csv')\n",
    "np.savetxt(\"lorenz_PCNN_manifold2_test.csv\", Architope_manifold2_prediction_y_test, delimiter=\",\")\n",
    "################ --- manifold 3 test --- #####################\n",
    "#Architope_manifold3_prediction_y_test = pd.DataFrame(Architope_manifolds_prediction_y_test[:,:,2], columns=['xdot', 'ydot', 'zdot'])\n",
    "#Architope_manifold3_prediction_y_test.index.names = ['index']\n",
    "#Architope_manifold3_prediction_y_test.to_csv('lorenz_PCNN_manifold3_test.csv')\n",
    "#np.savetxt(\"lorenz_PCNN_manifold3_test.csv\", Architope_manifold3_prediction_y_test, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Complexity/Efficiency Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Parameters for composite models #\n",
    "#-----------------------------------------#\n",
    "N_params_Architope_full = N_params_Architope + N_params_deep_classifier\n",
    "\n",
    "# Build AIC-like Metric #\n",
    "#-----------------------#\n",
    "AIC_like = 2*(N_params_Architope_full - np.log((performance_Architope['test']['MAE'])))\n",
    "AIC_like = np.round(AIC_like,3)\n",
    "Efficiency = np.log(N_params_Architope_full) *(performance_Architope['test']['MAE'])\n",
    "Efficiency = np.round(Efficiency,3)\n",
    "\n",
    "\n",
    "# Build Table #\n",
    "#-------------#\n",
    "Architope_Model_Complexity_full = pd.DataFrame({'L-time': [Architope_partition_training],\n",
    "                                                  'P-time':[Architope_partitioning_max_time_running],\n",
    "                                                  'N_params_expt': [N_params_Architope_full],\n",
    "                                                  'AIC-like': [AIC_like],\n",
    "                                                  'Eff': [Efficiency]})\n",
    "\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Architope_Model_Complexity_full.to_latex((results_tables_path+\"Architope_full_model_complexities.tex\"))\n",
    "\n",
    "#--------------======---------------#\n",
    "# Display Required Training Time(s) #\n",
    "#--------------======---------------#\n",
    "print(Architope_Model_Complexity_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Benchmark(s)\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architope with Logistic-Classifier Partitioning\n",
    "#### Train Logistic Classifier (Benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training linear classifier\n",
    "Architope_logistic_classifier_training_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'penalty': ['none','l2'], 'C': [0.1, 0.5, 1.0, 10, 100, 1000]}\n",
    "lr = LogisticRegression(random_state=2020)\n",
    "cv = RepeatedStratifiedKFold(n_splits=CV_folds, n_repeats=n_iter, random_state=0)\n",
    "classifier = RandomizedSearchCV(lr, parameters, random_state=2020)\n",
    "\n",
    "# Initialize Classes Labels\n",
    "partition_labels_training = np.argmin(training_quality,axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Logistic Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update User on shape of learned partition\n",
    "print(partition_labels_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print(\"Training classifier and generating partition!\")\n",
    "\n",
    "# Train Logistic Classifier #\n",
    "#---------------------------#\n",
    "# Supress warnings caused by \"ignoring C\" for 'none' penalty and similar obvious warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "# Train Classifier\n",
    "classifier.fit(X_train, partition_labels_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Predicted Class(es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "predicted_classes_train_logistic_BM = classifier.best_estimator_.predict(X_train)\n",
    "Architope_prediction_y_train_logistic_BM = np.take_along_axis(predictions_train, predicted_classes_train_logistic_BM[:,None], axis=1)\n",
    "\n",
    "# Testing Set\n",
    "predicted_classes_test_logistic_BM = classifier.best_estimator_.predict(X_test)\n",
    "Architope_prediction_y_test_logistic_BM = np.take_along_axis(predictions_test, predicted_classes_test_logistic_BM[:,None], axis=1)\n",
    "\n",
    "# Extract Number of Parameters Logistic Regressor\n",
    "N_params_best_logistic = (classifier.best_estimator_.coef_.shape[0])*(classifier.best_estimator_.coef_.shape[1]) + len(classifier.best_estimator_.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Elapsed Training linear classifier\n",
    "Architope_logistic_classifier_training = time.time() - Architope_logistic_classifier_training_begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Peformance\n",
    "performance_architope_ffNN_logistic = reporter(y_train_hat_in=Architope_prediction_y_train_logistic_BM,\n",
    "                                    y_test_hat_in=Architope_prediction_y_test_logistic_BM,\n",
    "                                    y_train_in=y_train,\n",
    "                                    y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_architope_ffNN_logistic.to_latex((results_tables_path+\"Architopes_logistic_performance.tex\"))\n",
    "\n",
    "# Update User\n",
    "print(performance_architope_ffNN_logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Bagged Feed-Forward Networks (ffNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Bagging_ffNN_bagging_time_begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Bagging Weights in-sample\n",
    "bagging_coefficients = LinearRegression().fit(predictions_train,y_train)\n",
    "\n",
    "# Predict Bagging Weights out-of-sample\n",
    "bagged_prediction_train = bagging_coefficients.predict(predictions_train)\n",
    "bagged_prediction_test = bagging_coefficients.predict(predictions_test)\n",
    "\n",
    "# Write number of trainable bagging parameters\n",
    "N_bagged_parameters = len(bagging_coefficients.coef_) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Bagging_ffNN_bagging_time = time.time() - Bagging_ffNN_bagging_time_begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Peformance\n",
    "performance_bagged_ffNN = reporter(y_train_hat_in=bagged_prediction_train,\n",
    "                                    y_test_hat_in=bagged_prediction_test,\n",
    "                                    y_train_in=y_train,\n",
    "                                    y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_bagged_ffNN.to_latex((results_tables_path+\"ffNN_Bagged.tex\"))\n",
    "\n",
    "# Update User\n",
    "print(\"Written Bagged Performance\")\n",
    "print(performance_bagged_ffNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Partition: Generated!...Feature Generation Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla ffNN\n",
    "#### Reload Hyper-parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-Load Hyper-parameter Grid\n",
    "exec(open('Grid_Enhanced_Network.py').read())\n",
    "# Re-Load Helper Function(s)\n",
    "exec(open('Helper_Functions.py').read())\n",
    "# Update Dimensions\n",
    "param_grid_Vanilla_Nets['input_dim'] = [X_train.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Vanilla_ffNN_time_beginn = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train vanilla ffNNs\n",
    "y_hat_train_Vanilla_ffNN, y_hat_test_Vanilla_ffNN, N_params_Vanilla_ffNN = build_ffNN(n_folds = CV_folds_failsafe, \n",
    "                                                                                      n_jobs = n_jobs, \n",
    "                                                                                      n_iter = n_iter, \n",
    "                                                                                      param_grid_in = param_grid_Vanilla_Nets, \n",
    "                                                                                      X_train=X_train, \n",
    "                                                                                      y_train=data_y, \n",
    "                                                                                      X_test_partial=X_train,\n",
    "                                                                                      X_test=X_test,\n",
    "                                                                                      NOCV=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for Bagging\n",
    "Vanilla_ffNN_time = time.time() - Vanilla_ffNN_time_beginn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print(\"Trained vanilla ffNNs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Peformance\n",
    "performance_Vanilla_ffNN = reporter(y_train_hat_in=y_hat_train_Vanilla_ffNN,y_test_hat_in=y_hat_test_Vanilla_ffNN,y_train_in=y_train,y_test_in=y_test)\n",
    "# Write Performance\n",
    "performance_Vanilla_ffNN.to_latex((results_tables_path+\"ffNN_Vanilla.tex\"))\n",
    "\n",
    "# Update User #\n",
    "#-------------#\n",
    "print(\"Written Bagged Vanilla ffNNs\")\n",
    "print(performance_Vanilla_ffNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Required Training Time(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-Line #\n",
    "#---------#\n",
    "\n",
    "# Architope (Full) Time Lapse\n",
    "Architope_Full_Time = partitioning_time + Architope_partition_training + Architope_deep_classifier_training\n",
    "# Architope (Logistic) Time Lapse\n",
    "Architope_logistic_Time = partitioning_time + Architope_partition_training + Architope_logistic_classifier_training\n",
    "# Bagged ffNN Training Time\n",
    "Bagged_ffNN_Time = partitioning_time + Architope_partition_training + Bagging_ffNN_bagging_time\n",
    "# Vanilla ffNN\n",
    "Vanilla_ffNN_Time = Vanilla_ffNN_time\n",
    "\n",
    "# Parallel (Only if applicable) #\n",
    "#-------------------------------#\n",
    "\n",
    "# Architope (Full) Time Lapse\n",
    "Architope_Full_Time_parallel = partitioning_time + Architope_partitioning_max_time_running + Architope_deep_classifier_training\n",
    "# Architope (Logistic) Time Lapse\n",
    "Architope_logistic_Time_parallel = partitioning_time + Architope_partitioning_max_time_running + Architope_logistic_classifier_training\n",
    "# Bagged ffNN Training Time\n",
    "Bagged_ffNN_Time_parallel = partitioning_time + Architope_partitioning_max_time_running + Bagging_ffNN_bagging_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Required Training Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print('Writing preliminary table: Required Training Times')\n",
    "\n",
    "# Format Required Training Time(s)\n",
    "training_times_In_Line = pd.DataFrame({'Architope': [round(Architope_Full_Time,3)],\n",
    "                                'Architope-logistic': [round(Architope_logistic_Time,3)],\n",
    "                                'Vanilla ffNN': [round(Vanilla_ffNN_Time,3)],\n",
    "                                'Bagged ffNN': [round(Bagged_ffNN_Time,3)]})\n",
    "training_times_Parallel = pd.DataFrame({'Architope': [round(Architope_Full_Time_parallel,3)],\n",
    "                                'Architope-logistic': [round(Architope_logistic_Time_parallel,3)],\n",
    "                                'Vanilla ffNN': ['-'],\n",
    "                                'Bagged ffNN': [round(Bagged_ffNN_Time_parallel,3)]})\n",
    "\n",
    "# Combine Training Times into Single Data-Frame #\n",
    "#-----------------------------------------------#\n",
    "Model_Training_times = training_times_In_Line.append(training_times_Parallel)\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Model_Training_times.to_latex((results_tables_path+\"Model_Training_Times.tex\"))\n",
    "# Display Required Training Time(s)\n",
    "print(Model_Training_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run: Gradient Boosted Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print('Training Gradient-Boosted Random Forest: In-progress...')\n",
    "# Run from External Script\n",
    "exec(open('Gradient_Boosted_Random_Forest_Regressor.py').read())\n",
    "\n",
    "# Update User #\n",
    "#-------------#\n",
    "print('Training of Gradient-Boosted Random Forest: Complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Result(s)\n",
    "#### (Update) Write Required Training Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update User #\n",
    "#-------------#\n",
    "print('Completing Table: Required Training Times')\n",
    "\n",
    "# Format Required Training Time(s)\n",
    "training_times_In_Line = pd.DataFrame({'Vanilla ffNN': [round(Vanilla_ffNN_Time,3)],\n",
    "                                       'Grad.Bstd Rand.F': [round(Gradient_boosted_Random_forest_time,3)],\n",
    "                                       'Bagged ffNN': [round(Bagged_ffNN_Time,3)],\n",
    "                                       'Architope-logistic': [round(Architope_logistic_Time,3)],\n",
    "                                       'Architope': [round(Architope_Full_Time,3)]\n",
    "                                      },index=['In-Line (L-Time)'])\n",
    "\n",
    "training_times_Parallel = pd.DataFrame({'Vanilla ffNN': ['-'],\n",
    "                                        'Grad.Bstd Rand.F': ['-'],\n",
    "                                        'Bagged ffNN': [round(Bagged_ffNN_Time_parallel,3)],\n",
    "                                        'Architope-logistic': [round(Architope_logistic_Time_parallel,3)],\n",
    "                                        'Architope': [round(Architope_Full_Time_parallel,3)]},index=['Parallel (P-Time)'])\n",
    "\n",
    "# Combine Training Times into Single Data-Frame #\n",
    "#-----------------------------------------------#\n",
    "Model_Training_times = training_times_In_Line.append(training_times_Parallel)\n",
    "Model_Training_times = Model_Training_times.transpose()\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Model_Training_times.to_latex((results_tables_path+\"Model_Training_Times.tex\"))\n",
    "# Display Required Training Time(s)\n",
    "print(Model_Training_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Metric(s)\n",
    "#### Write Predictive Performance Dataframe(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Training Performance\n",
    "predictive_performance_training = pd.DataFrame({'ffNN': performance_Vanilla_ffNN.train,\n",
    "                                                'GBRF': Gradient_boosted_tree.train,\n",
    "                                                'ffNN-bag': performance_bagged_ffNN.train,\n",
    "                                                'ffNN-lgt': performance_architope_ffNN_logistic.train,\n",
    "                                                'tope': performance_Architope.train})\n",
    "predictive_performance_training = predictive_performance_training.transpose()\n",
    "\n",
    "# Write Testing Performance\n",
    "predictive_performance_test = pd.DataFrame({'ffNN': performance_Vanilla_ffNN.test,\n",
    "                                            'GBRF': Gradient_boosted_tree.test,\n",
    "                                            'ffNN-bag': performance_bagged_ffNN.test,\n",
    "                                            'ffNN-lgt': performance_architope_ffNN_logistic.test,\n",
    "                                            'tope': performance_Architope.test})\n",
    "predictive_performance_test = predictive_performance_test.transpose()\n",
    "\n",
    "# Write into one Dataframe #\n",
    "#--------------------------#\n",
    "predictive_performance_training.to_latex((results_tables_path+\"Models_predictive_performance_training.tex\"))\n",
    "predictive_performance_test.to_latex((results_tables_path+\"Models_predictive_performance_testing.tex\"))\n",
    "\n",
    "# Update User #\n",
    "#-------------#\n",
    "print(predictive_performance_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Complexity/Efficiency Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Parameters for composite models #\n",
    "#-----------------------------------------#\n",
    "N_params_Architope_full = N_params_Architope + N_params_deep_classifier\n",
    "N_params_Architope_logistic = N_params_Architope + N_params_best_logistic\n",
    "N_params_bagged_ffNN = N_params_Architope + N_bagged_parameters\n",
    "\n",
    "# Build Table #\n",
    "#-------------#\n",
    "Number_of_model_parameters = pd.DataFrame({'Vanilla ffNN': [N_params_Vanilla_ffNN],\n",
    "                                           'Grad.Bstd Rand.F': [N_tot_params_in_forest],\n",
    "                                           'Bagged ffNN': [N_params_bagged_ffNN],\n",
    "                                           'Architope-logistic': [N_params_Architope_logistic],\n",
    "                                           'Architope': [N_params_Architope_full]},\n",
    "                                            index=['N_par'])\n",
    "\n",
    "Number_of_model_parameters = Number_of_model_parameters.transpose()\n",
    "\n",
    "# Append to Dataframe #\n",
    "#---------------------#\n",
    "Model_Complexity_Metrics = Model_Training_times\n",
    "Model_Complexity_Metrics['N_par']=Number_of_model_parameters.values\n",
    "\n",
    "# Build AIC-like Metric #\n",
    "#-----------------------#\n",
    "AIC_like = 2*((Model_Complexity_Metrics.N_par.values) - np.log(predictive_performance_test.MAE.values))\n",
    "AIC_like = np.round(AIC_like,3)\n",
    "Efficiency = np.log(Model_Complexity_Metrics.N_par.values) *predictive_performance_test.MAE.values\n",
    "Efficiency = np.round(Efficiency,3)\n",
    "\n",
    "\n",
    "# Update Training Metrics Dataframe #\n",
    "#-----------------------------------#\n",
    "Model_Complexity_Metrics['AIC_like'] = AIC_like\n",
    "Model_Complexity_Metrics['Eff'] = Efficiency\n",
    "\n",
    "# Write Required Training Time(s)\n",
    "Model_Complexity_Metrics.to_latex((results_tables_path+\"Model_Complexity_Metrics.tex\"))\n",
    "\n",
    "#--------------======---------------#\n",
    "# Display Required Training Time(s) #\n",
    "#--------------======---------------#\n",
    "print(Model_Complexity_Metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' ')\n",
    "print(' ')\n",
    "print('#-------------------#')\n",
    "print(' PERFORMANCE SUMMARY:')\n",
    "print('#-------------------#')\n",
    "print(' ')\n",
    "print(' ')\n",
    "print('#===================#')\n",
    "print(' Individual Metrics: ')\n",
    "print('#======-============#')\n",
    "print(' ')\n",
    "print('----------------------------------------')\n",
    "print('----------------------------------------')\n",
    "print('Architope (Full)')\n",
    "print('----------------------------------------')\n",
    "print(performance_Architope)\n",
    "print('----------------------------------------')\n",
    "print('Architope - Naive Logistic')\n",
    "print('----------------------------------------')\n",
    "print(performance_architope_ffNN_logistic)\n",
    "print('----------------------------------------')\n",
    "print('Vanilla ffNN')\n",
    "print('----------------------------------------')\n",
    "print(performance_Vanilla_ffNN)\n",
    "print('----------------------------------------')\n",
    "print('Bagged ffNN')\n",
    "print('----------------------------------------')\n",
    "print(performance_bagged_ffNN)\n",
    "print('----------------------------------------')\n",
    "print('Gradient Boosted Random Forest Regressor')\n",
    "print('----------------------------------------')\n",
    "print(Gradient_boosted_tree)\n",
    "print('----------------------------------------')\n",
    "print('----------------------------------------')\n",
    "print(' ')\n",
    "print(' ')\n",
    "#\n",
    "print('#==================#')\n",
    "print(' Overview  Metrics : ')\n",
    "print('#==================#')\n",
    "print(' ')\n",
    "print('----------------------------------------')\n",
    "print('Training Performance: ')\n",
    "print('----------------------------------------')\n",
    "print(predictive_performance_training)\n",
    "print('----------------------------------------')\n",
    "print('Testing Performance: ')\n",
    "print('----------------------------------------')\n",
    "print(predictive_performance_test)\n",
    "print('----------------------------------------')\n",
    "print(' ')\n",
    "print(' ')\n",
    "#\n",
    "print('#====================#')\n",
    "print(' Efficiency Metrics: ')\n",
    "print('#====================#')\n",
    "print(' ')\n",
    "print('Model Training Times:')\n",
    "print('----------------------------------------')\n",
    "print(Model_Complexity_Metrics)\n",
    "print(' ')\n",
    "print(' ')\n",
    "print(' Have a great day!!  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "# plt.scatter(x,y,color='gray',label='$f(x)$',linestyle='--')\n",
    "plt.scatter(x_1,y_1,color='slategrey',label=r'$f_1(x)$',linestyle=(0,(1,1)),s=3,alpha=.9,marker=1)\n",
    "plt.scatter(x_2,y_2,color='dodgerblue',label=r'$f_2(x)$',linestyle=(0,(1,1)),s=3,alpha=.9,marker=1)\n",
    "\n",
    "#--------------------#\n",
    "# Benchmark Model(s) #\n",
    "#--------------------#\n",
    "# Plot ffNN\n",
    "plt.scatter(x,y_hat_train_Vanilla_ffNN, color = 'darkmagenta',linestyle=(0,(1,10)),  label='ffNN',s=3,alpha=.95)\n",
    "plt.scatter(x,Architope_prediction_y_train, color = 'mediumseagreen',linestyle=(0,(1,10)), label='tope',s=3,alpha=.95)\n",
    "#\n",
    "#jj = 0\n",
    "#for j in range(0,len(x)-1,10):\n",
    "#    jj = jj+1;\n",
    "#    plt.scatter(x[j],y_hat_train_Vanilla_ffNN[jj], color = 'darkmagenta',linestyle=(0,(1,10)),  label='ffNN',s=3,alpha=.95)\n",
    "#    plt.scatter(x[j],Architope_prediction_y_train[jj], color = 'mediumseagreen',linestyle=(0,(1,10)), label='tope',s=3,alpha=.95)\n",
    "\n",
    "\n",
    "\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.legend(loc=\"upper left\",prop={'size': 10})\n",
    "plt.title(\"Model Predictions\")\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/DEMO.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#print(len(x)-1,len(y_hat_train_Vanilla_ffNN))\n",
    "#print(np.linspace(10,len(x)-1,len(y_hat_train_Vanilla_ffNN)))\n",
    "#def my_func(low,up,leng):\n",
    "#    list = []\n",
    "#    step = int((up - low) / float(leng))\n",
    "#    print(step)\n",
    "#    for i in range(leng):\n",
    "#        list.append(int(low))\n",
    "#        low = int(low + step)\n",
    "#    return list\n",
    "#\n",
    "#my_list = my_func(0,len(x)-1,len(y_hat_train_Vanilla_ffNN))\n",
    "#res = [int(item) for item in my_list]\n",
    "#\n",
    "#print(my_list)\n",
    "#print(type(my_list))\n",
    "#\n",
    "#indice_prova = 10,len(x)-1,len(y_hat_train_Vanilla_ffNN);\n",
    "#for j in range(0,len(x)-1,10):\n",
    "#    print(j,np.matrix(x[j]).shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fin\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "# Initialize Plot #\n",
    "#-----------------#\n",
    "plt.figure(num=None, figsize=(12, 12), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "# Generate Plots #\n",
    "#----------------#\n",
    "# Plot Signal\n",
    "# plt.scatter(x,y,color='gray',label='$f(x)$',linestyle='--')\n",
    "dfX_train = pd.DataFrame(X_train,columns=['x','y','z'])\n",
    "dfX_train.plot(x = 'x', y='y', z='z', kind = 'scatter')\n",
    "\n",
    "#--------------------#\n",
    "# Benchmark Model(s) #\n",
    "#--------------------#\n",
    "# Plot ffNN\n",
    "plt.scatter(x,y_hat_train_Vanilla_ffNN, color = 'darkmagenta',linestyle=(0,(1,10)),  label='ffNN',s=3,alpha=.95)\n",
    "plt.scatter(x,Architope_prediction_y_train, color = 'mediumseagreen',linestyle=(0,(1,10)), label='tope',s=3,alpha=.95)\n",
    "\n",
    "\n",
    "\n",
    "# Format Plot #\n",
    "#-------------#\n",
    "plt.legend(loc=\"upper left\",prop={'size': 10})\n",
    "plt.title(\"Model Predictions\")\n",
    "\n",
    "# Export #\n",
    "#--------#\n",
    "# SAVE Figure to .eps\n",
    "plt.savefig('./outputs/plotsANDfigures/lorenz.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
